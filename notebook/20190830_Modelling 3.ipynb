{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Segmentation Modelling (version : alam.1.2)\n",
    "\n",
    "This is the modelling documentation of Word Segmentation\n",
    "\n",
    "First Structured :\n",
    "\n",
    "\n",
    "Input :\n",
    "\n",
    "    INPUT LENGTH =15\n",
    "    TRAIN = 90k data (Random state : 342)\n",
    "    \n",
    "\n",
    "output :\n",
    "\n",
    "    Seq2Seq\n",
    "\n",
    "\n",
    "## Plan\n",
    "\n",
    "    [*] Get Data\n",
    "    [*] Transform the data\n",
    "    [ ] Prepare the model\n",
    "    [ ] Train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scr/')\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import WordSegmenTools as wst\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA_RAW='../../data/raw/'\n",
    "PATH_DATA_CLN='../../data/clean/'\n",
    "PATH_MODEL='../../data/model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_clean_100k.res']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(PATH_DATA_CLN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_LENGTH=15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_cln=pd.read_csv(PATH_DATA_CLN+'data_clean_100k.res')\n",
    "data_cln=pickle.load(open(PATH_DATA_CLN+'data_clean_100k.res','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cln['len_source']=data_cln.source.apply(len)\n",
    "data_used=data_cln[data_cln.len_source==INPUT_LENGTH]\n",
    "data_used=data_used.reset_index()[['source','target','index']]\n",
    "data_used.columns=['source','target','ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70882</th>\n",
       "      <td>diiniselainyang</td>\n",
       "      <td>di ini selain yang</td>\n",
       "      <td>1735243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97532</th>\n",
       "      <td>sebelumnyadasar</td>\n",
       "      <td>sebelumnya dasar</td>\n",
       "      <td>1862347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86145</th>\n",
       "      <td>perhatianramsey</td>\n",
       "      <td>perhatian ramsey</td>\n",
       "      <td>1807857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78675</th>\n",
       "      <td>ceobagianmadrid</td>\n",
       "      <td>ceo bagian madrid</td>\n",
       "      <td>1772446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97129</th>\n",
       "      <td>yangrincitvbaik</td>\n",
       "      <td>yang rinci tv baik</td>\n",
       "      <td>1860404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>dansaksikanfoto</td>\n",
       "      <td>dan saksikan foto</td>\n",
       "      <td>1406416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88169</th>\n",
       "      <td>memperbaikiatas</td>\n",
       "      <td>memperbaiki atas</td>\n",
       "      <td>1817330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12582</th>\n",
       "      <td>adasebagaikalla</td>\n",
       "      <td>ada sebagai kalla</td>\n",
       "      <td>1458956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>sergibahwasenin</td>\n",
       "      <td>sergi bahwa senin</td>\n",
       "      <td>1410438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53157</th>\n",
       "      <td>pemulihanversus</td>\n",
       "      <td>pemulihan versus</td>\n",
       "      <td>1651357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                source              target      ids\n",
       "70882  diiniselainyang  di ini selain yang  1735243\n",
       "97532  sebelumnyadasar    sebelumnya dasar  1862347\n",
       "86145  perhatianramsey    perhatian ramsey  1807857\n",
       "78675  ceobagianmadrid   ceo bagian madrid  1772446\n",
       "97129  yangrincitvbaik  yang rinci tv baik  1860404\n",
       "1359   dansaksikanfoto   dan saksikan foto  1406416\n",
       "88169  memperbaikiatas    memperbaiki atas  1817330\n",
       "12582  adasebagaikalla   ada sebagai kalla  1458956\n",
       "2204   sergibahwasenin   sergi bahwa senin  1410438\n",
       "53157  pemulihanversus    pemulihan versus  1651357"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_used.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_used['flag_space'] = data_used['target'].map(wst.get_flag_space)\n",
    "word2idx, idx2word = wst.get_label_index(data_used.source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_used_train=data_used.sample(90000,random_state=342)\n",
    "data_used_test=data_used[~(data_used.ids.isin(data_used_train.ids))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alamhanz/anaconda/envs/word_s/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## Target \n",
    "Y_tr=np.array(data_used_train.flag_space.apply(list).tolist(),dtype=np.double)\n",
    "Y_tr=Y_tr.reshape(-1,INPUT_LENGTH,1)\n",
    "Y_te=np.array(data_used_test.flag_space.apply(list).tolist(),dtype=np.double)\n",
    "Y_te=Y_te.reshape(-1,INPUT_LENGTH,1)\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit(Y_tr.reshape(-1,1))\n",
    "\n",
    "Y_tr=encoder.transform(Y_tr.reshape(-1,1)).toarray().reshape(-1,INPUT_LENGTH,len(encoder.categories_[0]))\n",
    "Y_te=encoder.transform(Y_te.reshape(-1,1)).toarray().reshape(-1,INPUT_LENGTH,len(encoder.categories_[0]))\n",
    "\n",
    "## Source\n",
    "X_tr=wst.char_vectorizer(data_used_train.source.tolist(), word2idx, INPUT_LENGTH)\n",
    "X_te=wst.char_vectorizer(data_used_test.source.tolist(), word2idx, INPUT_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 15, 26)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 15, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hid_dim, n_layers, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.lstm = torch.nn.LSTM(input_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(src)\n",
    "        outputs, (hidden, cell) = self.lstm(src)\n",
    "        return outputs,hidden, cell\n",
    "\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, input_dim ,output_dim, hid_dim, n_layers, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.hid_dim = hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.lstm = torch.nn.LSTM(input_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        self.Lin = torch.nn.Linear(hid_dim, output_dim)\n",
    "        self.out = torch.nn.Softmax()\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):        \n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(input)\n",
    "\n",
    "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        prediction = self.out(self.Lin(output.squeeze(0)))\n",
    "        return prediction, hidden, cell\n",
    "\n",
    "\n",
    "class Seq2Seqv1(torch.nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seqv1,self).__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "        \n",
    "    def duplicate_hidden(self,h,n_layers,batch_size):\n",
    "        list_h=[]\n",
    "        for i in range(n_layers):\n",
    "            list_h+=[h[:,-1,:][i]]*batch_size\n",
    "        enc_h=torch.cat(list_h,0).view(n_layers,batch_size,-1)\n",
    "        return enc_h\n",
    "        \n",
    "    def forward(self, src, trg=None, teacher_forcing_ratio = 0.5):  \n",
    "        if teacher_forcing_ratio==0:\n",
    "            trg=torch.zeros(batch_size,max_len,trg_vocab_size)\n",
    "            \n",
    "        batch_size = trg.shape[0]\n",
    "        max_len = trg.shape[1]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        n_layers = self.decoder.n_layers\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(batch_size, max_len, trg_vocab_size)\n",
    "        \n",
    "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        out_enc, h, c = self.encoder(src)\n",
    "        enc_h=self.duplicate_hidden(h,n_layers,batch_size)\n",
    "        enc_c=self.duplicate_hidden(c,n_layers,batch_size)          \n",
    "        \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = trg[:,0]\n",
    "        outputs[:,0]=input\n",
    "\n",
    "        for t in range(1, max_len):\n",
    "            output, enc_h, enc_c = self.decoder(input, enc_h, enc_c)\n",
    "            outputs[:,t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            input = (trg[:,t] if teacher_force else output)\n",
    "\n",
    "        return outputs\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.random()<0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers=2\n",
    "# batch=3\n",
    "# seq_len=5\n",
    "# embed=10\n",
    "# hidden_layer=30\n",
    "# output_dim=1\n",
    "# dropout=0.1\n",
    "\n",
    "# model0=Encoder(embed,hidden_layer,layers,dropout)\n",
    "# model1=Decoder(output_dim,output_dim,hidden_layer,layers,dropout)\n",
    "# model_seq=Seq2Seqv1(model0,model1)\n",
    "\n",
    "# X_source=torch.rand(batch,seq_len,embed)\n",
    "# X_target=torch.rand(batch,seq_len,output_dim)\n",
    "\n",
    "# model_seq(X_source,X_target,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_batching_torch(X,y,batch):\n",
    "    batches=[(torch.from_numpy(X[i*(batch):i*(batch)+batch]).type('torch.DoubleTensor'),\n",
    "              torch.from_numpy(y[i*(batch):i*(batch)+batch]).type('torch.DoubleTensor'))   \n",
    "                  for i in range(int(len(X)/batch)+1)]\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3601"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE=25\n",
    "training_samples=data_batching_torch(X_tr,Y_tr,BATCH_SIZE)\n",
    "len(training_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alamhanz/anaconda/envs/word_s/lib/python3.7/site-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "# Get the model\n",
    "LAYERS=1\n",
    "EMBED=26\n",
    "HIDDEN_LAYER=15\n",
    "DROPO=0.1\n",
    "OUT_DIM=2\n",
    "learningRate=0.0009\n",
    "teach_f=0.2\n",
    "\n",
    "model0=Encoder(EMBED,HIDDEN_LAYER,LAYERS,DROPO)\n",
    "model1=Decoder(OUT_DIM,OUT_DIM,HIDDEN_LAYER,LAYERS,DROPO)\n",
    "model_seq=Seq2Seqv1(model0,model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choose the optimizer and criterion\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model_seq.parameters(),lr=learningRate)\n",
    "# optimizer = torch.optim.SGD(model.parameters(),lr=learningRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "AA=training_samples[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.DoubleTensor'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AA.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alamhanz/anaconda/envs/word_s/lib/python3.7/site-packages/ipykernel/__main__.py:36: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss train 0.3063901637577338\n",
      "running loss train 0.3063124970346681\n",
      "running loss train 0.3064514522916733\n",
      "running loss train 0.3063511881480616\n",
      "running loss train 0.30615947727527937\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "running_loss_train = 0\n",
    "model_seq.double()\n",
    "model_seq.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss=[]\n",
    "    # Converting inputs and labels to Variable\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(training_samples, 1):\n",
    "        if data.size()[0]>0:\n",
    "            inputs = Variable(data)\n",
    "            labels = Variable(target)\n",
    "            optimizer.zero_grad()\n",
    "            outputs= model_seq(inputs,labels,teach_f)\n",
    "            # get loss for the predicted output\n",
    "            # print(outputs.type(),labels.float().type())\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            loss.backward()\n",
    "            # torch.nn.utils.clip_grad_norm_(model_seq.parameters(), 1)\n",
    "            # update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss.append(loss.item())\n",
    "            running_loss_train += (loss.item() - running_loss_train) / batch_idx\n",
    "        \n",
    "    if epoch % 2 == 0:\n",
    "        print(\"running loss train\", running_loss_train)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelLstm(\n",
       "  (lstm): LSTM(26, 25)\n",
       "  (linear): Linear(in_features=25, out_features=15, bias=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "XX=X_tr.copy()\n",
    "XX=Variable(torch.from_numpy(XX).type('torch.DoubleTensor'))\n",
    "yy=model(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000000000000000',\n",
       " '000000000000000',\n",
       " '000000000000000',\n",
       " '000000000000000',\n",
       " '000000000000000',\n",
       " '000000000000000',\n",
       " '000000000000000',\n",
       " '000000000000000',\n",
       " '000000000000000',\n",
       " '000000000000000']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy0=yy[0].data.numpy()\n",
    "yy0=(yy0>0.5).astype(int).astype(str)\n",
    "yy0=[''.join(i) for i in yy0]\n",
    "yy0[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_used_train['y_pred']=yy0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>flag_space</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50144</th>\n",
       "      <td>melainkandaerah</td>\n",
       "      <td>melainkan daerah</td>\n",
       "      <td>1637189</td>\n",
       "      <td>000000001000000</td>\n",
       "      <td>000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67640</th>\n",
       "      <td>menegaskantiket</td>\n",
       "      <td>menegaskan tiket</td>\n",
       "      <td>1719973</td>\n",
       "      <td>000000000100000</td>\n",
       "      <td>000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87884</th>\n",
       "      <td>pelakusetiapini</td>\n",
       "      <td>pelaku setiap ini</td>\n",
       "      <td>1815936</td>\n",
       "      <td>000001000001000</td>\n",
       "      <td>000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32800</th>\n",
       "      <td>tahunberbobotdi</td>\n",
       "      <td>tahun berbobot di</td>\n",
       "      <td>1554907</td>\n",
       "      <td>000010000000100</td>\n",
       "      <td>000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60884</th>\n",
       "      <td>terpopulerdalam</td>\n",
       "      <td>terpopuler dalam</td>\n",
       "      <td>1687901</td>\n",
       "      <td>000000000100000</td>\n",
       "      <td>000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15182</th>\n",
       "      <td>identikinisudah</td>\n",
       "      <td>identik ini sudah</td>\n",
       "      <td>1471301</td>\n",
       "      <td>000000100100000</td>\n",
       "      <td>000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65497</th>\n",
       "      <td>denganpekerjaan</td>\n",
       "      <td>dengan pekerjaan</td>\n",
       "      <td>1709857</td>\n",
       "      <td>000001000000000</td>\n",
       "      <td>000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48114</th>\n",
       "      <td>mobiltahunsedan</td>\n",
       "      <td>mobil tahun sedan</td>\n",
       "      <td>1627587</td>\n",
       "      <td>000010000100000</td>\n",
       "      <td>000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58791</th>\n",
       "      <td>terkaitterhadap</td>\n",
       "      <td>terkait terhadap</td>\n",
       "      <td>1678152</td>\n",
       "      <td>000000100000000</td>\n",
       "      <td>000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31506</th>\n",
       "      <td>sertatariftahap</td>\n",
       "      <td>serta tarif tahap</td>\n",
       "      <td>1548878</td>\n",
       "      <td>000010000100000</td>\n",
       "      <td>000000000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                source             target      ids       flag_space  \\\n",
       "50144  melainkandaerah   melainkan daerah  1637189  000000001000000   \n",
       "67640  menegaskantiket   menegaskan tiket  1719973  000000000100000   \n",
       "87884  pelakusetiapini  pelaku setiap ini  1815936  000001000001000   \n",
       "32800  tahunberbobotdi  tahun berbobot di  1554907  000010000000100   \n",
       "60884  terpopulerdalam   terpopuler dalam  1687901  000000000100000   \n",
       "15182  identikinisudah  identik ini sudah  1471301  000000100100000   \n",
       "65497  denganpekerjaan   dengan pekerjaan  1709857  000001000000000   \n",
       "48114  mobiltahunsedan  mobil tahun sedan  1627587  000010000100000   \n",
       "58791  terkaitterhadap   terkait terhadap  1678152  000000100000000   \n",
       "31506  sertatariftahap  serta tarif tahap  1548878  000010000100000   \n",
       "\n",
       "                y_pred  \n",
       "50144  000000000000000  \n",
       "67640  000000000000000  \n",
       "87884  000000000000000  \n",
       "32800  000000000000000  \n",
       "60884  000000000000000  \n",
       "15182  000000000000000  \n",
       "65497  000000000000000  \n",
       "48114  000000000000000  \n",
       "58791  000000000000000  \n",
       "31506  000000000000000  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_used_train.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test it\n",
    "XX=X_te.copy()\n",
    "XX=Variable(torch.from_numpy(XX).type('torch.DoubleTensor'))\n",
    "yy=model(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000000000000000',\n",
       " '000000000000000',\n",
       " '000000000000000',\n",
       " '000000000000000',\n",
       " '000000000000000',\n",
       " '000000000000000',\n",
       " '000000000000000',\n",
       " '000000000000000',\n",
       " '000000000000000',\n",
       " '000000000000000']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy0=yy[0].data.numpy()\n",
    "yy0=(yy0>0.5).astype(int).astype(str)\n",
    "yy0=[''.join(i) for i in yy0]\n",
    "yy0[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alamhanz/anaconda/envs/word_s/lib/python3.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "data_used_test['y_pred']=yy0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>flag_space</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12342</th>\n",
       "      <td>sepakperusahaan</td>\n",
       "      <td>sepak perusahaan</td>\n",
       "      <td>1457750</td>\n",
       "      <td>000010000000000</td>\n",
       "      <td>000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9138</th>\n",
       "      <td>miliarmelakukan</td>\n",
       "      <td>miliar melakukan</td>\n",
       "      <td>1442854</td>\n",
       "      <td>000001000000000</td>\n",
       "      <td>000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3403</th>\n",
       "      <td>asalpendaftaran</td>\n",
       "      <td>asal pendaftaran</td>\n",
       "      <td>1416167</td>\n",
       "      <td>000100000000000</td>\n",
       "      <td>000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74342</th>\n",
       "      <td>jelasnyastadium</td>\n",
       "      <td>jelasnya stadium</td>\n",
       "      <td>1751813</td>\n",
       "      <td>000000010000000</td>\n",
       "      <td>000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12597</th>\n",
       "      <td>cmnphargaplakat</td>\n",
       "      <td>cmnp harga plakat</td>\n",
       "      <td>1459043</td>\n",
       "      <td>000100001000000</td>\n",
       "      <td>000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86940</th>\n",
       "      <td>bahwadenganyang</td>\n",
       "      <td>bahwa dengan yang</td>\n",
       "      <td>1811573</td>\n",
       "      <td>000010000010000</td>\n",
       "      <td>000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54344</th>\n",
       "      <td>terjadibniingin</td>\n",
       "      <td>terjadi bni ingin</td>\n",
       "      <td>1657235</td>\n",
       "      <td>000000100100000</td>\n",
       "      <td>000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8989</th>\n",
       "      <td>untuktetappiper</td>\n",
       "      <td>untuk tetap piper</td>\n",
       "      <td>1442103</td>\n",
       "      <td>000010000100000</td>\n",
       "      <td>000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15108</th>\n",
       "      <td>ratelalusamping</td>\n",
       "      <td>rate lalu samping</td>\n",
       "      <td>1471008</td>\n",
       "      <td>000100010000000</td>\n",
       "      <td>000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28477</th>\n",
       "      <td>danyangnokiadwi</td>\n",
       "      <td>dan yang nokia dwi</td>\n",
       "      <td>1534286</td>\n",
       "      <td>001000100001000</td>\n",
       "      <td>000000000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                source              target      ids       flag_space  \\\n",
       "12342  sepakperusahaan    sepak perusahaan  1457750  000010000000000   \n",
       "9138   miliarmelakukan    miliar melakukan  1442854  000001000000000   \n",
       "3403   asalpendaftaran    asal pendaftaran  1416167  000100000000000   \n",
       "74342  jelasnyastadium    jelasnya stadium  1751813  000000010000000   \n",
       "12597  cmnphargaplakat   cmnp harga plakat  1459043  000100001000000   \n",
       "86940  bahwadenganyang   bahwa dengan yang  1811573  000010000010000   \n",
       "54344  terjadibniingin   terjadi bni ingin  1657235  000000100100000   \n",
       "8989   untuktetappiper   untuk tetap piper  1442103  000010000100000   \n",
       "15108  ratelalusamping   rate lalu samping  1471008  000100010000000   \n",
       "28477  danyangnokiadwi  dan yang nokia dwi  1534286  001000100001000   \n",
       "\n",
       "                y_pred  \n",
       "12342  000000000000000  \n",
       "9138   000000000000000  \n",
       "3403   000000000000000  \n",
       "74342  000000000000000  \n",
       "12597  000000000000000  \n",
       "86940  000000000000000  \n",
       "54344  000000000000000  \n",
       "8989   000000000000000  \n",
       "15108  000000000000000  \n",
       "28477  000000000000000  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_used_train.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:word_s]",
   "language": "python",
   "name": "conda-env-word_s-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
