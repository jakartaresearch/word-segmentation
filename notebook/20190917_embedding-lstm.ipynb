{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open(os.path.join('../data/clean/data_clean_100k.res'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['source_len']= data.source.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_data_selected = data[data['source_len'] == MAX_LENGTH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_data_selected.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2char = dict((idx, c) for idx, c in enumerate(\"abcdefghijklmnopqrstuvwxyz\", 1))\n",
    "char2idx = dict((c, idx) for idx, c in enumerate(\"abcdefghijklmnopqrstuvwxyz\", 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2char[0] = '<UNK>'\n",
    "char2idx['<UNK>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flag_space(sentence):\n",
    "    \n",
    "    no_space = []\n",
    "    flag_space = []\n",
    "    sentence = str(sentence)\n",
    "    for char in sentence: \n",
    "        if char != ' ':\n",
    "            no_space.append(char)\n",
    "            flag_space.append('0')\n",
    "        elif char == ' ':\n",
    "            flag_space[-1] = '1'\n",
    "            \n",
    "    no_space = ''.join(no_space)\n",
    "    flag_space = ''.join(flag_space)\n",
    "    \n",
    "    return flag_space\n",
    "\n",
    "def get_total_space(flag):\n",
    "    return sum(np.array(list(flag)).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source_char_idx(source):\n",
    "    return [char2idx[char_] for char_ in list(str(source))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "d_data_selected['flag_space'] = d_data_selected['target'].apply(get_flag_space)\n",
    "d_data_selected['flag_space_sum'] = d_data_selected['flag_space'].map(get_total_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "d_data_selected['source_array'] = d_data_selected['source'].map(get_source_char_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>source_len</th>\n",
       "      <th>flag_space</th>\n",
       "      <th>flag_space_sum</th>\n",
       "      <th>source_array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dibuangtersentuhjubysudah</td>\n",
       "      <td>dibuang tersentuh juby sudah</td>\n",
       "      <td>25</td>\n",
       "      <td>0000001000000001000100000</td>\n",
       "      <td>3</td>\n",
       "      <td>[4, 9, 2, 21, 1, 14, 7, 20, 5, 18, 19, 5, 14, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pintardikenalharikirilaga</td>\n",
       "      <td>pintar dikenal hari kiri laga</td>\n",
       "      <td>25</td>\n",
       "      <td>0000010000001000100010000</td>\n",
       "      <td>4</td>\n",
       "      <td>[16, 9, 14, 20, 1, 18, 4, 9, 11, 5, 14, 1, 12,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tirautamajelassesidisawit</td>\n",
       "      <td>tira utama jelas sesi di sawit</td>\n",
       "      <td>25</td>\n",
       "      <td>0001000010000100010100000</td>\n",
       "      <td>5</td>\n",
       "      <td>[20, 9, 18, 1, 21, 20, 1, 13, 1, 10, 5, 12, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>padasebagaimenyamakanpetr</td>\n",
       "      <td>pada sebagai menyamakan petr</td>\n",
       "      <td>25</td>\n",
       "      <td>0001000000100000000010000</td>\n",
       "      <td>3</td>\n",
       "      <td>[16, 1, 4, 1, 19, 5, 2, 1, 7, 1, 9, 13, 5, 14,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>demikiansementaraaslilaga</td>\n",
       "      <td>demikian sementara asli laga</td>\n",
       "      <td>25</td>\n",
       "      <td>0000000100000000100010000</td>\n",
       "      <td>3</td>\n",
       "      <td>[4, 5, 13, 9, 11, 9, 1, 14, 19, 5, 13, 5, 14, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>jugabandungapbnleveldalam</td>\n",
       "      <td>juga bandung apbn level dalam</td>\n",
       "      <td>25</td>\n",
       "      <td>0001000000100010000100000</td>\n",
       "      <td>4</td>\n",
       "      <td>[10, 21, 7, 1, 2, 1, 14, 4, 21, 14, 7, 1, 16, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>laininsurancewidiadetelah</td>\n",
       "      <td>lain insurance widiade telah</td>\n",
       "      <td>25</td>\n",
       "      <td>0001000000001000000100000</td>\n",
       "      <td>3</td>\n",
       "      <td>[12, 1, 9, 14, 9, 14, 19, 21, 18, 1, 14, 3, 5,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>memainkanagarinipertanian</td>\n",
       "      <td>memainkan agar ini pertanian</td>\n",
       "      <td>25</td>\n",
       "      <td>0000000010001001000000000</td>\n",
       "      <td>3</td>\n",
       "      <td>[13, 5, 13, 1, 9, 14, 11, 1, 14, 1, 7, 1, 18, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>polantastetapiharapanlalu</td>\n",
       "      <td>polantas tetapi harapan lalu</td>\n",
       "      <td>25</td>\n",
       "      <td>0000000100000100000010000</td>\n",
       "      <td>3</td>\n",
       "      <td>[16, 15, 12, 1, 14, 20, 1, 19, 20, 5, 20, 1, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dirilisadakurangberjangka</td>\n",
       "      <td>dirilis ada kurang berjangka</td>\n",
       "      <td>25</td>\n",
       "      <td>0000001001000001000000000</td>\n",
       "      <td>3</td>\n",
       "      <td>[4, 9, 18, 9, 12, 9, 19, 1, 4, 1, 11, 21, 18, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dijadikankemampuanduatapi</td>\n",
       "      <td>dijadikan kemampuan dua tapi</td>\n",
       "      <td>25</td>\n",
       "      <td>0000000010000000010010000</td>\n",
       "      <td>3</td>\n",
       "      <td>[4, 9, 10, 1, 4, 9, 11, 1, 14, 11, 5, 13, 1, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>milangolkementerianpersen</td>\n",
       "      <td>milan gol kementerian persen</td>\n",
       "      <td>25</td>\n",
       "      <td>0000100100000000001000000</td>\n",
       "      <td>3</td>\n",
       "      <td>[13, 9, 12, 1, 14, 7, 15, 12, 11, 5, 13, 5, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>statusmenjualpencetakpupr</td>\n",
       "      <td>status menjual pencetak pupr</td>\n",
       "      <td>25</td>\n",
       "      <td>0000010000001000000010000</td>\n",
       "      <td>3</td>\n",
       "      <td>[19, 20, 1, 20, 21, 19, 13, 5, 14, 10, 21, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mumemulaifacebookklasemen</td>\n",
       "      <td>mu memulai facebook klasemen</td>\n",
       "      <td>25</td>\n",
       "      <td>0100000010000000100000000</td>\n",
       "      <td>3</td>\n",
       "      <td>[13, 21, 13, 5, 13, 21, 12, 1, 9, 6, 1, 3, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>borobudurpasanganlanjutan</td>\n",
       "      <td>borobudur pasangan lanjutan</td>\n",
       "      <td>25</td>\n",
       "      <td>0000000010000000100000000</td>\n",
       "      <td>2</td>\n",
       "      <td>[2, 15, 18, 15, 2, 21, 4, 21, 18, 16, 1, 19, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>jumatdidikutiphidupukuran</td>\n",
       "      <td>jumat di dikutip hidup ukuran</td>\n",
       "      <td>25</td>\n",
       "      <td>0000101000000100001000000</td>\n",
       "      <td>4</td>\n",
       "      <td>[10, 21, 13, 1, 20, 4, 9, 4, 9, 11, 21, 20, 9,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pernyataanpadabernamamana</td>\n",
       "      <td>pernyataan pada bernama mana</td>\n",
       "      <td>25</td>\n",
       "      <td>0000000001000100000010000</td>\n",
       "      <td>3</td>\n",
       "      <td>[16, 5, 18, 14, 25, 1, 20, 1, 1, 14, 16, 1, 4,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>incimenuruteuropakesasini</td>\n",
       "      <td>inci menurut europa kesas ini</td>\n",
       "      <td>25</td>\n",
       "      <td>0001000000100000100001000</td>\n",
       "      <td>4</td>\n",
       "      <td>[9, 14, 3, 9, 13, 5, 14, 21, 18, 21, 20, 5, 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>acehnegarasatupertumbuhan</td>\n",
       "      <td>aceh negara satu pertumbuhan</td>\n",
       "      <td>25</td>\n",
       "      <td>0001000001000100000000000</td>\n",
       "      <td>3</td>\n",
       "      <td>[1, 3, 5, 8, 14, 5, 7, 1, 18, 1, 19, 1, 20, 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>duniatersebutpadasoemarno</td>\n",
       "      <td>dunia tersebut pada soemarno</td>\n",
       "      <td>25</td>\n",
       "      <td>0000100000001000100000000</td>\n",
       "      <td>3</td>\n",
       "      <td>[4, 21, 14, 9, 1, 20, 5, 18, 19, 5, 2, 21, 20,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bidanginisebelummessibaru</td>\n",
       "      <td>bidang ini sebelum messi baru</td>\n",
       "      <td>25</td>\n",
       "      <td>0000010010000001000010000</td>\n",
       "      <td>4</td>\n",
       "      <td>[2, 9, 4, 1, 14, 7, 9, 14, 9, 19, 5, 2, 5, 12,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sarriyangjokowitibadengan</td>\n",
       "      <td>sarri yang jokowi tiba dengan</td>\n",
       "      <td>25</td>\n",
       "      <td>0000100010000010001000000</td>\n",
       "      <td>4</td>\n",
       "      <td>[19, 1, 18, 18, 9, 25, 1, 14, 7, 10, 15, 11, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>diketahuiekonomiperingkat</td>\n",
       "      <td>diketahui ekonomi peringkat</td>\n",
       "      <td>25</td>\n",
       "      <td>0000000010000001000000000</td>\n",
       "      <td>2</td>\n",
       "      <td>[4, 9, 11, 5, 20, 1, 8, 21, 9, 5, 11, 15, 14, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>laindenganucapecstarbabak</td>\n",
       "      <td>lain dengan ucap ecstar babak</td>\n",
       "      <td>25</td>\n",
       "      <td>0001000001000100000100000</td>\n",
       "      <td>4</td>\n",
       "      <td>[12, 1, 9, 14, 4, 5, 14, 7, 1, 14, 21, 3, 1, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sebagaiselainkesayanganmu</td>\n",
       "      <td>sebagai selain kesayanganmu</td>\n",
       "      <td>25</td>\n",
       "      <td>0000001000001000000000000</td>\n",
       "      <td>2</td>\n",
       "      <td>[19, 5, 2, 1, 7, 1, 9, 19, 5, 12, 1, 9, 14, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>hinggadiaseanmasihkuarter</td>\n",
       "      <td>hingga di asean masih kuarter</td>\n",
       "      <td>25</td>\n",
       "      <td>0000010100001000010000000</td>\n",
       "      <td>4</td>\n",
       "      <td>[8, 9, 14, 7, 7, 1, 4, 9, 1, 19, 5, 1, 14, 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>batukeperluandebutnyayang</td>\n",
       "      <td>batu keperluan debutnya yang</td>\n",
       "      <td>25</td>\n",
       "      <td>0001000000001000000010000</td>\n",
       "      <td>3</td>\n",
       "      <td>[2, 1, 20, 21, 11, 5, 16, 5, 18, 12, 21, 1, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>urusankursijakartamembuat</td>\n",
       "      <td>urusan kursi jakarta membuat</td>\n",
       "      <td>25</td>\n",
       "      <td>0000010000100000010000000</td>\n",
       "      <td>3</td>\n",
       "      <td>[21, 18, 21, 19, 1, 14, 11, 21, 18, 19, 9, 10,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>masatanahbeberapapadasama</td>\n",
       "      <td>masa tanah beberapa pada sama</td>\n",
       "      <td>25</td>\n",
       "      <td>0001000010000000100010000</td>\n",
       "      <td>4</td>\n",
       "      <td>[13, 1, 19, 1, 20, 1, 14, 1, 8, 2, 5, 2, 5, 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>rapatjakartatidakptkepada</td>\n",
       "      <td>rapat jakarta tidak pt kepada</td>\n",
       "      <td>25</td>\n",
       "      <td>0000100000010000101000000</td>\n",
       "      <td>4</td>\n",
       "      <td>[18, 1, 16, 1, 20, 10, 1, 11, 1, 18, 20, 1, 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99970</th>\n",
       "      <td>sampingbermainkembalicara</td>\n",
       "      <td>samping bermain kembali cara</td>\n",
       "      <td>25</td>\n",
       "      <td>0000001000000100000010000</td>\n",
       "      <td>3</td>\n",
       "      <td>[19, 1, 13, 16, 9, 14, 7, 2, 5, 18, 13, 1, 9, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99971</th>\n",
       "      <td>tahunmendorongandroidyang</td>\n",
       "      <td>tahun mendorong android yang</td>\n",
       "      <td>25</td>\n",
       "      <td>0000100000000100000010000</td>\n",
       "      <td>3</td>\n",
       "      <td>[20, 1, 8, 21, 14, 13, 5, 14, 4, 15, 18, 15, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99972</th>\n",
       "      <td>asalyangtahunstudibersiap</td>\n",
       "      <td>asal yang tahun studi bersiap</td>\n",
       "      <td>25</td>\n",
       "      <td>0001000100001000010000000</td>\n",
       "      <td>4</td>\n",
       "      <td>[1, 19, 1, 12, 25, 1, 14, 7, 20, 1, 8, 21, 14,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973</th>\n",
       "      <td>wibjikaathleticpemainsatu</td>\n",
       "      <td>wib jika athletic pemain satu</td>\n",
       "      <td>25</td>\n",
       "      <td>0010001000000010000010000</td>\n",
       "      <td>4</td>\n",
       "      <td>[23, 9, 2, 10, 9, 11, 1, 1, 20, 8, 12, 5, 20, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99974</th>\n",
       "      <td>usaisebesartwitternasabah</td>\n",
       "      <td>usai sebesar twitter nasabah</td>\n",
       "      <td>25</td>\n",
       "      <td>0001000000100000010000000</td>\n",
       "      <td>3</td>\n",
       "      <td>[21, 19, 1, 9, 19, 5, 2, 5, 19, 1, 18, 20, 23,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99975</th>\n",
       "      <td>saudaraitaliasajaatauanak</td>\n",
       "      <td>saudara italia saja atau anak</td>\n",
       "      <td>25</td>\n",
       "      <td>0000001000001000100010000</td>\n",
       "      <td>4</td>\n",
       "      <td>[19, 1, 21, 4, 1, 18, 1, 9, 20, 1, 12, 9, 1, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99976</th>\n",
       "      <td>melajuasiakeretabarcelona</td>\n",
       "      <td>melaju asia kereta barcelona</td>\n",
       "      <td>25</td>\n",
       "      <td>0000010001000001000000000</td>\n",
       "      <td>3</td>\n",
       "      <td>[13, 5, 12, 1, 10, 21, 1, 19, 9, 1, 11, 5, 18,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99977</th>\n",
       "      <td>parisnasionaldicabutuntuk</td>\n",
       "      <td>paris nasional dicabut untuk</td>\n",
       "      <td>25</td>\n",
       "      <td>0000100000001000000100000</td>\n",
       "      <td>3</td>\n",
       "      <td>[16, 1, 18, 9, 19, 14, 1, 19, 9, 15, 14, 1, 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99978</th>\n",
       "      <td>yangbareldangolkekisruhan</td>\n",
       "      <td>yang barel dan gol kekisruhan</td>\n",
       "      <td>25</td>\n",
       "      <td>0001000010010010000000000</td>\n",
       "      <td>4</td>\n",
       "      <td>[25, 1, 14, 7, 2, 1, 18, 5, 12, 4, 1, 14, 7, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99979</th>\n",
       "      <td>lapordiyanglagamenyatakan</td>\n",
       "      <td>lapor di yang laga menyatakan</td>\n",
       "      <td>25</td>\n",
       "      <td>0000101000100010000000000</td>\n",
       "      <td>4</td>\n",
       "      <td>[12, 1, 16, 15, 18, 4, 9, 25, 1, 14, 7, 12, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99980</th>\n",
       "      <td>newcastleteruspersennamun</td>\n",
       "      <td>newcastle terus persen namun</td>\n",
       "      <td>25</td>\n",
       "      <td>0000000010000100000100000</td>\n",
       "      <td>3</td>\n",
       "      <td>[14, 5, 23, 3, 1, 19, 20, 12, 5, 20, 5, 18, 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99981</th>\n",
       "      <td>berkualitasberjangkabelum</td>\n",
       "      <td>berkualitas berjangka belum</td>\n",
       "      <td>25</td>\n",
       "      <td>0000000000100000000100000</td>\n",
       "      <td>2</td>\n",
       "      <td>[2, 5, 18, 11, 21, 1, 12, 9, 20, 1, 19, 2, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99982</th>\n",
       "      <td>hotelpemeriksaanlevelyang</td>\n",
       "      <td>hotel pemeriksaan level yang</td>\n",
       "      <td>25</td>\n",
       "      <td>0000100000000001000010000</td>\n",
       "      <td>3</td>\n",
       "      <td>[8, 15, 20, 5, 12, 16, 5, 13, 5, 18, 9, 11, 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99983</th>\n",
       "      <td>barisansaatvalverdepaling</td>\n",
       "      <td>barisan saat valverde paling</td>\n",
       "      <td>25</td>\n",
       "      <td>0000001000100000001000000</td>\n",
       "      <td>3</td>\n",
       "      <td>[2, 1, 18, 9, 19, 1, 14, 19, 1, 1, 20, 22, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99984</th>\n",
       "      <td>yangmempekerjakankemudian</td>\n",
       "      <td>yang mempekerjakan kemudian</td>\n",
       "      <td>25</td>\n",
       "      <td>0001000000000000100000000</td>\n",
       "      <td>2</td>\n",
       "      <td>[25, 1, 14, 7, 13, 5, 13, 16, 5, 11, 5, 18, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99985</th>\n",
       "      <td>denganuntukkualitasselama</td>\n",
       "      <td>dengan untuk kualitas selama</td>\n",
       "      <td>25</td>\n",
       "      <td>0000010000100000001000000</td>\n",
       "      <td>3</td>\n",
       "      <td>[4, 5, 14, 7, 1, 14, 21, 14, 20, 21, 11, 11, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99986</th>\n",
       "      <td>melemahbernamatelahmereka</td>\n",
       "      <td>melemah bernama telah mereka</td>\n",
       "      <td>25</td>\n",
       "      <td>0000001000000100001000000</td>\n",
       "      <td>3</td>\n",
       "      <td>[13, 5, 12, 5, 13, 1, 8, 2, 5, 18, 14, 1, 13, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99987</th>\n",
       "      <td>demikianberdasarkandengan</td>\n",
       "      <td>demikian berdasarkan dengan</td>\n",
       "      <td>25</td>\n",
       "      <td>0000000100000000001000000</td>\n",
       "      <td>2</td>\n",
       "      <td>[4, 5, 13, 9, 11, 9, 1, 14, 2, 5, 18, 4, 1, 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99988</th>\n",
       "      <td>laluberkassekitarsjafridi</td>\n",
       "      <td>lalu berkas sekitar sjafri di</td>\n",
       "      <td>25</td>\n",
       "      <td>0001000001000000100000100</td>\n",
       "      <td>4</td>\n",
       "      <td>[12, 1, 12, 21, 2, 5, 18, 11, 1, 19, 19, 5, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99989</th>\n",
       "      <td>menjadiarifintakdestinasi</td>\n",
       "      <td>menjadi arifin tak destinasi</td>\n",
       "      <td>25</td>\n",
       "      <td>0000001000001001000000000</td>\n",
       "      <td>3</td>\n",
       "      <td>[13, 5, 14, 10, 1, 4, 9, 1, 18, 9, 6, 9, 14, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99990</th>\n",
       "      <td>disesuaikandapatyangmusim</td>\n",
       "      <td>disesuaikan dapat yang musim</td>\n",
       "      <td>25</td>\n",
       "      <td>0000000000100001000100000</td>\n",
       "      <td>3</td>\n",
       "      <td>[4, 9, 19, 5, 19, 21, 1, 9, 11, 1, 14, 4, 1, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99991</th>\n",
       "      <td>rpcukupkejadianpenuntutan</td>\n",
       "      <td>rp cukup kejadian penuntutan</td>\n",
       "      <td>25</td>\n",
       "      <td>0100001000000010000000000</td>\n",
       "      <td>3</td>\n",
       "      <td>[18, 16, 3, 21, 11, 21, 16, 11, 5, 10, 1, 4, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99992</th>\n",
       "      <td>higuainakanmineralseluruh</td>\n",
       "      <td>higuain akan mineral seluruh</td>\n",
       "      <td>25</td>\n",
       "      <td>0000001000100000010000000</td>\n",
       "      <td>3</td>\n",
       "      <td>[8, 9, 7, 21, 1, 9, 14, 1, 11, 1, 14, 13, 9, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99993</th>\n",
       "      <td>masukwhenresolusiitukedua</td>\n",
       "      <td>masuk when resolusi itu kedua</td>\n",
       "      <td>25</td>\n",
       "      <td>0000100010000000100100000</td>\n",
       "      <td>4</td>\n",
       "      <td>[13, 1, 19, 21, 11, 23, 8, 5, 14, 18, 5, 19, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99994</th>\n",
       "      <td>lagikarenamenggerakanucap</td>\n",
       "      <td>lagi karena menggerakan ucap</td>\n",
       "      <td>25</td>\n",
       "      <td>0001000001000000000010000</td>\n",
       "      <td>3</td>\n",
       "      <td>[12, 1, 7, 9, 11, 1, 18, 5, 14, 1, 13, 5, 14, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>externaldanmerekalahnamun</td>\n",
       "      <td>external dan merekalah namun</td>\n",
       "      <td>25</td>\n",
       "      <td>0000000100100000000100000</td>\n",
       "      <td>3</td>\n",
       "      <td>[5, 24, 20, 5, 18, 14, 1, 12, 4, 1, 14, 13, 5,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>yangstandbydibandungduong</td>\n",
       "      <td>yang standby di bandung duong</td>\n",
       "      <td>25</td>\n",
       "      <td>0001000000101000000100000</td>\n",
       "      <td>4</td>\n",
       "      <td>[25, 1, 14, 7, 19, 20, 1, 14, 4, 2, 25, 4, 9, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>asingjugasundulannonmigas</td>\n",
       "      <td>asing juga sundulan nonmigas</td>\n",
       "      <td>25</td>\n",
       "      <td>0000100010000000100000000</td>\n",
       "      <td>3</td>\n",
       "      <td>[1, 19, 9, 14, 7, 10, 21, 7, 1, 19, 21, 14, 4,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>kemenhubmenjadibagianonwj</td>\n",
       "      <td>kemenhub menjadi bagian onwj</td>\n",
       "      <td>25</td>\n",
       "      <td>0000000100000010000010000</td>\n",
       "      <td>3</td>\n",
       "      <td>[11, 5, 13, 5, 14, 8, 21, 2, 13, 5, 14, 10, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>digitallangkahsepertikopi</td>\n",
       "      <td>digital langkah seperti kopi</td>\n",
       "      <td>25</td>\n",
       "      <td>0000001000000100000010000</td>\n",
       "      <td>3</td>\n",
       "      <td>[4, 9, 7, 9, 20, 1, 12, 12, 1, 14, 7, 11, 1, 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          source                          target  source_len  \\\n",
       "0      dibuangtersentuhjubysudah    dibuang tersentuh juby sudah          25   \n",
       "1      pintardikenalharikirilaga   pintar dikenal hari kiri laga          25   \n",
       "2      tirautamajelassesidisawit  tira utama jelas sesi di sawit          25   \n",
       "3      padasebagaimenyamakanpetr    pada sebagai menyamakan petr          25   \n",
       "4      demikiansementaraaslilaga    demikian sementara asli laga          25   \n",
       "5      jugabandungapbnleveldalam   juga bandung apbn level dalam          25   \n",
       "6      laininsurancewidiadetelah    lain insurance widiade telah          25   \n",
       "7      memainkanagarinipertanian    memainkan agar ini pertanian          25   \n",
       "8      polantastetapiharapanlalu    polantas tetapi harapan lalu          25   \n",
       "9      dirilisadakurangberjangka    dirilis ada kurang berjangka          25   \n",
       "10     dijadikankemampuanduatapi    dijadikan kemampuan dua tapi          25   \n",
       "11     milangolkementerianpersen    milan gol kementerian persen          25   \n",
       "12     statusmenjualpencetakpupr    status menjual pencetak pupr          25   \n",
       "13     mumemulaifacebookklasemen    mu memulai facebook klasemen          25   \n",
       "14     borobudurpasanganlanjutan     borobudur pasangan lanjutan          25   \n",
       "15     jumatdidikutiphidupukuran   jumat di dikutip hidup ukuran          25   \n",
       "16     pernyataanpadabernamamana    pernyataan pada bernama mana          25   \n",
       "17     incimenuruteuropakesasini   inci menurut europa kesas ini          25   \n",
       "18     acehnegarasatupertumbuhan    aceh negara satu pertumbuhan          25   \n",
       "19     duniatersebutpadasoemarno    dunia tersebut pada soemarno          25   \n",
       "20     bidanginisebelummessibaru   bidang ini sebelum messi baru          25   \n",
       "21     sarriyangjokowitibadengan   sarri yang jokowi tiba dengan          25   \n",
       "22     diketahuiekonomiperingkat     diketahui ekonomi peringkat          25   \n",
       "23     laindenganucapecstarbabak   lain dengan ucap ecstar babak          25   \n",
       "24     sebagaiselainkesayanganmu     sebagai selain kesayanganmu          25   \n",
       "25     hinggadiaseanmasihkuarter   hingga di asean masih kuarter          25   \n",
       "26     batukeperluandebutnyayang    batu keperluan debutnya yang          25   \n",
       "27     urusankursijakartamembuat    urusan kursi jakarta membuat          25   \n",
       "28     masatanahbeberapapadasama   masa tanah beberapa pada sama          25   \n",
       "29     rapatjakartatidakptkepada   rapat jakarta tidak pt kepada          25   \n",
       "...                          ...                             ...         ...   \n",
       "99970  sampingbermainkembalicara    samping bermain kembali cara          25   \n",
       "99971  tahunmendorongandroidyang    tahun mendorong android yang          25   \n",
       "99972  asalyangtahunstudibersiap   asal yang tahun studi bersiap          25   \n",
       "99973  wibjikaathleticpemainsatu   wib jika athletic pemain satu          25   \n",
       "99974  usaisebesartwitternasabah    usai sebesar twitter nasabah          25   \n",
       "99975  saudaraitaliasajaatauanak   saudara italia saja atau anak          25   \n",
       "99976  melajuasiakeretabarcelona    melaju asia kereta barcelona          25   \n",
       "99977  parisnasionaldicabutuntuk    paris nasional dicabut untuk          25   \n",
       "99978  yangbareldangolkekisruhan   yang barel dan gol kekisruhan          25   \n",
       "99979  lapordiyanglagamenyatakan   lapor di yang laga menyatakan          25   \n",
       "99980  newcastleteruspersennamun    newcastle terus persen namun          25   \n",
       "99981  berkualitasberjangkabelum     berkualitas berjangka belum          25   \n",
       "99982  hotelpemeriksaanlevelyang    hotel pemeriksaan level yang          25   \n",
       "99983  barisansaatvalverdepaling    barisan saat valverde paling          25   \n",
       "99984  yangmempekerjakankemudian     yang mempekerjakan kemudian          25   \n",
       "99985  denganuntukkualitasselama    dengan untuk kualitas selama          25   \n",
       "99986  melemahbernamatelahmereka    melemah bernama telah mereka          25   \n",
       "99987  demikianberdasarkandengan     demikian berdasarkan dengan          25   \n",
       "99988  laluberkassekitarsjafridi   lalu berkas sekitar sjafri di          25   \n",
       "99989  menjadiarifintakdestinasi    menjadi arifin tak destinasi          25   \n",
       "99990  disesuaikandapatyangmusim    disesuaikan dapat yang musim          25   \n",
       "99991  rpcukupkejadianpenuntutan    rp cukup kejadian penuntutan          25   \n",
       "99992  higuainakanmineralseluruh    higuain akan mineral seluruh          25   \n",
       "99993  masukwhenresolusiitukedua   masuk when resolusi itu kedua          25   \n",
       "99994  lagikarenamenggerakanucap    lagi karena menggerakan ucap          25   \n",
       "99995  externaldanmerekalahnamun    external dan merekalah namun          25   \n",
       "99996  yangstandbydibandungduong   yang standby di bandung duong          25   \n",
       "99997  asingjugasundulannonmigas    asing juga sundulan nonmigas          25   \n",
       "99998  kemenhubmenjadibagianonwj    kemenhub menjadi bagian onwj          25   \n",
       "99999  digitallangkahsepertikopi    digital langkah seperti kopi          25   \n",
       "\n",
       "                      flag_space  flag_space_sum  \\\n",
       "0      0000001000000001000100000               3   \n",
       "1      0000010000001000100010000               4   \n",
       "2      0001000010000100010100000               5   \n",
       "3      0001000000100000000010000               3   \n",
       "4      0000000100000000100010000               3   \n",
       "5      0001000000100010000100000               4   \n",
       "6      0001000000001000000100000               3   \n",
       "7      0000000010001001000000000               3   \n",
       "8      0000000100000100000010000               3   \n",
       "9      0000001001000001000000000               3   \n",
       "10     0000000010000000010010000               3   \n",
       "11     0000100100000000001000000               3   \n",
       "12     0000010000001000000010000               3   \n",
       "13     0100000010000000100000000               3   \n",
       "14     0000000010000000100000000               2   \n",
       "15     0000101000000100001000000               4   \n",
       "16     0000000001000100000010000               3   \n",
       "17     0001000000100000100001000               4   \n",
       "18     0001000001000100000000000               3   \n",
       "19     0000100000001000100000000               3   \n",
       "20     0000010010000001000010000               4   \n",
       "21     0000100010000010001000000               4   \n",
       "22     0000000010000001000000000               2   \n",
       "23     0001000001000100000100000               4   \n",
       "24     0000001000001000000000000               2   \n",
       "25     0000010100001000010000000               4   \n",
       "26     0001000000001000000010000               3   \n",
       "27     0000010000100000010000000               3   \n",
       "28     0001000010000000100010000               4   \n",
       "29     0000100000010000101000000               4   \n",
       "...                          ...             ...   \n",
       "99970  0000001000000100000010000               3   \n",
       "99971  0000100000000100000010000               3   \n",
       "99972  0001000100001000010000000               4   \n",
       "99973  0010001000000010000010000               4   \n",
       "99974  0001000000100000010000000               3   \n",
       "99975  0000001000001000100010000               4   \n",
       "99976  0000010001000001000000000               3   \n",
       "99977  0000100000001000000100000               3   \n",
       "99978  0001000010010010000000000               4   \n",
       "99979  0000101000100010000000000               4   \n",
       "99980  0000000010000100000100000               3   \n",
       "99981  0000000000100000000100000               2   \n",
       "99982  0000100000000001000010000               3   \n",
       "99983  0000001000100000001000000               3   \n",
       "99984  0001000000000000100000000               2   \n",
       "99985  0000010000100000001000000               3   \n",
       "99986  0000001000000100001000000               3   \n",
       "99987  0000000100000000001000000               2   \n",
       "99988  0001000001000000100000100               4   \n",
       "99989  0000001000001001000000000               3   \n",
       "99990  0000000000100001000100000               3   \n",
       "99991  0100001000000010000000000               3   \n",
       "99992  0000001000100000010000000               3   \n",
       "99993  0000100010000000100100000               4   \n",
       "99994  0001000001000000000010000               3   \n",
       "99995  0000000100100000000100000               3   \n",
       "99996  0001000000101000000100000               4   \n",
       "99997  0000100010000000100000000               3   \n",
       "99998  0000000100000010000010000               3   \n",
       "99999  0000001000000100000010000               3   \n",
       "\n",
       "                                            source_array  \n",
       "0      [4, 9, 2, 21, 1, 14, 7, 20, 5, 18, 19, 5, 14, ...  \n",
       "1      [16, 9, 14, 20, 1, 18, 4, 9, 11, 5, 14, 1, 12,...  \n",
       "2      [20, 9, 18, 1, 21, 20, 1, 13, 1, 10, 5, 12, 1,...  \n",
       "3      [16, 1, 4, 1, 19, 5, 2, 1, 7, 1, 9, 13, 5, 14,...  \n",
       "4      [4, 5, 13, 9, 11, 9, 1, 14, 19, 5, 13, 5, 14, ...  \n",
       "5      [10, 21, 7, 1, 2, 1, 14, 4, 21, 14, 7, 1, 16, ...  \n",
       "6      [12, 1, 9, 14, 9, 14, 19, 21, 18, 1, 14, 3, 5,...  \n",
       "7      [13, 5, 13, 1, 9, 14, 11, 1, 14, 1, 7, 1, 18, ...  \n",
       "8      [16, 15, 12, 1, 14, 20, 1, 19, 20, 5, 20, 1, 1...  \n",
       "9      [4, 9, 18, 9, 12, 9, 19, 1, 4, 1, 11, 21, 18, ...  \n",
       "10     [4, 9, 10, 1, 4, 9, 11, 1, 14, 11, 5, 13, 1, 1...  \n",
       "11     [13, 9, 12, 1, 14, 7, 15, 12, 11, 5, 13, 5, 14...  \n",
       "12     [19, 20, 1, 20, 21, 19, 13, 5, 14, 10, 21, 1, ...  \n",
       "13     [13, 21, 13, 5, 13, 21, 12, 1, 9, 6, 1, 3, 5, ...  \n",
       "14     [2, 15, 18, 15, 2, 21, 4, 21, 18, 16, 1, 19, 1...  \n",
       "15     [10, 21, 13, 1, 20, 4, 9, 4, 9, 11, 21, 20, 9,...  \n",
       "16     [16, 5, 18, 14, 25, 1, 20, 1, 1, 14, 16, 1, 4,...  \n",
       "17     [9, 14, 3, 9, 13, 5, 14, 21, 18, 21, 20, 5, 21...  \n",
       "18     [1, 3, 5, 8, 14, 5, 7, 1, 18, 1, 19, 1, 20, 21...  \n",
       "19     [4, 21, 14, 9, 1, 20, 5, 18, 19, 5, 2, 21, 20,...  \n",
       "20     [2, 9, 4, 1, 14, 7, 9, 14, 9, 19, 5, 2, 5, 12,...  \n",
       "21     [19, 1, 18, 18, 9, 25, 1, 14, 7, 10, 15, 11, 1...  \n",
       "22     [4, 9, 11, 5, 20, 1, 8, 21, 9, 5, 11, 15, 14, ...  \n",
       "23     [12, 1, 9, 14, 4, 5, 14, 7, 1, 14, 21, 3, 1, 1...  \n",
       "24     [19, 5, 2, 1, 7, 1, 9, 19, 5, 12, 1, 9, 14, 11...  \n",
       "25     [8, 9, 14, 7, 7, 1, 4, 9, 1, 19, 5, 1, 14, 13,...  \n",
       "26     [2, 1, 20, 21, 11, 5, 16, 5, 18, 12, 21, 1, 14...  \n",
       "27     [21, 18, 21, 19, 1, 14, 11, 21, 18, 19, 9, 10,...  \n",
       "28     [13, 1, 19, 1, 20, 1, 14, 1, 8, 2, 5, 2, 5, 18...  \n",
       "29     [18, 1, 16, 1, 20, 10, 1, 11, 1, 18, 20, 1, 20...  \n",
       "...                                                  ...  \n",
       "99970  [19, 1, 13, 16, 9, 14, 7, 2, 5, 18, 13, 1, 9, ...  \n",
       "99971  [20, 1, 8, 21, 14, 13, 5, 14, 4, 15, 18, 15, 1...  \n",
       "99972  [1, 19, 1, 12, 25, 1, 14, 7, 20, 1, 8, 21, 14,...  \n",
       "99973  [23, 9, 2, 10, 9, 11, 1, 1, 20, 8, 12, 5, 20, ...  \n",
       "99974  [21, 19, 1, 9, 19, 5, 2, 5, 19, 1, 18, 20, 23,...  \n",
       "99975  [19, 1, 21, 4, 1, 18, 1, 9, 20, 1, 12, 9, 1, 1...  \n",
       "99976  [13, 5, 12, 1, 10, 21, 1, 19, 9, 1, 11, 5, 18,...  \n",
       "99977  [16, 1, 18, 9, 19, 14, 1, 19, 9, 15, 14, 1, 12...  \n",
       "99978  [25, 1, 14, 7, 2, 1, 18, 5, 12, 4, 1, 14, 7, 1...  \n",
       "99979  [12, 1, 16, 15, 18, 4, 9, 25, 1, 14, 7, 12, 1,...  \n",
       "99980  [14, 5, 23, 3, 1, 19, 20, 12, 5, 20, 5, 18, 21...  \n",
       "99981  [2, 5, 18, 11, 21, 1, 12, 9, 20, 1, 19, 2, 5, ...  \n",
       "99982  [8, 15, 20, 5, 12, 16, 5, 13, 5, 18, 9, 11, 19...  \n",
       "99983  [2, 1, 18, 9, 19, 1, 14, 19, 1, 1, 20, 22, 1, ...  \n",
       "99984  [25, 1, 14, 7, 13, 5, 13, 16, 5, 11, 5, 18, 10...  \n",
       "99985  [4, 5, 14, 7, 1, 14, 21, 14, 20, 21, 11, 11, 2...  \n",
       "99986  [13, 5, 12, 5, 13, 1, 8, 2, 5, 18, 14, 1, 13, ...  \n",
       "99987  [4, 5, 13, 9, 11, 9, 1, 14, 2, 5, 18, 4, 1, 19...  \n",
       "99988  [12, 1, 12, 21, 2, 5, 18, 11, 1, 19, 19, 5, 11...  \n",
       "99989  [13, 5, 14, 10, 1, 4, 9, 1, 18, 9, 6, 9, 14, 2...  \n",
       "99990  [4, 9, 19, 5, 19, 21, 1, 9, 11, 1, 14, 4, 1, 1...  \n",
       "99991  [18, 16, 3, 21, 11, 21, 16, 11, 5, 10, 1, 4, 9...  \n",
       "99992  [8, 9, 7, 21, 1, 9, 14, 1, 11, 1, 14, 13, 9, 1...  \n",
       "99993  [13, 1, 19, 21, 11, 23, 8, 5, 14, 18, 5, 19, 1...  \n",
       "99994  [12, 1, 7, 9, 11, 1, 18, 5, 14, 1, 13, 5, 14, ...  \n",
       "99995  [5, 24, 20, 5, 18, 14, 1, 12, 4, 1, 14, 13, 5,...  \n",
       "99996  [25, 1, 14, 7, 19, 20, 1, 14, 4, 2, 25, 4, 9, ...  \n",
       "99997  [1, 19, 9, 14, 7, 10, 21, 7, 1, 19, 21, 14, 4,...  \n",
       "99998  [11, 5, 13, 5, 14, 8, 21, 2, 13, 5, 14, 10, 1,...  \n",
       "99999  [4, 9, 7, 9, 20, 1, 12, 12, 1, 14, 7, 11, 1, 8...  \n",
       "\n",
       "[100000 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_data_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, data):\n",
    "        row, col = data.shape\n",
    "        train = data.loc[:int(row*.8)]\n",
    "        test = data.loc[int(row*.8):]\n",
    "        train.reset_index(drop=True, inplace=True)\n",
    "        test.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        self.lookup = {\n",
    "            'train': (train, len(train)),\n",
    "            'test': (test, len(test))\n",
    "        }\n",
    "        \n",
    "        self.set_split('train')\n",
    "        \n",
    "    def set_split(self, split = 'train'):\n",
    "        self.data, self.length = self.lookup[split]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X = self.data.loc[index, 'source_array']\n",
    "        X = torch.LongTensor(X)\n",
    "        \n",
    "        \n",
    "        y = np.array(list(self.data.loc[index, 'flag_space'])).astype(int)\n",
    "        y = torch.Tensor(y).squeeze(0)\n",
    "        \n",
    "        return {'x': X,\n",
    "               'y': y}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, embedding_dim = 20):\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(len(char2idx), embedding_dim=embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, 256)\n",
    "        \n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 16)\n",
    "        self.fc5 = nn.Linear(16, 1)\n",
    "        \n",
    "        self.relu6 = nn.ReLU6()\n",
    "        \n",
    "        \n",
    "    def forward(self, input_, apply_sigmoid=False):\n",
    "        \n",
    "        X = self.embed(torch.LongTensor(input_))\n",
    "        X, _ = self.lstm(X)\n",
    "        X = self.fc1(X)\n",
    "        X = self.fc2(X)\n",
    "        X = self.fc3(X)\n",
    "        X = self.fc4(X)\n",
    "        X = self.fc5(X)\n",
    "        \n",
    "        if apply_sigmoid:\n",
    "            X = torch.sigmoid(X)\n",
    "        \n",
    "        y_pred = X.squeeze(2)    \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y_true, y_pred):\n",
    "    y_true = y_true.long().numpy()\n",
    "    y_pred = (y_pred > 0.5).long().numpy()\n",
    "    try:\n",
    "#         hamming_score = hamming_loss(y_true, y_pred)\n",
    "#         return 1 - hamming_score\n",
    "        return (y_true == y_pred).all(axis = 1).mean()\n",
    "    except:\n",
    "        print(\"y_true\", y_true, \"y_pred\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(d_data_selected)\n",
    "classifier = Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.BCEWithLogitsLoss(reduction= 'sum')\n",
    "optimizer = optim.Adam(classifier.parameters(), lr = 0.001, weight_decay=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict ={\n",
    "    'acc_train': [],\n",
    "    'acc_test': [],\n",
    "    'loss_train': [],\n",
    "    'loss_test': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 sec | epoch 0 loss train: 24.71 accuracy train: 0.00 loss val 23.86 accuracy val 0.00\n",
      "0.02 sec | epoch 1 loss train: 23.23 accuracy train: 0.00 loss val 22.70 accuracy val 0.00\n",
      "0.02 sec | epoch 2 loss train: 21.63 accuracy train: 0.00 loss val 21.71 accuracy val 0.00\n",
      "0.01 sec | epoch 3 loss train: 20.01 accuracy train: 0.00 loss val 21.11 accuracy val 0.00\n",
      "0.02 sec | epoch 4 loss train: 18.49 accuracy train: 0.00 loss val 21.11 accuracy val 0.00\n",
      "0.01 sec | epoch 5 loss train: 17.22 accuracy train: 0.00 loss val 21.81 accuracy val 0.00\n",
      "0.01 sec | epoch 6 loss train: 16.26 accuracy train: 0.00 loss val 23.18 accuracy val 0.00\n",
      "0.01 sec | epoch 7 loss train: 15.58 accuracy train: 0.00 loss val 24.99 accuracy val 0.00\n",
      "0.01 sec | epoch 8 loss train: 15.01 accuracy train: 0.00 loss val 26.98 accuracy val 0.00\n",
      "0.01 sec | epoch 9 loss train: 14.37 accuracy train: 0.00 loss val 28.92 accuracy val 0.00\n",
      "0.01 sec | epoch 10 loss train: 13.55 accuracy train: 0.00 loss val 30.69 accuracy val 0.00\n",
      "0.01 sec | epoch 11 loss train: 12.54 accuracy train: 0.00 loss val 32.30 accuracy val 0.00\n",
      "0.01 sec | epoch 12 loss train: 11.43 accuracy train: 0.00 loss val 33.83 accuracy val 0.00\n",
      "0.01 sec | epoch 13 loss train: 10.38 accuracy train: 0.00 loss val 35.40 accuracy val 0.00\n",
      "0.01 sec | epoch 14 loss train: 9.56 accuracy train: 0.00 loss val 37.12 accuracy val 0.00\n",
      "0.02 sec | epoch 15 loss train: 8.98 accuracy train: 0.00 loss val 39.02 accuracy val 0.00\n",
      "0.02 sec | epoch 16 loss train: 8.53 accuracy train: 0.00 loss val 41.10 accuracy val 0.00\n",
      "0.02 sec | epoch 17 loss train: 8.05 accuracy train: 0.00 loss val 43.35 accuracy val 0.00\n",
      "0.01 sec | epoch 18 loss train: 7.42 accuracy train: 0.00 loss val 45.82 accuracy val 0.00\n",
      "0.01 sec | epoch 19 loss train: 6.64 accuracy train: 0.00 loss val 48.59 accuracy val 0.00\n",
      "0.01 sec | epoch 20 loss train: 5.79 accuracy train: 0.00 loss val 51.78 accuracy val 0.00\n",
      "0.01 sec | epoch 21 loss train: 4.95 accuracy train: 0.50 loss val 55.49 accuracy val 0.00\n",
      "0.01 sec | epoch 22 loss train: 4.20 accuracy train: 0.50 loss val 59.79 accuracy val 0.00\n",
      "0.01 sec | epoch 23 loss train: 3.57 accuracy train: 0.50 loss val 64.74 accuracy val 0.00\n",
      "0.01 sec | epoch 24 loss train: 3.06 accuracy train: 0.50 loss val 70.29 accuracy val 0.00\n",
      "0.01 sec | epoch 25 loss train: 2.66 accuracy train: 0.50 loss val 76.36 accuracy val 0.00\n",
      "0.01 sec | epoch 26 loss train: 2.35 accuracy train: 0.50 loss val 82.84 accuracy val 0.00\n",
      "0.01 sec | epoch 27 loss train: 2.12 accuracy train: 0.50 loss val 89.57 accuracy val 0.00\n",
      "0.01 sec | epoch 28 loss train: 1.96 accuracy train: 0.50 loss val 96.36 accuracy val 0.00\n",
      "0.01 sec | epoch 29 loss train: 1.84 accuracy train: 0.50 loss val 103.06 accuracy val 0.00\n",
      "0.01 sec | epoch 30 loss train: 1.74 accuracy train: 0.50 loss val 109.58 accuracy val 0.00\n",
      "0.01 sec | epoch 31 loss train: 1.64 accuracy train: 0.50 loss val 115.90 accuracy val 0.00\n",
      "0.02 sec | epoch 32 loss train: 1.56 accuracy train: 0.50 loss val 122.10 accuracy val 0.00\n",
      "0.02 sec | epoch 33 loss train: 1.53 accuracy train: 0.50 loss val 128.26 accuracy val 0.00\n",
      "0.02 sec | epoch 34 loss train: 1.52 accuracy train: 0.50 loss val 134.43 accuracy val 0.00\n",
      "0.01 sec | epoch 35 loss train: 1.49 accuracy train: 0.50 loss val 140.60 accuracy val 0.00\n",
      "0.01 sec | epoch 36 loss train: 1.45 accuracy train: 0.50 loss val 146.70 accuracy val 0.00\n",
      "0.02 sec | epoch 37 loss train: 1.44 accuracy train: 0.50 loss val 152.52 accuracy val 0.00\n",
      "0.02 sec | epoch 38 loss train: 1.45 accuracy train: 0.50 loss val 157.92 accuracy val 0.00\n",
      "0.02 sec | epoch 39 loss train: 1.44 accuracy train: 0.50 loss val 162.86 accuracy val 0.00\n",
      "0.02 sec | epoch 40 loss train: 1.41 accuracy train: 0.50 loss val 167.51 accuracy val 0.00\n",
      "0.02 sec | epoch 41 loss train: 1.41 accuracy train: 0.50 loss val 172.05 accuracy val 0.00\n",
      "0.01 sec | epoch 42 loss train: 1.42 accuracy train: 0.50 loss val 176.52 accuracy val 0.00\n",
      "0.01 sec | epoch 43 loss train: 1.40 accuracy train: 0.50 loss val 180.84 accuracy val 0.00\n",
      "0.02 sec | epoch 44 loss train: 1.40 accuracy train: 0.50 loss val 184.79 accuracy val 0.00\n",
      "0.02 sec | epoch 45 loss train: 1.40 accuracy train: 0.50 loss val 188.18 accuracy val 0.00\n",
      "0.21 sec | epoch 46 loss train: 1.40 accuracy train: 0.50 loss val 191.09 accuracy val 0.00\n",
      "0.01 sec | epoch 47 loss train: 1.39 accuracy train: 0.50 loss val 193.75 accuracy val 0.00\n",
      "0.02 sec | epoch 48 loss train: 1.40 accuracy train: 0.50 loss val 196.37 accuracy val 0.00\n",
      "0.01 sec | epoch 49 loss train: 1.40 accuracy train: 0.50 loss val 198.93 accuracy val 0.00\n",
      "0.01 sec | epoch 50 loss train: 1.39 accuracy train: 0.50 loss val 201.27 accuracy val 0.00\n",
      "0.01 sec | epoch 51 loss train: 1.39 accuracy train: 0.50 loss val 203.18 accuracy val 0.00\n",
      "0.01 sec | epoch 52 loss train: 1.39 accuracy train: 0.50 loss val 204.70 accuracy val 0.00\n",
      "0.02 sec | epoch 53 loss train: 1.39 accuracy train: 0.50 loss val 206.06 accuracy val 0.00\n",
      "0.02 sec | epoch 54 loss train: 1.39 accuracy train: 0.50 loss val 207.43 accuracy val 0.00\n",
      "0.03 sec | epoch 55 loss train: 1.39 accuracy train: 0.50 loss val 208.81 accuracy val 0.00\n",
      "0.02 sec | epoch 56 loss train: 1.39 accuracy train: 0.50 loss val 210.00 accuracy val 0.00\n",
      "0.02 sec | epoch 57 loss train: 1.39 accuracy train: 0.50 loss val 210.87 accuracy val 0.00\n",
      "0.02 sec | epoch 58 loss train: 1.39 accuracy train: 0.50 loss val 211.51 accuracy val 0.00\n",
      "0.03 sec | epoch 59 loss train: 1.39 accuracy train: 0.50 loss val 212.11 accuracy val 0.00\n",
      "0.02 sec | epoch 60 loss train: 1.39 accuracy train: 0.50 loss val 212.77 accuracy val 0.00\n",
      "0.03 sec | epoch 61 loss train: 1.39 accuracy train: 0.50 loss val 213.41 accuracy val 0.00\n",
      "0.01 sec | epoch 62 loss train: 1.39 accuracy train: 0.50 loss val 213.87 accuracy val 0.00\n",
      "0.02 sec | epoch 63 loss train: 1.39 accuracy train: 0.50 loss val 214.11 accuracy val 0.00\n",
      "0.01 sec | epoch 64 loss train: 1.39 accuracy train: 0.50 loss val 214.26 accuracy val 0.00\n",
      "0.02 sec | epoch 65 loss train: 1.39 accuracy train: 0.50 loss val 214.47 accuracy val 0.00\n",
      "0.01 sec | epoch 66 loss train: 1.39 accuracy train: 0.50 loss val 214.72 accuracy val 0.00\n",
      "0.02 sec | epoch 67 loss train: 1.39 accuracy train: 0.50 loss val 214.90 accuracy val 0.00\n",
      "0.02 sec | epoch 68 loss train: 1.39 accuracy train: 0.50 loss val 214.91 accuracy val 0.00\n",
      "0.02 sec | epoch 69 loss train: 1.39 accuracy train: 0.50 loss val 214.82 accuracy val 0.00\n",
      "0.02 sec | epoch 70 loss train: 1.39 accuracy train: 0.50 loss val 214.77 accuracy val 0.00\n",
      "0.03 sec | epoch 71 loss train: 1.39 accuracy train: 0.50 loss val 214.78 accuracy val 0.00\n",
      "0.01 sec | epoch 72 loss train: 1.39 accuracy train: 0.50 loss val 214.77 accuracy val 0.00\n",
      "0.02 sec | epoch 73 loss train: 1.39 accuracy train: 0.50 loss val 214.64 accuracy val 0.00\n",
      "0.02 sec | epoch 74 loss train: 1.39 accuracy train: 0.50 loss val 214.43 accuracy val 0.00\n",
      "0.02 sec | epoch 75 loss train: 1.39 accuracy train: 0.50 loss val 214.23 accuracy val 0.00\n",
      "0.01 sec | epoch 76 loss train: 1.39 accuracy train: 0.50 loss val 214.10 accuracy val 0.00\n",
      "0.01 sec | epoch 77 loss train: 1.39 accuracy train: 0.50 loss val 213.98 accuracy val 0.00\n",
      "0.01 sec | epoch 78 loss train: 1.39 accuracy train: 0.50 loss val 213.77 accuracy val 0.00\n",
      "0.01 sec | epoch 79 loss train: 1.39 accuracy train: 0.50 loss val 213.50 accuracy val 0.00\n",
      "0.01 sec | epoch 80 loss train: 1.39 accuracy train: 0.50 loss val 213.24 accuracy val 0.00\n",
      "0.01 sec | epoch 81 loss train: 1.39 accuracy train: 0.50 loss val 213.04 accuracy val 0.00\n",
      "0.01 sec | epoch 82 loss train: 1.39 accuracy train: 0.50 loss val 212.85 accuracy val 0.00\n",
      "0.01 sec | epoch 83 loss train: 1.39 accuracy train: 0.50 loss val 212.61 accuracy val 0.00\n",
      "0.02 sec | epoch 84 loss train: 1.39 accuracy train: 0.50 loss val 212.31 accuracy val 0.00\n",
      "0.02 sec | epoch 85 loss train: 1.39 accuracy train: 0.50 loss val 212.03 accuracy val 0.00\n",
      "0.01 sec | epoch 86 loss train: 1.39 accuracy train: 0.50 loss val 211.80 accuracy val 0.00\n",
      "0.02 sec | epoch 87 loss train: 1.39 accuracy train: 0.50 loss val 211.59 accuracy val 0.00\n",
      "0.01 sec | epoch 88 loss train: 1.39 accuracy train: 0.50 loss val 211.33 accuracy val 0.00\n",
      "0.01 sec | epoch 89 loss train: 1.39 accuracy train: 0.50 loss val 211.05 accuracy val 0.00\n",
      "0.01 sec | epoch 90 loss train: 1.39 accuracy train: 0.50 loss val 210.77 accuracy val 0.00\n",
      "0.01 sec | epoch 91 loss train: 1.39 accuracy train: 0.50 loss val 210.55 accuracy val 0.00\n",
      "0.01 sec | epoch 92 loss train: 1.39 accuracy train: 0.50 loss val 210.33 accuracy val 0.00\n",
      "0.01 sec | epoch 93 loss train: 1.39 accuracy train: 0.50 loss val 210.08 accuracy val 0.00\n",
      "0.01 sec | epoch 94 loss train: 1.39 accuracy train: 0.50 loss val 209.82 accuracy val 0.00\n",
      "0.01 sec | epoch 95 loss train: 1.39 accuracy train: 0.50 loss val 209.57 accuracy val 0.00\n",
      "0.01 sec | epoch 96 loss train: 1.39 accuracy train: 0.50 loss val 209.36 accuracy val 0.00\n",
      "0.01 sec | epoch 97 loss train: 1.39 accuracy train: 0.50 loss val 209.16 accuracy val 0.00\n",
      "0.01 sec | epoch 98 loss train: 1.39 accuracy train: 0.50 loss val 208.93 accuracy val 0.00\n",
      "0.01 sec | epoch 99 loss train: 1.39 accuracy train: 0.50 loss val 208.69 accuracy val 0.00\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    \n",
    "    running_loss = 0\n",
    "    running_acc = 0\n",
    "    running_loss_val = 0\n",
    "    running_acc_val = 0\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    classifier.train()\n",
    "    dataset.set_split('train')\n",
    "    data_generator = DataLoader(dataset=dataset, batch_size=2, shuffle=False)\n",
    "    for batch_index, batch_dict in enumerate(data_generator, 1):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = classifier(batch_dict['x'])\n",
    "        \n",
    "        loss_train = loss_func(y_pred, batch_dict['y'])\n",
    "        loss_item = loss_train.item()\n",
    "        running_loss += (loss_item - running_loss) / batch_index\n",
    "        \n",
    "        loss_train.backward()\n",
    "        \n",
    "        accuracy_score = compute_accuracy(batch_dict['y'], y_pred)\n",
    "        running_acc += (accuracy_score - running_acc) / batch_index\n",
    "        \n",
    "        optimizer.step()\n",
    "        break\n",
    "        \n",
    "    classifier.eval()\n",
    "    dataset.set_split('test')\n",
    "    data_generator = DataLoader(dataset=dataset, batch_size=2, shuffle=False)\n",
    "    for batch_index, batch_dict in enumerate(data_generator, 1):\n",
    "        \n",
    "        y_pred = classifier(batch_dict['x'])\n",
    "        \n",
    "        loss_train_val = loss_func(y_pred, batch_dict['y'])\n",
    "        loss_item_val = loss_train_val.item()\n",
    "        running_loss_val += (loss_item_val - running_loss_val) / batch_index\n",
    "        \n",
    "        accuracy_score_val = compute_accuracy(batch_dict['y'], y_pred)\n",
    "        running_acc_val += (accuracy_score_val - running_acc_val) / batch_index\n",
    "        break\n",
    "        \n",
    "    history_dict['acc_train'].append(running_acc)\n",
    "    history_dict['acc_test'].append(running_acc_val)\n",
    "    history_dict['loss_train'].append(running_loss)\n",
    "    history_dict['loss_test'].append(running_loss_val)\n",
    "    \n",
    "    print(\"{:.2f} sec | epoch {} loss train: {:.2f} accuracy train: {:.2f} loss val {:.2f} accuracy val {:.2f}\".format(\n",
    "        time.time() - start, epoch, running_loss, running_acc, running_loss_val, running_acc_val\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 4.8660e-01, -1.4273e+00, -3.9109e-01,  4.0494e-01, -9.1139e-01,\n",
       "           8.0464e-02,  5.7828e-01, -1.4386e+00,  1.2356e+00, -5.3794e-01,\n",
       "           1.3258e+00,  7.9231e-01, -9.2269e-01,  1.8320e+00, -1.6268e+00,\n",
       "           2.9007e-01,  6.1937e-01,  5.1852e-01, -1.4722e+00,  1.8639e-01],\n",
       "         [ 1.2861e+00,  1.2190e+00,  1.8201e+00,  7.4567e-01,  5.8241e-01,\n",
       "           1.1132e+00,  1.2453e+00, -4.1103e-01,  1.1133e-01, -7.0772e-01,\n",
       "          -1.8388e+00, -3.8734e-01, -4.4801e-01,  8.9586e-01, -4.5137e-02,\n",
       "           6.1876e-01,  8.5535e-01, -3.4143e-01, -5.3053e-01,  1.8461e-01],\n",
       "         [ 5.4632e-01, -2.5116e-01, -1.0225e-01, -2.4044e+00,  3.1527e-03,\n",
       "           3.0873e-01,  4.9218e-01, -5.3592e-02, -5.3087e-01, -4.3339e-01,\n",
       "          -6.5787e-01, -1.2070e-04,  5.0195e-01,  2.1899e-01,  1.5569e-01,\n",
       "          -5.7083e-03, -5.9674e-01,  4.5279e-01,  7.7093e-01, -7.3761e-01]],\n",
       "\n",
       "        [[ 1.2861e+00,  1.2190e+00,  1.8201e+00,  7.4567e-01,  5.8241e-01,\n",
       "           1.1132e+00,  1.2453e+00, -4.1103e-01,  1.1133e-01, -7.0772e-01,\n",
       "          -1.8388e+00, -3.8734e-01, -4.4801e-01,  8.9586e-01, -4.5137e-02,\n",
       "           6.1876e-01,  8.5535e-01, -3.4143e-01, -5.3053e-01,  1.8461e-01],\n",
       "         [ 4.8660e-01, -1.4273e+00, -3.9109e-01,  4.0494e-01, -9.1139e-01,\n",
       "           8.0464e-02,  5.7828e-01, -1.4386e+00,  1.2356e+00, -5.3794e-01,\n",
       "           1.3258e+00,  7.9231e-01, -9.2269e-01,  1.8320e+00, -1.6268e+00,\n",
       "           2.9007e-01,  6.1937e-01,  5.1852e-01, -1.4722e+00,  1.8639e-01],\n",
       "         [-1.7220e+00, -8.3350e-01, -1.8331e-01,  4.6039e-01,  1.1989e+00,\n",
       "          -6.6488e-01,  2.6420e-01, -1.2578e+00,  2.9815e-01, -7.4274e-01,\n",
       "           1.7939e+00, -7.9185e-01, -1.7765e+00, -1.0488e+00, -1.3405e+00,\n",
       "           3.9565e-01, -7.1993e-01,  2.9633e-01, -1.4329e+00,  6.1433e-01]]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ = torch.LongTensor([[1,2,3], [2,1,5]])\n",
    "classifier.embed(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.7449e+01, -8.3835e+00, -1.6090e+01, -2.2077e+01, -3.8136e+01,\n",
       "         -2.4636e+01,  1.2522e+01, -2.7113e+01, -3.2307e+01, -2.0129e+01,\n",
       "         -2.3182e+01, -3.2307e+01, -2.4636e+01, -2.7113e+01, -2.2077e+01,\n",
       "          9.8977e-03, -8.7397e+00, -2.2077e+01, -1.6090e+01,  8.0307e+00,\n",
       "         -2.3182e+01, -2.2077e+01, -1.7449e+01, -3.8136e+01,  9.8974e-03],\n",
       "        [-9.3182e+00, -2.2133e+01, -2.8868e+01, -5.1900e+01, -6.2045e+01,\n",
       "          7.5745e+00, -2.0811e+01, -3.1158e+01, -3.2465e+01, -1.7134e+01,\n",
       "         -1.4039e+01, -5.6891e+01,  1.7777e+01, -2.3491e+01, -6.3611e+01,\n",
       "         -3.1712e+01,  1.0811e+01, -4.1056e+01, -1.1687e+01, -1.4991e+01,\n",
       "          7.8552e+00, -3.4989e+01, -4.6718e+01, -8.8989e+00, -4.8360e+01],\n",
       "        [-3.6548e+01, -3.4705e+01,  8.1868e+00, -8.4629e+01, -5.8451e+01,\n",
       "          1.6760e+01, -5.5066e+01, -3.0558e+01, -6.8844e+01, -2.7102e+00,\n",
       "          9.8869e+00, -3.9163e+01,  3.2254e+00, -5.2668e+01, -6.6486e+01,\n",
       "         -3.2217e+01, -1.7773e+01, -5.0100e+01, -3.3890e+01,  1.1734e+01,\n",
       "         -2.1392e+01, -5.7128e+01, -3.6646e+01, -2.2596e+01, -6.1321e+01],\n",
       "        [-3.3629e+01, -7.4726e+01,  2.8897e+01, -1.0122e+02, -6.9152e+01,\n",
       "         -8.3127e+00, -5.3316e+01, -5.0801e+01, -3.8386e+01, -9.4885e+00,\n",
       "          2.1168e+01, -9.9558e+00, -1.2980e+01, -4.2436e+01, -1.3890e+01,\n",
       "         -4.9635e+01,  1.7288e+01, -8.7067e+01, -3.7895e+01, -2.8252e+01,\n",
       "         -1.3258e+01, -3.3326e+01, -6.0361e+01, -5.4069e+01, -6.3609e+01]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.forward(torch.LongTensor(d_data_selected.loc[:3,'source_array']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-17.4492,  -8.3835, -38.1356, -24.6365, -27.1131, -38.1356, -20.1295,\n",
       "         -38.1356, -24.6365,   8.0307, -38.1356, -23.1820, -32.3073,  -2.1816,\n",
       "         -32.3073, -20.1295, -27.1131,  -8.3835,   2.2755, -32.3073, -10.4547,\n",
       "         -38.1356,  -8.4017, -38.1356, -24.6365],\n",
       "        [ -9.3182, -51.3102, -40.8702, -13.8582, -31.9202, -62.0448,  -1.5324,\n",
       "         -27.2404,   8.8628,  -0.8441, -42.7364, -17.7895, -16.1475, -13.7734,\n",
       "         -39.5886,  25.2888, -11.6049, -51.3102,  11.8879, -29.8764, -24.1528,\n",
       "         -44.2644, -35.6312, -27.2404,  11.8173]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_dict['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(208.6944, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(y_pred, batch_dict['y'], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_dict['loss_train'])\n",
    "plt.plot(history_dict['loss_test'])\n",
    "plt.ylim(0.0, 1.0)\n",
    "plt.savefig('../reports/20190916.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = classifier(data['x'].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
