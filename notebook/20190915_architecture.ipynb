{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open(os.path.join('../data/clean/data_clean_100k.res'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_data['source_len']= d_data.source.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_data_selected = d_data[d_data['source_len'] == MAX_LENGTH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_data_selected.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2char = dict((idx, c) for idx, c in enumerate(\"abcdefghijklmnopqrstuvwxyz\", 1))\n",
    "char2idx = dict((c, idx) for idx, c in enumerate(\"abcdefghijklmnopqrstuvwxyz\", 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2char[0] = '<UNK>'\n",
    "char2idx['<UNK>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_vectorizer(list_inputs, char_indices):\n",
    "    x = np.zeros((len([list_inputs]), MAX_LENGTH, len(char_indices)))\n",
    "    for i, input_ in enumerate([list_inputs]):\n",
    "        for t, char in enumerate(input_):\n",
    "            x[i, t, char_indices[char]] = 1\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flag_space(sentence):\n",
    "    \n",
    "    no_space = []\n",
    "    flag_space = []\n",
    "    sentence = str(sentence)\n",
    "    for char in sentence: \n",
    "        if char != ' ':\n",
    "            no_space.append(char)\n",
    "            flag_space.append('0')\n",
    "        elif char == ' ':\n",
    "            flag_space[-1] = '1'\n",
    "            \n",
    "    no_space = ''.join(no_space)\n",
    "    flag_space = ''.join(flag_space)\n",
    "    \n",
    "    return flag_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_vectorizer(list_inputs, char_indices):\n",
    "    x = np.zeros((len([list_inputs]), MAX_LENGTH, len(char_indices)))\n",
    "    for i, input_ in enumerate([list_inputs]):\n",
    "        for t, char in enumerate(input_):\n",
    "            try:\n",
    "                x[i, t, char_indices[char]] = 1\n",
    "            except:\n",
    "                x[i, t, 0] = 1\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andreas Chandra\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "d_data_selected['flag_space'] = d_data_selected['target'].apply(get_flag_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andreas Chandra\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\Andreas Chandra\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "d_data_selected.loc[:, 'matrix'] = d_data_selected.loc[:, 'source'].apply(char_vectorizer, args=(char2idx,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, data):\n",
    "        row, col = data.shape\n",
    "        train = data.loc[:int(row*.8)]\n",
    "        test = data.loc[int(row*.8):]\n",
    "        train.reset_index(drop=True, inplace=True)\n",
    "        test.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        self.lookup = {\n",
    "            'train': (train, len(train)),\n",
    "            'test': (test, len(test))\n",
    "        }\n",
    "        \n",
    "        self.set_split('train')\n",
    "        \n",
    "    def set_split(self, split = 'train'):\n",
    "        self.data, self.length = self.lookup[split]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X = self.data.loc[index, 'matrix']\n",
    "        X = torch.Tensor(X).squeeze(0)\n",
    "        \n",
    "        y = np.array(list(self.data.loc[index, 'flag_space'])).astype(int)\n",
    "        y = torch.Tensor(y).squeeze(0)\n",
    "        \n",
    "        return {'x': X,\n",
    "               'y': y}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(len(char2idx), 256)\n",
    "        \n",
    "        self.fc = nn.Linear(256, 1)\n",
    "        \n",
    "    def forward(self, input_, apply_sigmoid=False):\n",
    "        \n",
    "        y_pred, _ = self.lstm(input_)\n",
    "        y_pred = self.fc(y_pred)\n",
    "        \n",
    "        if apply_sigmoid:\n",
    "            y_pred = torch.sigmoid(y_pred)\n",
    "        \n",
    "        y_pred = y_pred.squeeze(2)    \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(d_data_selected)\n",
    "classifier = Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_loss = 0\n",
    "running_acc = 0\n",
    "running_loss_val = 0\n",
    "running_acc_val = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    classifier.eval()\n",
    "    data_generator = DataLoader(dataset=dataset, batch_size=2, shuffle=True)\n",
    "    for batch_index, batch_dict in enumerate(data_generator, 1):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = classifier(batch_dict['x'])\n",
    "        \n",
    "        loss_train = loss_func(y_pred, batch_dict['y'])\n",
    "        loss_item = loss_train.item()\n",
    "        \n",
    "        accuracy_score = accuracy(batch_dict['y'], y_pred)\n",
    "        \n",
    "        running_loss += (running_loss - loss_item) / batch_index\n",
    "        \n",
    "        loss_train.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred > 0.5).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "col, row = y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col * row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_dict['y'].long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eq((y_pred > 0.5).long(), batch_dict['y'].long()).sum().item() / (col * row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
