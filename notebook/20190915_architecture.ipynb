{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open(os.path.join('../data/clean/data_clean_100k.res'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_data['source_len']= d_data.source.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_data_selected = d_data[d_data['source_len'] == MAX_LENGTH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_data_selected.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2char = dict((idx, c) for idx, c in enumerate(\"abcdefghijklmnopqrstuvwxyz\", 1))\n",
    "char2idx = dict((c, idx) for idx, c in enumerate(\"abcdefghijklmnopqrstuvwxyz\", 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2char[0] = '<UNK>'\n",
    "char2idx['<UNK>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_vectorizer(list_inputs, char_indices):\n",
    "    x = np.zeros((len([list_inputs]), MAX_LENGTH, len(char_indices)))\n",
    "    for i, input_ in enumerate([list_inputs]):\n",
    "        for t, char in enumerate(input_):\n",
    "            x[i, t, char_indices[char]] = 1\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flag_space(sentence):\n",
    "    \n",
    "    no_space = []\n",
    "    flag_space = []\n",
    "    sentence = str(sentence)\n",
    "    for char in sentence: \n",
    "        if char != ' ':\n",
    "            no_space.append(char)\n",
    "            flag_space.append('0')\n",
    "        elif char == ' ':\n",
    "            flag_space[-1] = '1'\n",
    "            \n",
    "    no_space = ''.join(no_space)\n",
    "    flag_space = ''.join(flag_space)\n",
    "    \n",
    "    return flag_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_vectorizer(list_inputs, char_indices):\n",
    "    x = np.zeros((len([list_inputs]), MAX_LENGTH, len(char_indices)))\n",
    "    for i, input_ in enumerate([list_inputs]):\n",
    "        for t, char in enumerate(input_):\n",
    "            try:\n",
    "                x[i, t, char_indices[char]] = 1\n",
    "            except:\n",
    "                x[i, t, 0] = 1\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_space_to_list(flag):\n",
    "    return np.array(list(flag)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andreas Chandra\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "d_data_selected['flag_space'] = d_data_selected['target'].apply(get_flag_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andreas Chandra\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\Andreas Chandra\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "d_data_selected.loc[:, 'matrix'] = d_data_selected.loc[:, 'source'].apply(char_vectorizer, args=(char2idx,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andreas Chandra\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "d_data_selected['flag_space_array'] = d_data_selected.flag_space.apply(flag_space_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andreas Chandra\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "d_data_selected['flag_space_sum'] = d_data_selected.flag_space_array.apply(np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, data):\n",
    "        row, col = data.shape\n",
    "        train = data.loc[:int(row*.8)]\n",
    "        test = data.loc[int(row*.8):]\n",
    "        train.reset_index(drop=True, inplace=True)\n",
    "        test.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        self.lookup = {\n",
    "            'train': (train, len(train)),\n",
    "            'test': (test, len(test))\n",
    "        }\n",
    "        \n",
    "        self.set_split('train')\n",
    "        \n",
    "    def set_split(self, split = 'train'):\n",
    "        self.data, self.length = self.lookup[split]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X = self.data.loc[index, 'matrix']\n",
    "        X = torch.Tensor(X).squeeze(0)\n",
    "        \n",
    "        y = np.array(list(self.data.loc[index, 'flag_space'])).astype(int)\n",
    "        y = torch.Tensor(y).squeeze(0)\n",
    "        \n",
    "        return {'x': X,\n",
    "               'y': y}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(len(char2idx), 256)\n",
    "        \n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 16)\n",
    "        self.fc5 = nn.Linear(16, 1)\n",
    "        \n",
    "    def forward(self, input_, apply_sigmoid=False):\n",
    "        \n",
    "        y_pred, _ = self.lstm(input_)\n",
    "        y_pred, _ = self.lstm(input_, _)\n",
    "        y_pred = self.fc1(y_pred)\n",
    "        y_pred = self.fc2(y_pred)\n",
    "        y_pred = self.fc3(y_pred)\n",
    "        y_pred = self.fc4(y_pred)\n",
    "        y_pred = self.fc5(y_pred)\n",
    "        \n",
    "        if apply_sigmoid:\n",
    "            y_pred = torch.sigmoid(y_pred)\n",
    "        \n",
    "        y_pred = y_pred.squeeze(2)    \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y_true, y_pred):\n",
    "    y_true = y_true.long().numpy()\n",
    "    y_pred = (y_pred > 0.5).long().numpy()\n",
    "    try:\n",
    "        hamming_score = hamming_loss(y_true, y_pred)\n",
    "        return 1 - hamming_score\n",
    "    except:\n",
    "        print(\"y_true\", y_true, \"y_pred\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(d_data_selected)\n",
    "classifier = Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr = 0.001, weight_decay=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict ={\n",
    "    'acc_train': [],\n",
    "    'acc_test': [],\n",
    "    'loss_train': [],\n",
    "    'loss_test': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06 sec | epoch 0 loss train: 0.44 accuracy train: 0.84 loss val 0.35 accuracy val 0.88\n",
      "0.06 sec | epoch 1 loss train: 0.34 accuracy train: 0.90 loss val 0.50 accuracy val 0.80\n",
      "0.06 sec | epoch 2 loss train: 0.43 accuracy train: 0.84 loss val 0.47 accuracy val 0.82\n",
      "0.06 sec | epoch 3 loss train: 0.40 accuracy train: 0.86 loss val 0.45 accuracy val 0.84\n",
      "0.07 sec | epoch 4 loss train: 0.37 accuracy train: 0.88 loss val 0.43 accuracy val 0.84\n",
      "0.07 sec | epoch 5 loss train: 0.36 accuracy train: 0.88 loss val 0.43 accuracy val 0.84\n",
      "0.07 sec | epoch 6 loss train: 0.41 accuracy train: 0.86 loss val 0.40 accuracy val 0.86\n",
      "0.07 sec | epoch 7 loss train: 0.43 accuracy train: 0.84 loss val 0.46 accuracy val 0.82\n",
      "0.06 sec | epoch 8 loss train: 0.36 accuracy train: 0.88 loss val 0.39 accuracy val 0.86\n",
      "0.06 sec | epoch 9 loss train: 0.38 accuracy train: 0.86 loss val 0.33 accuracy val 0.90\n",
      "0.06 sec | epoch 10 loss train: 0.42 accuracy train: 0.84 loss val 0.37 accuracy val 0.88\n",
      "0.07 sec | epoch 11 loss train: 0.42 accuracy train: 0.84 loss val 0.43 accuracy val 0.84\n",
      "0.06 sec | epoch 12 loss train: 0.40 accuracy train: 0.86 loss val 0.31 accuracy val 0.90\n",
      "0.07 sec | epoch 13 loss train: 0.39 accuracy train: 0.86 loss val 0.38 accuracy val 0.86\n",
      "0.07 sec | epoch 14 loss train: 0.44 accuracy train: 0.84 loss val 0.37 accuracy val 0.86\n",
      "0.06 sec | epoch 15 loss train: 0.35 accuracy train: 0.88 loss val 0.32 accuracy val 0.88\n",
      "0.06 sec | epoch 16 loss train: 0.46 accuracy train: 0.82 loss val 0.39 accuracy val 0.86\n",
      "0.05 sec | epoch 17 loss train: 0.41 accuracy train: 0.86 loss val 0.43 accuracy val 0.84\n",
      "0.05 sec | epoch 18 loss train: 0.40 accuracy train: 0.86 loss val 0.36 accuracy val 0.88\n",
      "0.06 sec | epoch 19 loss train: 0.37 accuracy train: 0.88 loss val 0.43 accuracy val 0.84\n",
      "0.06 sec | epoch 20 loss train: 0.36 accuracy train: 0.88 loss val 0.46 accuracy val 0.82\n",
      "0.06 sec | epoch 21 loss train: 0.40 accuracy train: 0.86 loss val 0.32 accuracy val 0.90\n",
      "0.05 sec | epoch 22 loss train: 0.40 accuracy train: 0.86 loss val 0.40 accuracy val 0.86\n",
      "0.06 sec | epoch 23 loss train: 0.36 accuracy train: 0.88 loss val 0.35 accuracy val 0.88\n",
      "0.06 sec | epoch 24 loss train: 0.38 accuracy train: 0.86 loss val 0.32 accuracy val 0.90\n",
      "0.05 sec | epoch 25 loss train: 0.34 accuracy train: 0.90 loss val 0.38 accuracy val 0.86\n",
      "0.05 sec | epoch 26 loss train: 0.38 accuracy train: 0.86 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 27 loss train: 0.34 accuracy train: 0.88 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 28 loss train: 0.46 accuracy train: 0.84 loss val 0.35 accuracy val 0.88\n",
      "0.06 sec | epoch 29 loss train: 0.35 accuracy train: 0.88 loss val 0.39 accuracy val 0.86\n",
      "0.06 sec | epoch 30 loss train: 0.39 accuracy train: 0.86 loss val 0.37 accuracy val 0.88\n",
      "0.06 sec | epoch 31 loss train: 0.31 accuracy train: 0.90 loss val 0.36 accuracy val 0.88\n",
      "0.07 sec | epoch 32 loss train: 0.38 accuracy train: 0.86 loss val 0.38 accuracy val 0.86\n",
      "0.06 sec | epoch 33 loss train: 0.47 accuracy train: 0.82 loss val 0.32 accuracy val 0.90\n",
      "0.06 sec | epoch 34 loss train: 0.34 accuracy train: 0.88 loss val 0.39 accuracy val 0.88\n",
      "0.06 sec | epoch 35 loss train: 0.33 accuracy train: 0.88 loss val 0.31 accuracy val 0.90\n",
      "0.07 sec | epoch 36 loss train: 0.36 accuracy train: 0.88 loss val 0.47 accuracy val 0.82\n",
      "0.07 sec | epoch 37 loss train: 0.33 accuracy train: 0.90 loss val 0.41 accuracy val 0.84\n",
      "0.06 sec | epoch 38 loss train: 0.43 accuracy train: 0.84 loss val 0.43 accuracy val 0.84\n",
      "0.07 sec | epoch 39 loss train: 0.39 accuracy train: 0.86 loss val 0.40 accuracy val 0.86\n",
      "0.07 sec | epoch 40 loss train: 0.40 accuracy train: 0.86 loss val 0.37 accuracy val 0.88\n",
      "0.06 sec | epoch 41 loss train: 0.44 accuracy train: 0.82 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 42 loss train: 0.35 accuracy train: 0.88 loss val 0.39 accuracy val 0.86\n",
      "0.05 sec | epoch 43 loss train: 0.35 accuracy train: 0.88 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 44 loss train: 0.33 accuracy train: 0.90 loss val 0.38 accuracy val 0.86\n",
      "0.07 sec | epoch 45 loss train: 0.36 accuracy train: 0.88 loss val 0.42 accuracy val 0.84\n",
      "0.07 sec | epoch 46 loss train: 0.37 accuracy train: 0.88 loss val 0.36 accuracy val 0.88\n",
      "0.06 sec | epoch 47 loss train: 0.37 accuracy train: 0.86 loss val 0.35 accuracy val 0.88\n",
      "0.06 sec | epoch 48 loss train: 0.35 accuracy train: 0.88 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 49 loss train: 0.43 accuracy train: 0.84 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 50 loss train: 0.41 accuracy train: 0.86 loss val 0.44 accuracy val 0.84\n",
      "0.06 sec | epoch 51 loss train: 0.36 accuracy train: 0.88 loss val 0.31 accuracy val 0.90\n",
      "0.06 sec | epoch 52 loss train: 0.44 accuracy train: 0.84 loss val 0.34 accuracy val 0.88\n",
      "0.06 sec | epoch 53 loss train: 0.43 accuracy train: 0.84 loss val 0.39 accuracy val 0.86\n",
      "0.06 sec | epoch 54 loss train: 0.41 accuracy train: 0.86 loss val 0.33 accuracy val 0.90\n",
      "0.06 sec | epoch 55 loss train: 0.35 accuracy train: 0.88 loss val 0.32 accuracy val 0.90\n",
      "0.06 sec | epoch 56 loss train: 0.36 accuracy train: 0.88 loss val 0.37 accuracy val 0.88\n",
      "0.06 sec | epoch 57 loss train: 0.34 accuracy train: 0.88 loss val 0.40 accuracy val 0.86\n",
      "0.06 sec | epoch 58 loss train: 0.45 accuracy train: 0.84 loss val 0.32 accuracy val 0.90\n",
      "0.06 sec | epoch 59 loss train: 0.34 accuracy train: 0.88 loss val 0.41 accuracy val 0.84\n",
      "0.06 sec | epoch 60 loss train: 0.41 accuracy train: 0.84 loss val 0.37 accuracy val 0.86\n",
      "0.06 sec | epoch 61 loss train: 0.37 accuracy train: 0.88 loss val 0.33 accuracy val 0.90\n",
      "0.06 sec | epoch 62 loss train: 0.41 accuracy train: 0.86 loss val 0.45 accuracy val 0.82\n",
      "0.06 sec | epoch 63 loss train: 0.34 accuracy train: 0.88 loss val 0.40 accuracy val 0.84\n",
      "0.06 sec | epoch 64 loss train: 0.46 accuracy train: 0.82 loss val 0.37 accuracy val 0.88\n",
      "0.06 sec | epoch 65 loss train: 0.42 accuracy train: 0.86 loss val 0.44 accuracy val 0.84\n",
      "0.06 sec | epoch 66 loss train: 0.44 accuracy train: 0.84 loss val 0.38 accuracy val 0.86\n",
      "0.06 sec | epoch 67 loss train: 0.39 accuracy train: 0.86 loss val 0.35 accuracy val 0.88\n",
      "0.07 sec | epoch 68 loss train: 0.38 accuracy train: 0.86 loss val 0.35 accuracy val 0.88\n",
      "0.06 sec | epoch 69 loss train: 0.38 accuracy train: 0.86 loss val 0.38 accuracy val 0.86\n",
      "0.06 sec | epoch 70 loss train: 0.43 accuracy train: 0.84 loss val 0.46 accuracy val 0.84\n",
      "0.06 sec | epoch 71 loss train: 0.44 accuracy train: 0.84 loss val 0.39 accuracy val 0.86\n",
      "0.07 sec | epoch 72 loss train: 0.47 accuracy train: 0.82 loss val 0.38 accuracy val 0.86\n",
      "0.07 sec | epoch 73 loss train: 0.38 accuracy train: 0.88 loss val 0.35 accuracy val 0.88\n",
      "0.06 sec | epoch 74 loss train: 0.37 accuracy train: 0.88 loss val 0.34 accuracy val 0.90\n",
      "0.05 sec | epoch 75 loss train: 0.40 accuracy train: 0.86 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 76 loss train: 0.34 accuracy train: 0.90 loss val 0.39 accuracy val 0.86\n",
      "0.06 sec | epoch 77 loss train: 0.31 accuracy train: 0.92 loss val 0.36 accuracy val 0.88\n",
      "0.06 sec | epoch 78 loss train: 0.38 accuracy train: 0.86 loss val 0.31 accuracy val 0.90\n",
      "0.05 sec | epoch 79 loss train: 0.38 accuracy train: 0.88 loss val 0.35 accuracy val 0.88\n",
      "0.06 sec | epoch 80 loss train: 0.44 accuracy train: 0.84 loss val 0.46 accuracy val 0.82\n",
      "0.07 sec | epoch 81 loss train: 0.36 accuracy train: 0.88 loss val 0.39 accuracy val 0.86\n",
      "0.06 sec | epoch 82 loss train: 0.27 accuracy train: 0.92 loss val 0.34 accuracy val 0.88\n",
      "0.06 sec | epoch 83 loss train: 0.44 accuracy train: 0.84 loss val 0.34 accuracy val 0.88\n",
      "0.07 sec | epoch 84 loss train: 0.40 accuracy train: 0.86 loss val 0.43 accuracy val 0.86\n",
      "0.06 sec | epoch 85 loss train: 0.44 accuracy train: 0.84 loss val 0.42 accuracy val 0.84\n",
      "0.07 sec | epoch 86 loss train: 0.35 accuracy train: 0.88 loss val 0.36 accuracy val 0.88\n",
      "0.06 sec | epoch 87 loss train: 0.40 accuracy train: 0.86 loss val 0.37 accuracy val 0.88\n",
      "0.06 sec | epoch 88 loss train: 0.43 accuracy train: 0.84 loss val 0.38 accuracy val 0.86\n",
      "0.07 sec | epoch 89 loss train: 0.43 accuracy train: 0.84 loss val 0.36 accuracy val 0.88\n",
      "0.07 sec | epoch 90 loss train: 0.40 accuracy train: 0.86 loss val 0.39 accuracy val 0.86\n",
      "0.06 sec | epoch 91 loss train: 0.42 accuracy train: 0.84 loss val 0.34 accuracy val 0.90\n",
      "0.06 sec | epoch 92 loss train: 0.42 accuracy train: 0.84 loss val 0.39 accuracy val 0.86\n",
      "0.06 sec | epoch 93 loss train: 0.33 accuracy train: 0.90 loss val 0.40 accuracy val 0.86\n",
      "0.06 sec | epoch 94 loss train: 0.44 accuracy train: 0.84 loss val 0.37 accuracy val 0.88\n",
      "0.06 sec | epoch 95 loss train: 0.44 accuracy train: 0.84 loss val 0.42 accuracy val 0.84\n",
      "0.05 sec | epoch 96 loss train: 0.37 accuracy train: 0.88 loss val 0.40 accuracy val 0.86\n",
      "0.06 sec | epoch 97 loss train: 0.42 accuracy train: 0.84 loss val 0.42 accuracy val 0.84\n",
      "0.06 sec | epoch 98 loss train: 0.33 accuracy train: 0.90 loss val 0.36 accuracy val 0.86\n",
      "0.06 sec | epoch 99 loss train: 0.39 accuracy train: 0.86 loss val 0.39 accuracy val 0.86\n",
      "0.06 sec | epoch 100 loss train: 0.37 accuracy train: 0.88 loss val 0.39 accuracy val 0.86\n",
      "0.06 sec | epoch 101 loss train: 0.49 accuracy train: 0.82 loss val 0.39 accuracy val 0.86\n",
      "0.06 sec | epoch 102 loss train: 0.31 accuracy train: 0.90 loss val 0.30 accuracy val 0.90\n",
      "0.06 sec | epoch 103 loss train: 0.35 accuracy train: 0.88 loss val 0.41 accuracy val 0.86\n",
      "0.06 sec | epoch 104 loss train: 0.44 accuracy train: 0.84 loss val 0.40 accuracy val 0.86\n",
      "0.06 sec | epoch 105 loss train: 0.40 accuracy train: 0.86 loss val 0.32 accuracy val 0.90\n",
      "0.05 sec | epoch 106 loss train: 0.41 accuracy train: 0.86 loss val 0.40 accuracy val 0.86\n",
      "0.06 sec | epoch 107 loss train: 0.31 accuracy train: 0.90 loss val 0.31 accuracy val 0.90\n",
      "0.06 sec | epoch 108 loss train: 0.29 accuracy train: 0.90 loss val 0.28 accuracy val 0.92\n",
      "0.06 sec | epoch 109 loss train: 0.37 accuracy train: 0.88 loss val 0.44 accuracy val 0.84\n",
      "0.05 sec | epoch 110 loss train: 0.36 accuracy train: 0.88 loss val 0.40 accuracy val 0.86\n",
      "0.06 sec | epoch 111 loss train: 0.35 accuracy train: 0.88 loss val 0.28 accuracy val 0.92\n",
      "0.06 sec | epoch 112 loss train: 0.39 accuracy train: 0.86 loss val 0.38 accuracy val 0.88\n",
      "0.05 sec | epoch 113 loss train: 0.44 accuracy train: 0.84 loss val 0.40 accuracy val 0.86\n",
      "0.06 sec | epoch 114 loss train: 0.45 accuracy train: 0.84 loss val 0.29 accuracy val 0.92\n",
      "0.06 sec | epoch 115 loss train: 0.27 accuracy train: 0.92 loss val 0.31 accuracy val 0.90\n",
      "0.07 sec | epoch 116 loss train: 0.39 accuracy train: 0.86 loss val 0.35 accuracy val 0.88\n",
      "0.06 sec | epoch 117 loss train: 0.41 accuracy train: 0.86 loss val 0.34 accuracy val 0.90\n",
      "0.05 sec | epoch 118 loss train: 0.39 accuracy train: 0.86 loss val 0.36 accuracy val 0.86\n",
      "0.06 sec | epoch 119 loss train: 0.37 accuracy train: 0.88 loss val 0.33 accuracy val 0.88\n",
      "0.06 sec | epoch 120 loss train: 0.39 accuracy train: 0.86 loss val 0.45 accuracy val 0.84\n",
      "0.06 sec | epoch 121 loss train: 0.32 accuracy train: 0.90 loss val 0.41 accuracy val 0.86\n",
      "0.06 sec | epoch 122 loss train: 0.45 accuracy train: 0.84 loss val 0.47 accuracy val 0.82\n",
      "0.06 sec | epoch 123 loss train: 0.39 accuracy train: 0.86 loss val 0.32 accuracy val 0.90\n",
      "0.05 sec | epoch 124 loss train: 0.38 accuracy train: 0.86 loss val 0.29 accuracy val 0.92\n",
      "0.06 sec | epoch 125 loss train: 0.36 accuracy train: 0.88 loss val 0.38 accuracy val 0.88\n",
      "0.06 sec | epoch 126 loss train: 0.34 accuracy train: 0.88 loss val 0.39 accuracy val 0.86\n",
      "0.06 sec | epoch 127 loss train: 0.35 accuracy train: 0.88 loss val 0.39 accuracy val 0.86\n",
      "0.06 sec | epoch 128 loss train: 0.40 accuracy train: 0.86 loss val 0.35 accuracy val 0.88\n",
      "0.06 sec | epoch 129 loss train: 0.32 accuracy train: 0.88 loss val 0.39 accuracy val 0.86\n",
      "0.07 sec | epoch 130 loss train: 0.41 accuracy train: 0.86 loss val 0.31 accuracy val 0.90\n",
      "0.06 sec | epoch 131 loss train: 0.40 accuracy train: 0.86 loss val 0.44 accuracy val 0.84\n",
      "0.06 sec | epoch 132 loss train: 0.38 accuracy train: 0.86 loss val 0.43 accuracy val 0.84\n",
      "0.06 sec | epoch 133 loss train: 0.45 accuracy train: 0.84 loss val 0.33 accuracy val 0.88\n",
      "0.06 sec | epoch 134 loss train: 0.43 accuracy train: 0.84 loss val 0.43 accuracy val 0.84\n",
      "0.06 sec | epoch 135 loss train: 0.43 accuracy train: 0.86 loss val 0.48 accuracy val 0.82\n",
      "0.06 sec | epoch 136 loss train: 0.37 accuracy train: 0.88 loss val 0.39 accuracy val 0.86\n",
      "0.06 sec | epoch 137 loss train: 0.33 accuracy train: 0.90 loss val 0.39 accuracy val 0.86\n",
      "0.05 sec | epoch 138 loss train: 0.36 accuracy train: 0.88 loss val 0.42 accuracy val 0.86\n",
      "0.05 sec | epoch 139 loss train: 0.44 accuracy train: 0.84 loss val 0.33 accuracy val 0.90\n",
      "0.05 sec | epoch 140 loss train: 0.35 accuracy train: 0.88 loss val 0.35 accuracy val 0.88\n",
      "0.06 sec | epoch 141 loss train: 0.41 accuracy train: 0.86 loss val 0.34 accuracy val 0.88\n",
      "0.06 sec | epoch 142 loss train: 0.36 accuracy train: 0.88 loss val 0.43 accuracy val 0.84\n",
      "0.06 sec | epoch 143 loss train: 0.39 accuracy train: 0.86 loss val 0.47 accuracy val 0.82\n",
      "0.05 sec | epoch 144 loss train: 0.36 accuracy train: 0.88 loss val 0.35 accuracy val 0.88\n",
      "0.06 sec | epoch 145 loss train: 0.34 accuracy train: 0.88 loss val 0.44 accuracy val 0.84\n",
      "0.06 sec | epoch 146 loss train: 0.42 accuracy train: 0.86 loss val 0.43 accuracy val 0.84\n",
      "0.05 sec | epoch 147 loss train: 0.35 accuracy train: 0.88 loss val 0.43 accuracy val 0.84\n",
      "0.06 sec | epoch 148 loss train: 0.38 accuracy train: 0.86 loss val 0.35 accuracy val 0.88\n",
      "0.06 sec | epoch 149 loss train: 0.35 accuracy train: 0.88 loss val 0.45 accuracy val 0.84\n",
      "0.06 sec | epoch 150 loss train: 0.41 accuracy train: 0.86 loss val 0.37 accuracy val 0.86\n",
      "0.05 sec | epoch 151 loss train: 0.45 accuracy train: 0.82 loss val 0.30 accuracy val 0.90\n",
      "0.06 sec | epoch 152 loss train: 0.40 accuracy train: 0.86 loss val 0.44 accuracy val 0.84\n",
      "0.05 sec | epoch 153 loss train: 0.37 accuracy train: 0.86 loss val 0.43 accuracy val 0.84\n",
      "0.05 sec | epoch 154 loss train: 0.32 accuracy train: 0.90 loss val 0.47 accuracy val 0.82\n",
      "0.05 sec | epoch 155 loss train: 0.41 accuracy train: 0.86 loss val 0.43 accuracy val 0.84\n",
      "0.06 sec | epoch 156 loss train: 0.42 accuracy train: 0.84 loss val 0.40 accuracy val 0.86\n",
      "0.05 sec | epoch 157 loss train: 0.45 accuracy train: 0.82 loss val 0.36 accuracy val 0.88\n",
      "0.06 sec | epoch 158 loss train: 0.47 accuracy train: 0.82 loss val 0.38 accuracy val 0.86\n",
      "0.06 sec | epoch 159 loss train: 0.39 accuracy train: 0.86 loss val 0.34 accuracy val 0.88\n",
      "0.06 sec | epoch 160 loss train: 0.32 accuracy train: 0.90 loss val 0.42 accuracy val 0.84\n",
      "0.05 sec | epoch 161 loss train: 0.33 accuracy train: 0.90 loss val 0.41 accuracy val 0.86\n",
      "0.06 sec | epoch 162 loss train: 0.37 accuracy train: 0.88 loss val 0.39 accuracy val 0.86\n",
      "0.05 sec | epoch 163 loss train: 0.30 accuracy train: 0.90 loss val 0.30 accuracy val 0.90\n",
      "0.05 sec | epoch 164 loss train: 0.30 accuracy train: 0.90 loss val 0.38 accuracy val 0.86\n",
      "0.06 sec | epoch 165 loss train: 0.30 accuracy train: 0.90 loss val 0.54 accuracy val 0.80\n",
      "0.06 sec | epoch 166 loss train: 0.34 accuracy train: 0.90 loss val 0.37 accuracy val 0.88\n",
      "0.05 sec | epoch 167 loss train: 0.34 accuracy train: 0.90 loss val 0.35 accuracy val 0.88\n",
      "0.06 sec | epoch 168 loss train: 0.40 accuracy train: 0.86 loss val 0.36 accuracy val 0.86\n",
      "0.05 sec | epoch 169 loss train: 0.47 accuracy train: 0.84 loss val 0.38 accuracy val 0.86\n",
      "0.06 sec | epoch 170 loss train: 0.31 accuracy train: 0.90 loss val 0.40 accuracy val 0.86\n",
      "0.06 sec | epoch 171 loss train: 0.42 accuracy train: 0.84 loss val 0.32 accuracy val 0.90\n",
      "0.06 sec | epoch 172 loss train: 0.32 accuracy train: 0.90 loss val 0.34 accuracy val 0.88\n",
      "0.05 sec | epoch 173 loss train: 0.43 accuracy train: 0.86 loss val 0.39 accuracy val 0.86\n",
      "0.05 sec | epoch 174 loss train: 0.42 accuracy train: 0.86 loss val 0.37 accuracy val 0.86\n",
      "0.05 sec | epoch 175 loss train: 0.38 accuracy train: 0.86 loss val 0.37 accuracy val 0.86\n",
      "0.06 sec | epoch 176 loss train: 0.38 accuracy train: 0.88 loss val 0.31 accuracy val 0.90\n",
      "0.06 sec | epoch 177 loss train: 0.37 accuracy train: 0.86 loss val 0.35 accuracy val 0.88\n",
      "0.06 sec | epoch 178 loss train: 0.41 accuracy train: 0.84 loss val 0.34 accuracy val 0.88\n",
      "0.06 sec | epoch 179 loss train: 0.37 accuracy train: 0.88 loss val 0.37 accuracy val 0.88\n",
      "0.06 sec | epoch 180 loss train: 0.39 accuracy train: 0.86 loss val 0.45 accuracy val 0.84\n",
      "0.06 sec | epoch 181 loss train: 0.41 accuracy train: 0.86 loss val 0.38 accuracy val 0.88\n",
      "0.06 sec | epoch 182 loss train: 0.40 accuracy train: 0.86 loss val 0.37 accuracy val 0.88\n",
      "0.06 sec | epoch 183 loss train: 0.36 accuracy train: 0.88 loss val 0.34 accuracy val 0.88\n",
      "0.05 sec | epoch 184 loss train: 0.37 accuracy train: 0.86 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 185 loss train: 0.38 accuracy train: 0.86 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 186 loss train: 0.32 accuracy train: 0.90 loss val 0.37 accuracy val 0.88\n",
      "0.06 sec | epoch 187 loss train: 0.34 accuracy train: 0.88 loss val 0.34 accuracy val 0.90\n",
      "0.06 sec | epoch 188 loss train: 0.55 accuracy train: 0.80 loss val 0.29 accuracy val 0.90\n",
      "0.06 sec | epoch 189 loss train: 0.35 accuracy train: 0.88 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 190 loss train: 0.47 accuracy train: 0.82 loss val 0.34 accuracy val 0.90\n",
      "0.06 sec | epoch 191 loss train: 0.42 accuracy train: 0.86 loss val 0.34 accuracy val 0.90\n",
      "0.06 sec | epoch 192 loss train: 0.34 accuracy train: 0.88 loss val 0.36 accuracy val 0.86\n",
      "0.06 sec | epoch 193 loss train: 0.40 accuracy train: 0.86 loss val 0.48 accuracy val 0.82\n",
      "0.06 sec | epoch 194 loss train: 0.44 accuracy train: 0.84 loss val 0.31 accuracy val 0.90\n",
      "0.05 sec | epoch 195 loss train: 0.39 accuracy train: 0.86 loss val 0.42 accuracy val 0.86\n",
      "0.05 sec | epoch 196 loss train: 0.34 accuracy train: 0.90 loss val 0.30 accuracy val 0.92\n",
      "0.06 sec | epoch 197 loss train: 0.38 accuracy train: 0.88 loss val 0.41 accuracy val 0.86\n",
      "0.06 sec | epoch 198 loss train: 0.39 accuracy train: 0.86 loss val 0.45 accuracy val 0.82\n",
      "0.06 sec | epoch 199 loss train: 0.33 accuracy train: 0.90 loss val 0.43 accuracy val 0.84\n",
      "0.07 sec | epoch 200 loss train: 0.39 accuracy train: 0.86 loss val 0.39 accuracy val 0.86\n",
      "0.06 sec | epoch 201 loss train: 0.45 accuracy train: 0.84 loss val 0.28 accuracy val 0.92\n",
      "0.05 sec | epoch 202 loss train: 0.39 accuracy train: 0.86 loss val 0.32 accuracy val 0.88\n",
      "0.05 sec | epoch 203 loss train: 0.27 accuracy train: 0.92 loss val 0.35 accuracy val 0.88\n",
      "0.06 sec | epoch 204 loss train: 0.37 accuracy train: 0.88 loss val 0.40 accuracy val 0.86\n",
      "0.05 sec | epoch 205 loss train: 0.35 accuracy train: 0.88 loss val 0.36 accuracy val 0.88\n",
      "0.06 sec | epoch 206 loss train: 0.43 accuracy train: 0.84 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 207 loss train: 0.46 accuracy train: 0.84 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 208 loss train: 0.31 accuracy train: 0.90 loss val 0.42 accuracy val 0.86\n",
      "0.05 sec | epoch 209 loss train: 0.35 accuracy train: 0.88 loss val 0.46 accuracy val 0.84\n",
      "0.05 sec | epoch 210 loss train: 0.40 accuracy train: 0.86 loss val 0.40 accuracy val 0.86\n",
      "0.06 sec | epoch 211 loss train: 0.37 accuracy train: 0.88 loss val 0.37 accuracy val 0.86\n",
      "0.04 sec | epoch 212 loss train: 0.32 accuracy train: 0.90 loss val 0.48 accuracy val 0.82\n",
      "0.05 sec | epoch 213 loss train: 0.35 accuracy train: 0.88 loss val 0.36 accuracy val 0.86\n",
      "0.05 sec | epoch 214 loss train: 0.38 accuracy train: 0.86 loss val 0.33 accuracy val 0.88\n",
      "0.05 sec | epoch 215 loss train: 0.45 accuracy train: 0.84 loss val 0.44 accuracy val 0.84\n",
      "0.06 sec | epoch 216 loss train: 0.45 accuracy train: 0.84 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 217 loss train: 0.44 accuracy train: 0.82 loss val 0.32 accuracy val 0.90\n",
      "0.05 sec | epoch 218 loss train: 0.47 accuracy train: 0.82 loss val 0.43 accuracy val 0.84\n",
      "0.04 sec | epoch 219 loss train: 0.38 accuracy train: 0.86 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 220 loss train: 0.38 accuracy train: 0.86 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 221 loss train: 0.38 accuracy train: 0.86 loss val 0.44 accuracy val 0.84\n",
      "0.06 sec | epoch 222 loss train: 0.36 accuracy train: 0.88 loss val 0.37 accuracy val 0.88\n",
      "0.05 sec | epoch 223 loss train: 0.38 accuracy train: 0.88 loss val 0.43 accuracy val 0.84\n",
      "0.07 sec | epoch 224 loss train: 0.39 accuracy train: 0.86 loss val 0.34 accuracy val 0.88\n",
      "0.07 sec | epoch 225 loss train: 0.39 accuracy train: 0.86 loss val 0.43 accuracy val 0.82\n",
      "0.05 sec | epoch 226 loss train: 0.35 accuracy train: 0.88 loss val 0.44 accuracy val 0.84\n",
      "0.05 sec | epoch 227 loss train: 0.35 accuracy train: 0.88 loss val 0.38 accuracy val 0.86\n",
      "0.05 sec | epoch 228 loss train: 0.40 accuracy train: 0.86 loss val 0.31 accuracy val 0.90\n",
      "0.05 sec | epoch 229 loss train: 0.34 accuracy train: 0.90 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 230 loss train: 0.37 accuracy train: 0.88 loss val 0.33 accuracy val 0.88\n",
      "0.06 sec | epoch 231 loss train: 0.39 accuracy train: 0.86 loss val 0.44 accuracy val 0.84\n",
      "0.05 sec | epoch 232 loss train: 0.40 accuracy train: 0.86 loss val 0.46 accuracy val 0.84\n",
      "0.06 sec | epoch 233 loss train: 0.39 accuracy train: 0.86 loss val 0.37 accuracy val 0.86\n",
      "0.07 sec | epoch 234 loss train: 0.30 accuracy train: 0.90 loss val 0.39 accuracy val 0.86\n",
      "0.05 sec | epoch 235 loss train: 0.38 accuracy train: 0.88 loss val 0.38 accuracy val 0.86\n",
      "0.08 sec | epoch 236 loss train: 0.44 accuracy train: 0.84 loss val 0.33 accuracy val 0.90\n",
      "0.08 sec | epoch 237 loss train: 0.42 accuracy train: 0.84 loss val 0.36 accuracy val 0.88\n",
      "0.06 sec | epoch 238 loss train: 0.50 accuracy train: 0.82 loss val 0.37 accuracy val 0.86\n",
      "0.08 sec | epoch 239 loss train: 0.37 accuracy train: 0.86 loss val 0.41 accuracy val 0.86\n",
      "0.06 sec | epoch 240 loss train: 0.34 accuracy train: 0.90 loss val 0.39 accuracy val 0.86\n",
      "0.06 sec | epoch 241 loss train: 0.36 accuracy train: 0.88 loss val 0.37 accuracy val 0.88\n",
      "0.06 sec | epoch 242 loss train: 0.39 accuracy train: 0.88 loss val 0.39 accuracy val 0.86\n",
      "0.06 sec | epoch 243 loss train: 0.31 accuracy train: 0.90 loss val 0.37 accuracy val 0.88\n",
      "0.07 sec | epoch 244 loss train: 0.44 accuracy train: 0.84 loss val 0.36 accuracy val 0.88\n",
      "0.07 sec | epoch 245 loss train: 0.30 accuracy train: 0.90 loss val 0.32 accuracy val 0.90\n",
      "0.09 sec | epoch 246 loss train: 0.35 accuracy train: 0.90 loss val 0.37 accuracy val 0.88\n",
      "0.06 sec | epoch 247 loss train: 0.38 accuracy train: 0.86 loss val 0.40 accuracy val 0.84\n",
      "0.07 sec | epoch 248 loss train: 0.39 accuracy train: 0.86 loss val 0.35 accuracy val 0.88\n",
      "0.08 sec | epoch 249 loss train: 0.34 accuracy train: 0.88 loss val 0.36 accuracy val 0.88\n",
      "0.06 sec | epoch 250 loss train: 0.34 accuracy train: 0.88 loss val 0.39 accuracy val 0.86\n",
      "0.06 sec | epoch 251 loss train: 0.55 accuracy train: 0.80 loss val 0.38 accuracy val 0.86\n",
      "0.06 sec | epoch 252 loss train: 0.32 accuracy train: 0.88 loss val 0.39 accuracy val 0.88\n",
      "0.09 sec | epoch 253 loss train: 0.46 accuracy train: 0.84 loss val 0.36 accuracy val 0.88\n",
      "0.07 sec | epoch 254 loss train: 0.35 accuracy train: 0.88 loss val 0.32 accuracy val 0.90\n",
      "0.08 sec | epoch 255 loss train: 0.47 accuracy train: 0.80 loss val 0.35 accuracy val 0.88\n",
      "0.08 sec | epoch 256 loss train: 0.33 accuracy train: 0.88 loss val 0.34 accuracy val 0.88\n",
      "0.08 sec | epoch 257 loss train: 0.41 accuracy train: 0.86 loss val 0.40 accuracy val 0.86\n",
      "0.08 sec | epoch 258 loss train: 0.36 accuracy train: 0.88 loss val 0.42 accuracy val 0.84\n",
      "0.08 sec | epoch 259 loss train: 0.42 accuracy train: 0.84 loss val 0.38 accuracy val 0.88\n",
      "0.09 sec | epoch 260 loss train: 0.28 accuracy train: 0.92 loss val 0.35 accuracy val 0.88\n",
      "0.07 sec | epoch 261 loss train: 0.36 accuracy train: 0.86 loss val 0.33 accuracy val 0.90\n",
      "0.09 sec | epoch 262 loss train: 0.33 accuracy train: 0.90 loss val 0.41 accuracy val 0.86\n",
      "0.08 sec | epoch 263 loss train: 0.32 accuracy train: 0.90 loss val 0.41 accuracy val 0.84\n",
      "0.06 sec | epoch 264 loss train: 0.35 accuracy train: 0.88 loss val 0.39 accuracy val 0.86\n",
      "0.06 sec | epoch 265 loss train: 0.40 accuracy train: 0.86 loss val 0.35 accuracy val 0.88\n",
      "0.06 sec | epoch 266 loss train: 0.33 accuracy train: 0.88 loss val 0.37 accuracy val 0.86\n",
      "0.05 sec | epoch 267 loss train: 0.43 accuracy train: 0.84 loss val 0.34 accuracy val 0.88\n",
      "0.05 sec | epoch 268 loss train: 0.47 accuracy train: 0.84 loss val 0.42 accuracy val 0.86\n",
      "0.05 sec | epoch 269 loss train: 0.34 accuracy train: 0.88 loss val 0.47 accuracy val 0.82\n",
      "0.05 sec | epoch 270 loss train: 0.41 accuracy train: 0.84 loss val 0.34 accuracy val 0.88\n",
      "0.08 sec | epoch 271 loss train: 0.36 accuracy train: 0.88 loss val 0.44 accuracy val 0.84\n",
      "0.07 sec | epoch 272 loss train: 0.35 accuracy train: 0.90 loss val 0.36 accuracy val 0.88\n",
      "0.07 sec | epoch 273 loss train: 0.36 accuracy train: 0.88 loss val 0.29 accuracy val 0.90\n",
      "0.05 sec | epoch 274 loss train: 0.32 accuracy train: 0.90 loss val 0.37 accuracy val 0.88\n",
      "0.06 sec | epoch 275 loss train: 0.40 accuracy train: 0.86 loss val 0.38 accuracy val 0.86\n",
      "0.06 sec | epoch 276 loss train: 0.45 accuracy train: 0.84 loss val 0.38 accuracy val 0.88\n",
      "0.09 sec | epoch 277 loss train: 0.34 accuracy train: 0.88 loss val 0.43 accuracy val 0.84\n",
      "0.08 sec | epoch 278 loss train: 0.31 accuracy train: 0.90 loss val 0.45 accuracy val 0.82\n",
      "0.07 sec | epoch 279 loss train: 0.40 accuracy train: 0.86 loss val 0.31 accuracy val 0.90\n",
      "0.09 sec | epoch 280 loss train: 0.41 accuracy train: 0.86 loss val 0.39 accuracy val 0.86\n",
      "0.09 sec | epoch 281 loss train: 0.39 accuracy train: 0.86 loss val 0.42 accuracy val 0.86\n",
      "0.09 sec | epoch 282 loss train: 0.36 accuracy train: 0.86 loss val 0.30 accuracy val 0.90\n",
      "0.07 sec | epoch 283 loss train: 0.39 accuracy train: 0.86 loss val 0.41 accuracy val 0.84\n",
      "0.09 sec | epoch 284 loss train: 0.39 accuracy train: 0.88 loss val 0.39 accuracy val 0.86\n",
      "0.07 sec | epoch 285 loss train: 0.27 accuracy train: 0.92 loss val 0.45 accuracy val 0.84\n",
      "0.06 sec | epoch 286 loss train: 0.30 accuracy train: 0.90 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 287 loss train: 0.26 accuracy train: 0.92 loss val 0.33 accuracy val 0.88\n",
      "0.05 sec | epoch 288 loss train: 0.31 accuracy train: 0.90 loss val 0.38 accuracy val 0.86\n",
      "0.05 sec | epoch 289 loss train: 0.37 accuracy train: 0.88 loss val 0.40 accuracy val 0.88\n",
      "0.06 sec | epoch 290 loss train: 0.36 accuracy train: 0.86 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 291 loss train: 0.32 accuracy train: 0.88 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 292 loss train: 0.40 accuracy train: 0.86 loss val 0.38 accuracy val 0.86\n",
      "0.07 sec | epoch 293 loss train: 0.37 accuracy train: 0.88 loss val 0.44 accuracy val 0.84\n",
      "0.08 sec | epoch 294 loss train: 0.33 accuracy train: 0.88 loss val 0.37 accuracy val 0.88\n",
      "0.07 sec | epoch 295 loss train: 0.31 accuracy train: 0.90 loss val 0.34 accuracy val 0.88\n",
      "0.07 sec | epoch 296 loss train: 0.45 accuracy train: 0.82 loss val 0.48 accuracy val 0.82\n",
      "0.05 sec | epoch 297 loss train: 0.42 accuracy train: 0.86 loss val 0.40 accuracy val 0.86\n",
      "0.05 sec | epoch 298 loss train: 0.43 accuracy train: 0.86 loss val 0.41 accuracy val 0.86\n",
      "0.07 sec | epoch 299 loss train: 0.32 accuracy train: 0.90 loss val 0.48 accuracy val 0.82\n",
      "0.08 sec | epoch 300 loss train: 0.37 accuracy train: 0.88 loss val 0.37 accuracy val 0.86\n",
      "0.09 sec | epoch 301 loss train: 0.43 accuracy train: 0.84 loss val 0.33 accuracy val 0.90\n",
      "0.09 sec | epoch 302 loss train: 0.46 accuracy train: 0.82 loss val 0.41 accuracy val 0.86\n",
      "0.07 sec | epoch 303 loss train: 0.44 accuracy train: 0.84 loss val 0.35 accuracy val 0.88\n",
      "0.09 sec | epoch 304 loss train: 0.40 accuracy train: 0.86 loss val 0.39 accuracy val 0.86\n",
      "0.09 sec | epoch 305 loss train: 0.33 accuracy train: 0.90 loss val 0.44 accuracy val 0.82\n",
      "0.06 sec | epoch 306 loss train: 0.38 accuracy train: 0.86 loss val 0.38 accuracy val 0.88\n",
      "0.07 sec | epoch 307 loss train: 0.39 accuracy train: 0.86 loss val 0.34 accuracy val 0.88\n",
      "0.05 sec | epoch 308 loss train: 0.43 accuracy train: 0.82 loss val 0.34 accuracy val 0.88\n",
      "0.07 sec | epoch 309 loss train: 0.31 accuracy train: 0.90 loss val 0.36 accuracy val 0.88\n",
      "0.06 sec | epoch 310 loss train: 0.43 accuracy train: 0.84 loss val 0.45 accuracy val 0.84\n",
      "0.08 sec | epoch 311 loss train: 0.35 accuracy train: 0.88 loss val 0.35 accuracy val 0.88\n",
      "0.08 sec | epoch 312 loss train: 0.38 accuracy train: 0.86 loss val 0.44 accuracy val 0.82\n",
      "0.05 sec | epoch 313 loss train: 0.31 accuracy train: 0.90 loss val 0.36 accuracy val 0.88\n",
      "0.07 sec | epoch 314 loss train: 0.41 accuracy train: 0.86 loss val 0.33 accuracy val 0.88\n",
      "0.06 sec | epoch 315 loss train: 0.30 accuracy train: 0.90 loss val 0.46 accuracy val 0.84\n",
      "0.06 sec | epoch 316 loss train: 0.43 accuracy train: 0.86 loss val 0.35 accuracy val 0.90\n",
      "0.07 sec | epoch 317 loss train: 0.35 accuracy train: 0.88 loss val 0.36 accuracy val 0.88\n",
      "0.08 sec | epoch 318 loss train: 0.45 accuracy train: 0.84 loss val 0.44 accuracy val 0.86\n",
      "0.06 sec | epoch 319 loss train: 0.47 accuracy train: 0.84 loss val 0.40 accuracy val 0.86\n",
      "0.08 sec | epoch 320 loss train: 0.39 accuracy train: 0.86 loss val 0.41 accuracy val 0.86\n",
      "0.06 sec | epoch 321 loss train: 0.44 accuracy train: 0.84 loss val 0.38 accuracy val 0.88\n",
      "0.04 sec | epoch 322 loss train: 0.32 accuracy train: 0.90 loss val 0.41 accuracy val 0.84\n",
      "0.05 sec | epoch 323 loss train: 0.37 accuracy train: 0.88 loss val 0.45 accuracy val 0.82\n",
      "0.05 sec | epoch 324 loss train: 0.37 accuracy train: 0.86 loss val 0.38 accuracy val 0.86\n",
      "0.06 sec | epoch 325 loss train: 0.37 accuracy train: 0.86 loss val 0.43 accuracy val 0.84\n",
      "0.06 sec | epoch 326 loss train: 0.44 accuracy train: 0.84 loss val 0.30 accuracy val 0.92\n",
      "0.06 sec | epoch 327 loss train: 0.48 accuracy train: 0.82 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 328 loss train: 0.40 accuracy train: 0.84 loss val 0.45 accuracy val 0.84\n",
      "0.05 sec | epoch 329 loss train: 0.32 accuracy train: 0.90 loss val 0.41 accuracy val 0.84\n",
      "0.05 sec | epoch 330 loss train: 0.38 accuracy train: 0.86 loss val 0.41 accuracy val 0.84\n",
      "0.05 sec | epoch 331 loss train: 0.37 accuracy train: 0.88 loss val 0.38 accuracy val 0.86\n",
      "0.05 sec | epoch 332 loss train: 0.39 accuracy train: 0.86 loss val 0.44 accuracy val 0.84\n",
      "0.05 sec | epoch 333 loss train: 0.36 accuracy train: 0.88 loss val 0.32 accuracy val 0.88\n",
      "0.05 sec | epoch 334 loss train: 0.36 accuracy train: 0.88 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 335 loss train: 0.37 accuracy train: 0.88 loss val 0.38 accuracy val 0.86\n",
      "0.07 sec | epoch 336 loss train: 0.37 accuracy train: 0.88 loss val 0.30 accuracy val 0.90\n",
      "0.07 sec | epoch 337 loss train: 0.42 accuracy train: 0.84 loss val 0.49 accuracy val 0.82\n",
      "0.08 sec | epoch 338 loss train: 0.30 accuracy train: 0.90 loss val 0.40 accuracy val 0.86\n",
      "0.06 sec | epoch 339 loss train: 0.38 accuracy train: 0.86 loss val 0.48 accuracy val 0.82\n",
      "0.06 sec | epoch 340 loss train: 0.33 accuracy train: 0.88 loss val 0.29 accuracy val 0.90\n",
      "0.08 sec | epoch 341 loss train: 0.42 accuracy train: 0.84 loss val 0.40 accuracy val 0.86\n",
      "0.08 sec | epoch 342 loss train: 0.37 accuracy train: 0.86 loss val 0.39 accuracy val 0.86\n",
      "0.06 sec | epoch 343 loss train: 0.43 accuracy train: 0.84 loss val 0.49 accuracy val 0.82\n",
      "0.05 sec | epoch 344 loss train: 0.41 accuracy train: 0.86 loss val 0.40 accuracy val 0.86\n",
      "0.06 sec | epoch 345 loss train: 0.42 accuracy train: 0.84 loss val 0.49 accuracy val 0.82\n",
      "0.06 sec | epoch 346 loss train: 0.40 accuracy train: 0.84 loss val 0.32 accuracy val 0.90\n",
      "0.07 sec | epoch 347 loss train: 0.30 accuracy train: 0.92 loss val 0.39 accuracy val 0.86\n",
      "0.07 sec | epoch 348 loss train: 0.35 accuracy train: 0.88 loss val 0.43 accuracy val 0.84\n",
      "0.05 sec | epoch 349 loss train: 0.36 accuracy train: 0.88 loss val 0.31 accuracy val 0.92\n",
      "0.05 sec | epoch 350 loss train: 0.37 accuracy train: 0.86 loss val 0.41 accuracy val 0.86\n",
      "0.05 sec | epoch 351 loss train: 0.38 accuracy train: 0.84 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 352 loss train: 0.37 accuracy train: 0.88 loss val 0.37 accuracy val 0.88\n",
      "0.05 sec | epoch 353 loss train: 0.33 accuracy train: 0.88 loss val 0.49 accuracy val 0.80\n",
      "0.05 sec | epoch 354 loss train: 0.33 accuracy train: 0.88 loss val 0.31 accuracy val 0.88\n",
      "0.05 sec | epoch 355 loss train: 0.42 accuracy train: 0.86 loss val 0.36 accuracy val 0.86\n",
      "0.05 sec | epoch 356 loss train: 0.44 accuracy train: 0.84 loss val 0.53 accuracy val 0.80\n",
      "0.05 sec | epoch 357 loss train: 0.31 accuracy train: 0.90 loss val 0.30 accuracy val 0.90\n",
      "0.05 sec | epoch 358 loss train: 0.39 accuracy train: 0.88 loss val 0.39 accuracy val 0.86\n",
      "0.06 sec | epoch 359 loss train: 0.33 accuracy train: 0.88 loss val 0.33 accuracy val 0.88\n",
      "0.08 sec | epoch 360 loss train: 0.40 accuracy train: 0.84 loss val 0.40 accuracy val 0.86\n",
      "0.08 sec | epoch 361 loss train: 0.39 accuracy train: 0.88 loss val 0.32 accuracy val 0.90\n",
      "0.07 sec | epoch 362 loss train: 0.33 accuracy train: 0.88 loss val 0.35 accuracy val 0.88\n",
      "0.08 sec | epoch 363 loss train: 0.28 accuracy train: 0.90 loss val 0.48 accuracy val 0.82\n",
      "0.07 sec | epoch 364 loss train: 0.34 accuracy train: 0.88 loss val 0.39 accuracy val 0.84\n",
      "0.08 sec | epoch 365 loss train: 0.34 accuracy train: 0.88 loss val 0.30 accuracy val 0.90\n",
      "0.08 sec | epoch 366 loss train: 0.41 accuracy train: 0.84 loss val 0.43 accuracy val 0.82\n",
      "0.07 sec | epoch 367 loss train: 0.33 accuracy train: 0.88 loss val 0.41 accuracy val 0.84\n",
      "0.07 sec | epoch 368 loss train: 0.39 accuracy train: 0.86 loss val 0.41 accuracy val 0.86\n",
      "0.07 sec | epoch 369 loss train: 0.38 accuracy train: 0.86 loss val 0.34 accuracy val 0.88\n",
      "0.08 sec | epoch 370 loss train: 0.48 accuracy train: 0.82 loss val 0.31 accuracy val 0.90\n",
      "0.05 sec | epoch 371 loss train: 0.42 accuracy train: 0.82 loss val 0.38 accuracy val 0.86\n",
      "0.08 sec | epoch 372 loss train: 0.40 accuracy train: 0.86 loss val 0.37 accuracy val 0.88\n",
      "0.05 sec | epoch 373 loss train: 0.37 accuracy train: 0.86 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 374 loss train: 0.40 accuracy train: 0.86 loss val 0.42 accuracy val 0.86\n",
      "0.05 sec | epoch 375 loss train: 0.29 accuracy train: 0.90 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 376 loss train: 0.38 accuracy train: 0.88 loss val 0.38 accuracy val 0.86\n",
      "0.06 sec | epoch 377 loss train: 0.34 accuracy train: 0.88 loss val 0.47 accuracy val 0.84\n",
      "0.07 sec | epoch 378 loss train: 0.41 accuracy train: 0.86 loss val 0.45 accuracy val 0.82\n",
      "0.08 sec | epoch 379 loss train: 0.33 accuracy train: 0.90 loss val 0.34 accuracy val 0.86\n",
      "0.07 sec | epoch 380 loss train: 0.35 accuracy train: 0.88 loss val 0.35 accuracy val 0.86\n",
      "0.07 sec | epoch 381 loss train: 0.37 accuracy train: 0.86 loss val 0.46 accuracy val 0.84\n",
      "0.07 sec | epoch 382 loss train: 0.33 accuracy train: 0.88 loss val 0.46 accuracy val 0.82\n",
      "0.05 sec | epoch 383 loss train: 0.39 accuracy train: 0.86 loss val 0.38 accuracy val 0.86\n",
      "0.06 sec | epoch 384 loss train: 0.41 accuracy train: 0.86 loss val 0.40 accuracy val 0.86\n",
      "0.06 sec | epoch 385 loss train: 0.40 accuracy train: 0.86 loss val 0.32 accuracy val 0.90\n",
      "0.05 sec | epoch 386 loss train: 0.29 accuracy train: 0.90 loss val 0.30 accuracy val 0.90\n",
      "0.07 sec | epoch 387 loss train: 0.33 accuracy train: 0.88 loss val 0.49 accuracy val 0.82\n",
      "0.08 sec | epoch 388 loss train: 0.38 accuracy train: 0.88 loss val 0.40 accuracy val 0.86\n",
      "0.08 sec | epoch 389 loss train: 0.35 accuracy train: 0.88 loss val 0.32 accuracy val 0.88\n",
      "0.07 sec | epoch 390 loss train: 0.36 accuracy train: 0.86 loss val 0.38 accuracy val 0.88\n",
      "0.05 sec | epoch 391 loss train: 0.41 accuracy train: 0.86 loss val 0.33 accuracy val 0.90\n",
      "0.05 sec | epoch 392 loss train: 0.42 accuracy train: 0.84 loss val 0.28 accuracy val 0.90\n",
      "0.05 sec | epoch 393 loss train: 0.37 accuracy train: 0.86 loss val 0.33 accuracy val 0.90\n",
      "0.05 sec | epoch 394 loss train: 0.38 accuracy train: 0.86 loss val 0.38 accuracy val 0.86\n",
      "0.07 sec | epoch 395 loss train: 0.33 accuracy train: 0.90 loss val 0.24 accuracy val 0.92\n",
      "0.05 sec | epoch 396 loss train: 0.34 accuracy train: 0.88 loss val 0.28 accuracy val 0.92\n",
      "0.06 sec | epoch 397 loss train: 0.36 accuracy train: 0.88 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 398 loss train: 0.38 accuracy train: 0.86 loss val 0.39 accuracy val 0.86\n",
      "0.06 sec | epoch 399 loss train: 0.42 accuracy train: 0.84 loss val 0.42 accuracy val 0.86\n",
      "0.06 sec | epoch 400 loss train: 0.37 accuracy train: 0.88 loss val 0.36 accuracy val 0.88\n",
      "0.08 sec | epoch 401 loss train: 0.38 accuracy train: 0.86 loss val 0.30 accuracy val 0.90\n",
      "0.06 sec | epoch 402 loss train: 0.35 accuracy train: 0.88 loss val 0.37 accuracy val 0.86\n",
      "0.07 sec | epoch 403 loss train: 0.35 accuracy train: 0.90 loss val 0.39 accuracy val 0.86\n",
      "0.08 sec | epoch 404 loss train: 0.39 accuracy train: 0.86 loss val 0.40 accuracy val 0.84\n",
      "0.06 sec | epoch 405 loss train: 0.38 accuracy train: 0.86 loss val 0.32 accuracy val 0.90\n",
      "0.06 sec | epoch 406 loss train: 0.41 accuracy train: 0.84 loss val 0.49 accuracy val 0.82\n",
      "0.05 sec | epoch 407 loss train: 0.35 accuracy train: 0.88 loss val 0.28 accuracy val 0.90\n",
      "0.06 sec | epoch 408 loss train: 0.47 accuracy train: 0.82 loss val 0.34 accuracy val 0.88\n",
      "0.06 sec | epoch 409 loss train: 0.37 accuracy train: 0.84 loss val 0.44 accuracy val 0.84\n",
      "0.05 sec | epoch 410 loss train: 0.40 accuracy train: 0.86 loss val 0.38 accuracy val 0.86\n",
      "0.08 sec | epoch 411 loss train: 0.38 accuracy train: 0.88 loss val 0.37 accuracy val 0.86\n",
      "0.07 sec | epoch 412 loss train: 0.40 accuracy train: 0.84 loss val 0.37 accuracy val 0.84\n",
      "0.07 sec | epoch 413 loss train: 0.36 accuracy train: 0.86 loss val 0.37 accuracy val 0.86\n",
      "0.06 sec | epoch 414 loss train: 0.34 accuracy train: 0.88 loss val 0.34 accuracy val 0.88\n",
      "0.05 sec | epoch 415 loss train: 0.42 accuracy train: 0.84 loss val 0.33 accuracy val 0.88\n",
      "0.05 sec | epoch 416 loss train: 0.33 accuracy train: 0.88 loss val 0.34 accuracy val 0.88\n",
      "0.05 sec | epoch 417 loss train: 0.41 accuracy train: 0.84 loss val 0.34 accuracy val 0.88\n",
      "0.05 sec | epoch 418 loss train: 0.41 accuracy train: 0.82 loss val 0.30 accuracy val 0.90\n",
      "0.04 sec | epoch 419 loss train: 0.41 accuracy train: 0.84 loss val 0.44 accuracy val 0.84\n",
      "0.05 sec | epoch 420 loss train: 0.37 accuracy train: 0.86 loss val 0.36 accuracy val 0.86\n",
      "0.05 sec | epoch 421 loss train: 0.36 accuracy train: 0.86 loss val 0.40 accuracy val 0.86\n",
      "0.05 sec | epoch 422 loss train: 0.38 accuracy train: 0.86 loss val 0.37 accuracy val 0.86\n",
      "0.05 sec | epoch 423 loss train: 0.36 accuracy train: 0.88 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 424 loss train: 0.37 accuracy train: 0.88 loss val 0.40 accuracy val 0.88\n",
      "0.05 sec | epoch 425 loss train: 0.43 accuracy train: 0.86 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 426 loss train: 0.37 accuracy train: 0.86 loss val 0.44 accuracy val 0.86\n",
      "0.05 sec | epoch 427 loss train: 0.43 accuracy train: 0.86 loss val 0.30 accuracy val 0.90\n",
      "0.05 sec | epoch 428 loss train: 0.32 accuracy train: 0.90 loss val 0.35 accuracy val 0.86\n",
      "0.05 sec | epoch 429 loss train: 0.31 accuracy train: 0.90 loss val 0.36 accuracy val 0.86\n",
      "0.06 sec | epoch 430 loss train: 0.35 accuracy train: 0.88 loss val 0.39 accuracy val 0.86\n",
      "0.05 sec | epoch 431 loss train: 0.38 accuracy train: 0.86 loss val 0.33 accuracy val 0.88\n",
      "0.05 sec | epoch 432 loss train: 0.33 accuracy train: 0.88 loss val 0.39 accuracy val 0.88\n",
      "0.07 sec | epoch 433 loss train: 0.39 accuracy train: 0.86 loss val 0.38 accuracy val 0.86\n",
      "0.07 sec | epoch 434 loss train: 0.41 accuracy train: 0.84 loss val 0.35 accuracy val 0.88\n",
      "0.07 sec | epoch 435 loss train: 0.38 accuracy train: 0.88 loss val 0.29 accuracy val 0.90\n",
      "0.06 sec | epoch 436 loss train: 0.37 accuracy train: 0.86 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 437 loss train: 0.40 accuracy train: 0.86 loss val 0.39 accuracy val 0.86\n",
      "0.05 sec | epoch 438 loss train: 0.43 accuracy train: 0.86 loss val 0.37 accuracy val 0.86\n",
      "0.06 sec | epoch 439 loss train: 0.44 accuracy train: 0.84 loss val 0.46 accuracy val 0.82\n",
      "0.06 sec | epoch 440 loss train: 0.35 accuracy train: 0.86 loss val 0.38 accuracy val 0.84\n",
      "0.05 sec | epoch 441 loss train: 0.41 accuracy train: 0.86 loss val 0.37 accuracy val 0.86\n",
      "0.05 sec | epoch 442 loss train: 0.39 accuracy train: 0.86 loss val 0.40 accuracy val 0.86\n",
      "0.05 sec | epoch 443 loss train: 0.36 accuracy train: 0.88 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 444 loss train: 0.39 accuracy train: 0.88 loss val 0.35 accuracy val 0.88\n",
      "0.04 sec | epoch 445 loss train: 0.43 accuracy train: 0.84 loss val 0.37 accuracy val 0.86\n",
      "0.05 sec | epoch 446 loss train: 0.47 accuracy train: 0.82 loss val 0.34 accuracy val 0.88\n",
      "0.05 sec | epoch 447 loss train: 0.33 accuracy train: 0.90 loss val 0.38 accuracy val 0.86\n",
      "0.04 sec | epoch 448 loss train: 0.45 accuracy train: 0.84 loss val 0.38 accuracy val 0.86\n",
      "0.05 sec | epoch 449 loss train: 0.40 accuracy train: 0.86 loss val 0.39 accuracy val 0.86\n",
      "0.05 sec | epoch 450 loss train: 0.40 accuracy train: 0.86 loss val 0.48 accuracy val 0.80\n",
      "0.05 sec | epoch 451 loss train: 0.38 accuracy train: 0.88 loss val 0.37 accuracy val 0.86\n",
      "0.05 sec | epoch 452 loss train: 0.39 accuracy train: 0.86 loss val 0.39 accuracy val 0.86\n",
      "0.06 sec | epoch 453 loss train: 0.31 accuracy train: 0.90 loss val 0.34 accuracy val 0.88\n",
      "0.06 sec | epoch 454 loss train: 0.39 accuracy train: 0.86 loss val 0.39 accuracy val 0.86\n",
      "0.04 sec | epoch 455 loss train: 0.40 accuracy train: 0.86 loss val 0.40 accuracy val 0.86\n",
      "0.06 sec | epoch 456 loss train: 0.35 accuracy train: 0.88 loss val 0.37 accuracy val 0.88\n",
      "0.05 sec | epoch 457 loss train: 0.32 accuracy train: 0.90 loss val 0.36 accuracy val 0.88\n",
      "0.06 sec | epoch 458 loss train: 0.45 accuracy train: 0.84 loss val 0.32 accuracy val 0.90\n",
      "0.05 sec | epoch 459 loss train: 0.31 accuracy train: 0.90 loss val 0.31 accuracy val 0.90\n",
      "0.06 sec | epoch 460 loss train: 0.34 accuracy train: 0.88 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 461 loss train: 0.54 accuracy train: 0.80 loss val 0.32 accuracy val 0.90\n",
      "0.05 sec | epoch 462 loss train: 0.38 accuracy train: 0.86 loss val 0.37 accuracy val 0.86\n",
      "0.05 sec | epoch 463 loss train: 0.36 accuracy train: 0.88 loss val 0.39 accuracy val 0.86\n",
      "0.05 sec | epoch 464 loss train: 0.39 accuracy train: 0.86 loss val 0.36 accuracy val 0.88\n",
      "0.04 sec | epoch 465 loss train: 0.39 accuracy train: 0.86 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 466 loss train: 0.34 accuracy train: 0.88 loss val 0.38 accuracy val 0.88\n",
      "0.04 sec | epoch 467 loss train: 0.49 accuracy train: 0.82 loss val 0.39 accuracy val 0.86\n",
      "0.06 sec | epoch 468 loss train: 0.38 accuracy train: 0.86 loss val 0.50 accuracy val 0.80\n",
      "0.08 sec | epoch 469 loss train: 0.40 accuracy train: 0.86 loss val 0.31 accuracy val 0.90\n",
      "0.08 sec | epoch 470 loss train: 0.34 accuracy train: 0.88 loss val 0.40 accuracy val 0.86\n",
      "0.06 sec | epoch 471 loss train: 0.32 accuracy train: 0.90 loss val 0.37 accuracy val 0.88\n",
      "0.07 sec | epoch 472 loss train: 0.36 accuracy train: 0.88 loss val 0.34 accuracy val 0.88\n",
      "0.06 sec | epoch 473 loss train: 0.41 accuracy train: 0.84 loss val 0.45 accuracy val 0.84\n",
      "0.06 sec | epoch 474 loss train: 0.42 accuracy train: 0.86 loss val 0.30 accuracy val 0.90\n",
      "0.06 sec | epoch 475 loss train: 0.44 accuracy train: 0.82 loss val 0.35 accuracy val 0.88\n",
      "0.07 sec | epoch 476 loss train: 0.43 accuracy train: 0.84 loss val 0.35 accuracy val 0.88\n",
      "0.06 sec | epoch 477 loss train: 0.36 accuracy train: 0.88 loss val 0.38 accuracy val 0.86\n",
      "0.06 sec | epoch 478 loss train: 0.39 accuracy train: 0.86 loss val 0.45 accuracy val 0.84\n",
      "0.07 sec | epoch 479 loss train: 0.40 accuracy train: 0.86 loss val 0.45 accuracy val 0.82\n",
      "0.06 sec | epoch 480 loss train: 0.29 accuracy train: 0.90 loss val 0.41 accuracy val 0.84\n",
      "0.06 sec | epoch 481 loss train: 0.34 accuracy train: 0.90 loss val 0.35 accuracy val 0.88\n",
      "0.07 sec | epoch 482 loss train: 0.37 accuracy train: 0.86 loss val 0.37 accuracy val 0.88\n",
      "0.07 sec | epoch 483 loss train: 0.30 accuracy train: 0.90 loss val 0.41 accuracy val 0.86\n",
      "0.07 sec | epoch 484 loss train: 0.34 accuracy train: 0.88 loss val 0.33 accuracy val 0.88\n",
      "0.05 sec | epoch 485 loss train: 0.29 accuracy train: 0.90 loss val 0.40 accuracy val 0.86\n",
      "0.06 sec | epoch 486 loss train: 0.32 accuracy train: 0.88 loss val 0.32 accuracy val 0.88\n",
      "0.06 sec | epoch 487 loss train: 0.43 accuracy train: 0.86 loss val 0.36 accuracy val 0.86\n",
      "0.06 sec | epoch 488 loss train: 0.33 accuracy train: 0.88 loss val 0.37 accuracy val 0.88\n",
      "0.05 sec | epoch 489 loss train: 0.40 accuracy train: 0.86 loss val 0.36 accuracy val 0.88\n",
      "0.04 sec | epoch 490 loss train: 0.24 accuracy train: 0.92 loss val 0.39 accuracy val 0.86\n",
      "0.05 sec | epoch 491 loss train: 0.32 accuracy train: 0.90 loss val 0.37 accuracy val 0.86\n",
      "0.06 sec | epoch 492 loss train: 0.37 accuracy train: 0.88 loss val 0.41 accuracy val 0.86\n",
      "0.06 sec | epoch 493 loss train: 0.22 accuracy train: 0.92 loss val 0.29 accuracy val 0.90\n",
      "0.07 sec | epoch 494 loss train: 0.32 accuracy train: 0.88 loss val 0.38 accuracy val 0.86\n",
      "0.07 sec | epoch 495 loss train: 0.44 accuracy train: 0.84 loss val 0.25 accuracy val 0.92\n",
      "0.06 sec | epoch 496 loss train: 0.29 accuracy train: 0.92 loss val 0.39 accuracy val 0.84\n",
      "0.08 sec | epoch 497 loss train: 0.38 accuracy train: 0.86 loss val 0.37 accuracy val 0.88\n",
      "0.09 sec | epoch 498 loss train: 0.39 accuracy train: 0.86 loss val 0.42 accuracy val 0.86\n",
      "0.08 sec | epoch 499 loss train: 0.31 accuracy train: 0.90 loss val 0.33 accuracy val 0.90\n",
      "0.07 sec | epoch 500 loss train: 0.34 accuracy train: 0.88 loss val 0.46 accuracy val 0.84\n",
      "0.08 sec | epoch 501 loss train: 0.36 accuracy train: 0.86 loss val 0.43 accuracy val 0.84\n",
      "0.09 sec | epoch 502 loss train: 0.38 accuracy train: 0.88 loss val 0.37 accuracy val 0.88\n",
      "0.06 sec | epoch 503 loss train: 0.38 accuracy train: 0.88 loss val 0.30 accuracy val 0.90\n",
      "0.08 sec | epoch 504 loss train: 0.38 accuracy train: 0.88 loss val 0.42 accuracy val 0.84\n",
      "0.08 sec | epoch 505 loss train: 0.31 accuracy train: 0.90 loss val 0.45 accuracy val 0.84\n",
      "0.06 sec | epoch 506 loss train: 0.34 accuracy train: 0.88 loss val 0.41 accuracy val 0.86\n",
      "0.07 sec | epoch 507 loss train: 0.38 accuracy train: 0.86 loss val 0.39 accuracy val 0.88\n",
      "0.07 sec | epoch 508 loss train: 0.33 accuracy train: 0.90 loss val 0.44 accuracy val 0.86\n",
      "0.07 sec | epoch 509 loss train: 0.34 accuracy train: 0.88 loss val 0.34 accuracy val 0.88\n",
      "0.07 sec | epoch 510 loss train: 0.40 accuracy train: 0.86 loss val 0.45 accuracy val 0.84\n",
      "0.05 sec | epoch 511 loss train: 0.41 accuracy train: 0.86 loss val 0.41 accuracy val 0.84\n",
      "0.06 sec | epoch 512 loss train: 0.29 accuracy train: 0.92 loss val 0.34 accuracy val 0.88\n",
      "0.06 sec | epoch 513 loss train: 0.36 accuracy train: 0.86 loss val 0.41 accuracy val 0.86\n",
      "0.06 sec | epoch 514 loss train: 0.39 accuracy train: 0.86 loss val 0.35 accuracy val 0.88\n",
      "0.07 sec | epoch 515 loss train: 0.44 accuracy train: 0.86 loss val 0.34 accuracy val 0.88\n",
      "0.08 sec | epoch 516 loss train: 0.40 accuracy train: 0.84 loss val 0.35 accuracy val 0.88\n",
      "0.06 sec | epoch 517 loss train: 0.35 accuracy train: 0.88 loss val 0.36 accuracy val 0.88\n",
      "0.09 sec | epoch 518 loss train: 0.35 accuracy train: 0.88 loss val 0.34 accuracy val 0.88\n",
      "0.05 sec | epoch 519 loss train: 0.36 accuracy train: 0.88 loss val 0.32 accuracy val 0.90\n",
      "0.06 sec | epoch 520 loss train: 0.40 accuracy train: 0.84 loss val 0.35 accuracy val 0.88\n",
      "0.08 sec | epoch 521 loss train: 0.41 accuracy train: 0.84 loss val 0.35 accuracy val 0.88\n",
      "0.07 sec | epoch 522 loss train: 0.35 accuracy train: 0.90 loss val 0.38 accuracy val 0.86\n",
      "0.10 sec | epoch 523 loss train: 0.39 accuracy train: 0.86 loss val 0.41 accuracy val 0.86\n",
      "0.08 sec | epoch 524 loss train: 0.43 accuracy train: 0.84 loss val 0.36 accuracy val 0.88\n",
      "0.09 sec | epoch 525 loss train: 0.41 accuracy train: 0.86 loss val 0.42 accuracy val 0.86\n",
      "0.08 sec | epoch 526 loss train: 0.36 accuracy train: 0.88 loss val 0.38 accuracy val 0.86\n",
      "0.07 sec | epoch 527 loss train: 0.36 accuracy train: 0.86 loss val 0.37 accuracy val 0.88\n",
      "0.06 sec | epoch 528 loss train: 0.43 accuracy train: 0.84 loss val 0.45 accuracy val 0.84\n",
      "0.06 sec | epoch 529 loss train: 0.36 accuracy train: 0.88 loss val 0.30 accuracy val 0.90\n",
      "0.06 sec | epoch 530 loss train: 0.32 accuracy train: 0.90 loss val 0.41 accuracy val 0.86\n",
      "0.06 sec | epoch 531 loss train: 0.42 accuracy train: 0.84 loss val 0.42 accuracy val 0.86\n",
      "0.07 sec | epoch 532 loss train: 0.39 accuracy train: 0.86 loss val 0.42 accuracy val 0.84\n",
      "0.06 sec | epoch 533 loss train: 0.42 accuracy train: 0.86 loss val 0.42 accuracy val 0.86\n",
      "0.05 sec | epoch 534 loss train: 0.41 accuracy train: 0.86 loss val 0.37 accuracy val 0.86\n",
      "0.05 sec | epoch 535 loss train: 0.36 accuracy train: 0.88 loss val 0.30 accuracy val 0.90\n",
      "0.05 sec | epoch 536 loss train: 0.40 accuracy train: 0.86 loss val 0.34 accuracy val 0.88\n",
      "0.05 sec | epoch 537 loss train: 0.41 accuracy train: 0.86 loss val 0.41 accuracy val 0.84\n",
      "0.05 sec | epoch 538 loss train: 0.40 accuracy train: 0.86 loss val 0.47 accuracy val 0.82\n",
      "0.05 sec | epoch 539 loss train: 0.40 accuracy train: 0.86 loss val 0.43 accuracy val 0.84\n",
      "0.04 sec | epoch 540 loss train: 0.42 accuracy train: 0.84 loss val 0.38 accuracy val 0.88\n",
      "0.04 sec | epoch 541 loss train: 0.37 accuracy train: 0.88 loss val 0.32 accuracy val 0.90\n",
      "0.04 sec | epoch 542 loss train: 0.47 accuracy train: 0.82 loss val 0.42 accuracy val 0.84\n",
      "0.05 sec | epoch 543 loss train: 0.34 accuracy train: 0.90 loss val 0.49 accuracy val 0.80\n",
      "0.05 sec | epoch 544 loss train: 0.35 accuracy train: 0.88 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 545 loss train: 0.40 accuracy train: 0.86 loss val 0.39 accuracy val 0.86\n",
      "0.05 sec | epoch 546 loss train: 0.35 accuracy train: 0.88 loss val 0.43 accuracy val 0.84\n",
      "0.05 sec | epoch 547 loss train: 0.39 accuracy train: 0.86 loss val 0.41 accuracy val 0.86\n",
      "0.05 sec | epoch 548 loss train: 0.40 accuracy train: 0.86 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 549 loss train: 0.38 accuracy train: 0.88 loss val 0.37 accuracy val 0.88\n",
      "0.05 sec | epoch 550 loss train: 0.38 accuracy train: 0.86 loss val 0.41 accuracy val 0.86\n",
      "0.04 sec | epoch 551 loss train: 0.38 accuracy train: 0.86 loss val 0.33 accuracy val 0.90\n",
      "0.05 sec | epoch 552 loss train: 0.32 accuracy train: 0.90 loss val 0.42 accuracy val 0.84\n",
      "0.06 sec | epoch 553 loss train: 0.40 accuracy train: 0.86 loss val 0.38 accuracy val 0.86\n",
      "0.07 sec | epoch 554 loss train: 0.34 accuracy train: 0.90 loss val 0.41 accuracy val 0.84\n",
      "0.07 sec | epoch 555 loss train: 0.32 accuracy train: 0.90 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 556 loss train: 0.31 accuracy train: 0.90 loss val 0.39 accuracy val 0.86\n",
      "0.05 sec | epoch 557 loss train: 0.48 accuracy train: 0.84 loss val 0.41 accuracy val 0.86\n",
      "0.06 sec | epoch 558 loss train: 0.43 accuracy train: 0.84 loss val 0.29 accuracy val 0.90\n",
      "0.07 sec | epoch 559 loss train: 0.40 accuracy train: 0.86 loss val 0.41 accuracy val 0.86\n",
      "0.09 sec | epoch 560 loss train: 0.43 accuracy train: 0.84 loss val 0.35 accuracy val 0.88\n",
      "0.06 sec | epoch 561 loss train: 0.38 accuracy train: 0.86 loss val 0.41 accuracy val 0.86\n",
      "0.08 sec | epoch 562 loss train: 0.39 accuracy train: 0.86 loss val 0.35 accuracy val 0.88\n",
      "0.07 sec | epoch 563 loss train: 0.37 accuracy train: 0.88 loss val 0.37 accuracy val 0.88\n",
      "0.06 sec | epoch 564 loss train: 0.37 accuracy train: 0.88 loss val 0.33 accuracy val 0.90\n",
      "0.06 sec | epoch 565 loss train: 0.39 accuracy train: 0.86 loss val 0.29 accuracy val 0.92\n",
      "0.06 sec | epoch 566 loss train: 0.34 accuracy train: 0.88 loss val 0.41 accuracy val 0.86\n",
      "0.06 sec | epoch 567 loss train: 0.47 accuracy train: 0.82 loss val 0.47 accuracy val 0.82\n",
      "0.06 sec | epoch 568 loss train: 0.41 accuracy train: 0.84 loss val 0.38 accuracy val 0.86\n",
      "0.06 sec | epoch 569 loss train: 0.39 accuracy train: 0.86 loss val 0.36 accuracy val 0.88\n",
      "0.06 sec | epoch 570 loss train: 0.36 accuracy train: 0.88 loss val 0.40 accuracy val 0.84\n",
      "0.05 sec | epoch 571 loss train: 0.35 accuracy train: 0.88 loss val 0.43 accuracy val 0.84\n",
      "0.07 sec | epoch 572 loss train: 0.38 accuracy train: 0.88 loss val 0.39 accuracy val 0.86\n",
      "0.06 sec | epoch 573 loss train: 0.33 accuracy train: 0.88 loss val 0.32 accuracy val 0.90\n",
      "0.06 sec | epoch 574 loss train: 0.36 accuracy train: 0.88 loss val 0.39 accuracy val 0.86\n",
      "0.07 sec | epoch 575 loss train: 0.40 accuracy train: 0.86 loss val 0.37 accuracy val 0.88\n",
      "0.07 sec | epoch 576 loss train: 0.36 accuracy train: 0.88 loss val 0.30 accuracy val 0.90\n",
      "0.08 sec | epoch 577 loss train: 0.37 accuracy train: 0.88 loss val 0.37 accuracy val 0.88\n",
      "0.07 sec | epoch 578 loss train: 0.34 accuracy train: 0.88 loss val 0.39 accuracy val 0.86\n",
      "0.07 sec | epoch 579 loss train: 0.38 accuracy train: 0.88 loss val 0.33 accuracy val 0.90\n",
      "0.07 sec | epoch 580 loss train: 0.36 accuracy train: 0.88 loss val 0.33 accuracy val 0.90\n",
      "0.08 sec | epoch 581 loss train: 0.34 accuracy train: 0.88 loss val 0.45 accuracy val 0.84\n",
      "0.08 sec | epoch 582 loss train: 0.46 accuracy train: 0.82 loss val 0.39 accuracy val 0.88\n",
      "0.07 sec | epoch 583 loss train: 0.34 accuracy train: 0.88 loss val 0.38 accuracy val 0.86\n",
      "0.06 sec | epoch 584 loss train: 0.42 accuracy train: 0.84 loss val 0.26 accuracy val 0.92\n",
      "0.07 sec | epoch 585 loss train: 0.37 accuracy train: 0.88 loss val 0.32 accuracy val 0.88\n",
      "0.07 sec | epoch 586 loss train: 0.33 accuracy train: 0.88 loss val 0.40 accuracy val 0.86\n",
      "0.05 sec | epoch 587 loss train: 0.38 accuracy train: 0.86 loss val 0.40 accuracy val 0.86\n",
      "0.07 sec | epoch 588 loss train: 0.31 accuracy train: 0.90 loss val 0.46 accuracy val 0.82\n",
      "0.08 sec | epoch 589 loss train: 0.35 accuracy train: 0.88 loss val 0.39 accuracy val 0.86\n",
      "0.09 sec | epoch 590 loss train: 0.34 accuracy train: 0.90 loss val 0.34 accuracy val 0.88\n",
      "0.07 sec | epoch 591 loss train: 0.39 accuracy train: 0.86 loss val 0.37 accuracy val 0.86\n",
      "0.07 sec | epoch 592 loss train: 0.31 accuracy train: 0.90 loss val 0.49 accuracy val 0.82\n",
      "0.06 sec | epoch 593 loss train: 0.49 accuracy train: 0.80 loss val 0.34 accuracy val 0.88\n",
      "0.06 sec | epoch 594 loss train: 0.42 accuracy train: 0.84 loss val 0.40 accuracy val 0.86\n",
      "0.05 sec | epoch 595 loss train: 0.44 accuracy train: 0.84 loss val 0.37 accuracy val 0.86\n",
      "0.05 sec | epoch 596 loss train: 0.38 accuracy train: 0.86 loss val 0.39 accuracy val 0.86\n",
      "0.05 sec | epoch 597 loss train: 0.41 accuracy train: 0.84 loss val 0.43 accuracy val 0.86\n",
      "0.05 sec | epoch 598 loss train: 0.32 accuracy train: 0.90 loss val 0.36 accuracy val 0.88\n",
      "0.07 sec | epoch 599 loss train: 0.32 accuracy train: 0.88 loss val 0.41 accuracy val 0.86\n",
      "0.07 sec | epoch 600 loss train: 0.33 accuracy train: 0.88 loss val 0.32 accuracy val 0.90\n",
      "0.08 sec | epoch 601 loss train: 0.31 accuracy train: 0.90 loss val 0.39 accuracy val 0.84\n",
      "0.06 sec | epoch 602 loss train: 0.30 accuracy train: 0.90 loss val 0.44 accuracy val 0.82\n",
      "0.08 sec | epoch 603 loss train: 0.31 accuracy train: 0.92 loss val 0.41 accuracy val 0.84\n",
      "0.05 sec | epoch 604 loss train: 0.39 accuracy train: 0.86 loss val 0.52 accuracy val 0.80\n",
      "0.05 sec | epoch 605 loss train: 0.40 accuracy train: 0.86 loss val 0.32 accuracy val 0.88\n",
      "0.05 sec | epoch 606 loss train: 0.48 accuracy train: 0.84 loss val 0.43 accuracy val 0.86\n",
      "0.06 sec | epoch 607 loss train: 0.42 accuracy train: 0.86 loss val 0.38 accuracy val 0.86\n",
      "0.08 sec | epoch 608 loss train: 0.42 accuracy train: 0.84 loss val 0.30 accuracy val 0.90\n",
      "0.07 sec | epoch 609 loss train: 0.35 accuracy train: 0.88 loss val 0.34 accuracy val 0.88\n",
      "0.08 sec | epoch 610 loss train: 0.28 accuracy train: 0.90 loss val 0.30 accuracy val 0.88\n",
      "0.07 sec | epoch 611 loss train: 0.30 accuracy train: 0.90 loss val 0.37 accuracy val 0.86\n",
      "0.06 sec | epoch 612 loss train: 0.46 accuracy train: 0.84 loss val 0.42 accuracy val 0.86\n",
      "0.07 sec | epoch 613 loss train: 0.36 accuracy train: 0.88 loss val 0.35 accuracy val 0.88\n",
      "0.07 sec | epoch 614 loss train: 0.45 accuracy train: 0.82 loss val 0.45 accuracy val 0.84\n",
      "0.06 sec | epoch 615 loss train: 0.32 accuracy train: 0.90 loss val 0.33 accuracy val 0.90\n",
      "0.07 sec | epoch 616 loss train: 0.48 accuracy train: 0.80 loss val 0.36 accuracy val 0.88\n",
      "0.07 sec | epoch 617 loss train: 0.42 accuracy train: 0.84 loss val 0.30 accuracy val 0.92\n",
      "0.08 sec | epoch 618 loss train: 0.37 accuracy train: 0.88 loss val 0.39 accuracy val 0.86\n",
      "0.07 sec | epoch 619 loss train: 0.36 accuracy train: 0.86 loss val 0.31 accuracy val 0.88\n",
      "0.07 sec | epoch 620 loss train: 0.41 accuracy train: 0.84 loss val 0.34 accuracy val 0.88\n",
      "0.09 sec | epoch 621 loss train: 0.34 accuracy train: 0.88 loss val 0.41 accuracy val 0.86\n",
      "0.07 sec | epoch 622 loss train: 0.33 accuracy train: 0.88 loss val 0.41 accuracy val 0.84\n",
      "0.05 sec | epoch 623 loss train: 0.40 accuracy train: 0.86 loss val 0.46 accuracy val 0.84\n",
      "0.06 sec | epoch 624 loss train: 0.29 accuracy train: 0.90 loss val 0.36 accuracy val 0.86\n",
      "0.05 sec | epoch 625 loss train: 0.33 accuracy train: 0.88 loss val 0.37 accuracy val 0.86\n",
      "0.05 sec | epoch 626 loss train: 0.40 accuracy train: 0.86 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 627 loss train: 0.36 accuracy train: 0.86 loss val 0.30 accuracy val 0.90\n",
      "0.05 sec | epoch 628 loss train: 0.35 accuracy train: 0.86 loss val 0.44 accuracy val 0.84\n",
      "0.04 sec | epoch 629 loss train: 0.47 accuracy train: 0.82 loss val 0.34 accuracy val 0.88\n",
      "0.05 sec | epoch 630 loss train: 0.37 accuracy train: 0.88 loss val 0.48 accuracy val 0.84\n",
      "0.05 sec | epoch 631 loss train: 0.33 accuracy train: 0.88 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 632 loss train: 0.32 accuracy train: 0.88 loss val 0.56 accuracy val 0.82\n",
      "0.05 sec | epoch 633 loss train: 0.35 accuracy train: 0.86 loss val 0.39 accuracy val 0.90\n",
      "0.05 sec | epoch 634 loss train: 0.30 accuracy train: 0.88 loss val 0.41 accuracy val 0.86\n",
      "0.05 sec | epoch 635 loss train: 0.27 accuracy train: 0.92 loss val 0.41 accuracy val 0.82\n",
      "0.05 sec | epoch 636 loss train: 0.33 accuracy train: 0.88 loss val 0.39 accuracy val 0.88\n",
      "0.04 sec | epoch 637 loss train: 0.38 accuracy train: 0.88 loss val 0.39 accuracy val 0.88\n",
      "0.04 sec | epoch 638 loss train: 0.32 accuracy train: 0.90 loss val 0.40 accuracy val 0.82\n",
      "0.05 sec | epoch 639 loss train: 0.45 accuracy train: 0.86 loss val 0.49 accuracy val 0.80\n",
      "0.04 sec | epoch 640 loss train: 0.38 accuracy train: 0.86 loss val 0.48 accuracy val 0.84\n",
      "0.05 sec | epoch 641 loss train: 0.38 accuracy train: 0.88 loss val 0.39 accuracy val 0.86\n",
      "0.04 sec | epoch 642 loss train: 0.33 accuracy train: 0.88 loss val 0.48 accuracy val 0.82\n",
      "0.04 sec | epoch 643 loss train: 0.46 accuracy train: 0.82 loss val 0.29 accuracy val 0.92\n",
      "0.05 sec | epoch 644 loss train: 0.36 accuracy train: 0.86 loss val 0.34 accuracy val 0.88\n",
      "0.05 sec | epoch 645 loss train: 0.36 accuracy train: 0.88 loss val 0.41 accuracy val 0.86\n",
      "0.05 sec | epoch 646 loss train: 0.29 accuracy train: 0.92 loss val 0.44 accuracy val 0.84\n",
      "0.06 sec | epoch 647 loss train: 0.38 accuracy train: 0.86 loss val 0.34 accuracy val 0.88\n",
      "0.07 sec | epoch 648 loss train: 0.41 accuracy train: 0.84 loss val 0.39 accuracy val 0.86\n",
      "0.07 sec | epoch 649 loss train: 0.39 accuracy train: 0.86 loss val 0.44 accuracy val 0.84\n",
      "0.07 sec | epoch 650 loss train: 0.33 accuracy train: 0.88 loss val 0.34 accuracy val 0.88\n",
      "0.09 sec | epoch 651 loss train: 0.32 accuracy train: 0.88 loss val 0.38 accuracy val 0.86\n",
      "0.07 sec | epoch 652 loss train: 0.43 accuracy train: 0.84 loss val 0.40 accuracy val 0.86\n",
      "0.06 sec | epoch 653 loss train: 0.38 accuracy train: 0.86 loss val 0.39 accuracy val 0.86\n",
      "0.06 sec | epoch 654 loss train: 0.36 accuracy train: 0.86 loss val 0.43 accuracy val 0.84\n",
      "0.05 sec | epoch 655 loss train: 0.41 accuracy train: 0.86 loss val 0.46 accuracy val 0.82\n",
      "0.05 sec | epoch 656 loss train: 0.34 accuracy train: 0.88 loss val 0.35 accuracy val 0.88\n",
      "0.06 sec | epoch 657 loss train: 0.29 accuracy train: 0.90 loss val 0.39 accuracy val 0.86\n",
      "0.06 sec | epoch 658 loss train: 0.33 accuracy train: 0.88 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 659 loss train: 0.41 accuracy train: 0.86 loss val 0.32 accuracy val 0.88\n",
      "0.06 sec | epoch 660 loss train: 0.34 accuracy train: 0.88 loss val 0.29 accuracy val 0.92\n",
      "0.24 sec | epoch 661 loss train: 0.36 accuracy train: 0.88 loss val 0.36 accuracy val 0.88\n",
      "0.18 sec | epoch 662 loss train: 0.40 accuracy train: 0.84 loss val 0.42 accuracy val 0.84\n",
      "0.04 sec | epoch 663 loss train: 0.36 accuracy train: 0.86 loss val 0.37 accuracy val 0.86\n",
      "0.04 sec | epoch 664 loss train: 0.38 accuracy train: 0.88 loss val 0.32 accuracy val 0.90\n",
      "0.06 sec | epoch 665 loss train: 0.43 accuracy train: 0.86 loss val 0.44 accuracy val 0.84\n",
      "0.08 sec | epoch 666 loss train: 0.43 accuracy train: 0.86 loss val 0.38 accuracy val 0.86\n",
      "0.08 sec | epoch 667 loss train: 0.39 accuracy train: 0.86 loss val 0.32 accuracy val 0.90\n",
      "0.07 sec | epoch 668 loss train: 0.36 accuracy train: 0.88 loss val 0.31 accuracy val 0.90\n",
      "0.07 sec | epoch 669 loss train: 0.43 accuracy train: 0.84 loss val 0.38 accuracy val 0.88\n",
      "0.08 sec | epoch 670 loss train: 0.34 accuracy train: 0.88 loss val 0.43 accuracy val 0.84\n",
      "0.05 sec | epoch 671 loss train: 0.39 accuracy train: 0.86 loss val 0.37 accuracy val 0.86\n",
      "0.08 sec | epoch 672 loss train: 0.33 accuracy train: 0.88 loss val 0.40 accuracy val 0.86\n",
      "0.08 sec | epoch 673 loss train: 0.36 accuracy train: 0.88 loss val 0.33 accuracy val 0.88\n",
      "0.08 sec | epoch 674 loss train: 0.44 accuracy train: 0.84 loss val 0.35 accuracy val 0.88\n",
      "0.09 sec | epoch 675 loss train: 0.35 accuracy train: 0.88 loss val 0.37 accuracy val 0.86\n",
      "0.07 sec | epoch 676 loss train: 0.42 accuracy train: 0.84 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 677 loss train: 0.41 accuracy train: 0.84 loss val 0.38 accuracy val 0.88\n",
      "0.05 sec | epoch 678 loss train: 0.29 accuracy train: 0.90 loss val 0.36 accuracy val 0.86\n",
      "0.05 sec | epoch 679 loss train: 0.30 accuracy train: 0.90 loss val 0.47 accuracy val 0.84\n",
      "0.05 sec | epoch 680 loss train: 0.42 accuracy train: 0.84 loss val 0.38 accuracy val 0.86\n",
      "0.04 sec | epoch 681 loss train: 0.31 accuracy train: 0.90 loss val 0.41 accuracy val 0.86\n",
      "0.06 sec | epoch 682 loss train: 0.38 accuracy train: 0.88 loss val 0.43 accuracy val 0.84\n",
      "0.07 sec | epoch 683 loss train: 0.44 accuracy train: 0.84 loss val 0.41 accuracy val 0.84\n",
      "0.06 sec | epoch 684 loss train: 0.39 accuracy train: 0.86 loss val 0.32 accuracy val 0.88\n",
      "0.05 sec | epoch 685 loss train: 0.31 accuracy train: 0.90 loss val 0.40 accuracy val 0.88\n",
      "0.05 sec | epoch 686 loss train: 0.47 accuracy train: 0.84 loss val 0.38 accuracy val 0.86\n",
      "0.04 sec | epoch 687 loss train: 0.33 accuracy train: 0.88 loss val 0.34 accuracy val 0.88\n",
      "0.05 sec | epoch 688 loss train: 0.43 accuracy train: 0.82 loss val 0.37 accuracy val 0.88\n",
      "0.07 sec | epoch 689 loss train: 0.35 accuracy train: 0.88 loss val 0.32 accuracy val 0.90\n",
      "0.08 sec | epoch 690 loss train: 0.31 accuracy train: 0.90 loss val 0.34 accuracy val 0.88\n",
      "0.05 sec | epoch 691 loss train: 0.35 accuracy train: 0.88 loss val 0.31 accuracy val 0.90\n",
      "0.06 sec | epoch 692 loss train: 0.33 accuracy train: 0.88 loss val 0.34 accuracy val 0.88\n",
      "0.04 sec | epoch 693 loss train: 0.36 accuracy train: 0.86 loss val 0.28 accuracy val 0.90\n",
      "0.05 sec | epoch 694 loss train: 0.25 accuracy train: 0.92 loss val 0.40 accuracy val 0.84\n",
      "0.04 sec | epoch 695 loss train: 0.41 accuracy train: 0.84 loss val 0.44 accuracy val 0.86\n",
      "0.04 sec | epoch 696 loss train: 0.43 accuracy train: 0.84 loss val 0.40 accuracy val 0.84\n",
      "0.04 sec | epoch 697 loss train: 0.40 accuracy train: 0.84 loss val 0.35 accuracy val 0.86\n",
      "0.06 sec | epoch 698 loss train: 0.31 accuracy train: 0.88 loss val 0.40 accuracy val 0.86\n",
      "0.06 sec | epoch 699 loss train: 0.35 accuracy train: 0.88 loss val 0.45 accuracy val 0.82\n",
      "0.05 sec | epoch 700 loss train: 0.40 accuracy train: 0.86 loss val 0.29 accuracy val 0.90\n",
      "0.07 sec | epoch 701 loss train: 0.38 accuracy train: 0.88 loss val 0.50 accuracy val 0.82\n",
      "0.04 sec | epoch 702 loss train: 0.36 accuracy train: 0.88 loss val 0.47 accuracy val 0.84\n",
      "0.05 sec | epoch 703 loss train: 0.39 accuracy train: 0.84 loss val 0.43 accuracy val 0.82\n",
      "0.05 sec | epoch 704 loss train: 0.36 accuracy train: 0.90 loss val 0.33 accuracy val 0.88\n",
      "0.05 sec | epoch 705 loss train: 0.39 accuracy train: 0.88 loss val 0.33 accuracy val 0.88\n",
      "0.06 sec | epoch 706 loss train: 0.37 accuracy train: 0.88 loss val 0.39 accuracy val 0.88\n",
      "0.05 sec | epoch 707 loss train: 0.41 accuracy train: 0.84 loss val 0.34 accuracy val 0.88\n",
      "0.04 sec | epoch 708 loss train: 0.38 accuracy train: 0.86 loss val 0.32 accuracy val 0.90\n",
      "0.05 sec | epoch 709 loss train: 0.38 accuracy train: 0.86 loss val 0.36 accuracy val 0.86\n",
      "0.05 sec | epoch 710 loss train: 0.33 accuracy train: 0.88 loss val 0.34 accuracy val 0.88\n",
      "0.05 sec | epoch 711 loss train: 0.39 accuracy train: 0.86 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 712 loss train: 0.37 accuracy train: 0.86 loss val 0.42 accuracy val 0.84\n",
      "0.05 sec | epoch 713 loss train: 0.27 accuracy train: 0.92 loss val 0.35 accuracy val 0.86\n",
      "0.05 sec | epoch 714 loss train: 0.38 accuracy train: 0.88 loss val 0.40 accuracy val 0.86\n",
      "0.05 sec | epoch 715 loss train: 0.31 accuracy train: 0.90 loss val 0.34 accuracy val 0.86\n",
      "0.05 sec | epoch 716 loss train: 0.37 accuracy train: 0.86 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 717 loss train: 0.42 accuracy train: 0.84 loss val 0.43 accuracy val 0.86\n",
      "0.05 sec | epoch 718 loss train: 0.38 accuracy train: 0.86 loss val 0.32 accuracy val 0.88\n",
      "0.05 sec | epoch 719 loss train: 0.43 accuracy train: 0.84 loss val 0.40 accuracy val 0.86\n",
      "0.05 sec | epoch 720 loss train: 0.33 accuracy train: 0.90 loss val 0.45 accuracy val 0.84\n",
      "0.05 sec | epoch 721 loss train: 0.36 accuracy train: 0.86 loss val 0.32 accuracy val 0.90\n",
      "0.05 sec | epoch 722 loss train: 0.32 accuracy train: 0.88 loss val 0.41 accuracy val 0.86\n",
      "0.05 sec | epoch 723 loss train: 0.41 accuracy train: 0.86 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 724 loss train: 0.40 accuracy train: 0.88 loss val 0.32 accuracy val 0.88\n",
      "0.05 sec | epoch 725 loss train: 0.37 accuracy train: 0.86 loss val 0.27 accuracy val 0.90\n",
      "0.05 sec | epoch 726 loss train: 0.36 accuracy train: 0.88 loss val 0.33 accuracy val 0.90\n",
      "0.05 sec | epoch 727 loss train: 0.33 accuracy train: 0.90 loss val 0.40 accuracy val 0.86\n",
      "0.05 sec | epoch 728 loss train: 0.50 accuracy train: 0.82 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 729 loss train: 0.28 accuracy train: 0.90 loss val 0.42 accuracy val 0.84\n",
      "0.05 sec | epoch 730 loss train: 0.41 accuracy train: 0.86 loss val 0.34 accuracy val 0.88\n",
      "0.05 sec | epoch 731 loss train: 0.42 accuracy train: 0.86 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 732 loss train: 0.37 accuracy train: 0.86 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 733 loss train: 0.40 accuracy train: 0.84 loss val 0.37 accuracy val 0.88\n",
      "0.04 sec | epoch 734 loss train: 0.35 accuracy train: 0.88 loss val 0.42 accuracy val 0.84\n",
      "0.04 sec | epoch 735 loss train: 0.50 accuracy train: 0.82 loss val 0.38 accuracy val 0.86\n",
      "0.05 sec | epoch 736 loss train: 0.37 accuracy train: 0.86 loss val 0.38 accuracy val 0.86\n",
      "0.05 sec | epoch 737 loss train: 0.44 accuracy train: 0.84 loss val 0.38 accuracy val 0.86\n",
      "0.05 sec | epoch 738 loss train: 0.39 accuracy train: 0.86 loss val 0.43 accuracy val 0.84\n",
      "0.05 sec | epoch 739 loss train: 0.34 accuracy train: 0.88 loss val 0.43 accuracy val 0.84\n",
      "0.05 sec | epoch 740 loss train: 0.41 accuracy train: 0.86 loss val 0.32 accuracy val 0.90\n",
      "0.05 sec | epoch 741 loss train: 0.40 accuracy train: 0.86 loss val 0.38 accuracy val 0.88\n",
      "0.06 sec | epoch 742 loss train: 0.32 accuracy train: 0.90 loss val 0.38 accuracy val 0.86\n",
      "0.05 sec | epoch 743 loss train: 0.38 accuracy train: 0.86 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 744 loss train: 0.35 accuracy train: 0.88 loss val 0.38 accuracy val 0.86\n",
      "0.05 sec | epoch 745 loss train: 0.43 accuracy train: 0.84 loss val 0.34 accuracy val 0.88\n",
      "0.05 sec | epoch 746 loss train: 0.36 accuracy train: 0.88 loss val 0.42 accuracy val 0.84\n",
      "0.05 sec | epoch 747 loss train: 0.32 accuracy train: 0.90 loss val 0.39 accuracy val 0.86\n",
      "0.05 sec | epoch 748 loss train: 0.37 accuracy train: 0.86 loss val 0.30 accuracy val 0.90\n",
      "0.05 sec | epoch 749 loss train: 0.38 accuracy train: 0.88 loss val 0.41 accuracy val 0.86\n",
      "0.05 sec | epoch 750 loss train: 0.42 accuracy train: 0.86 loss val 0.42 accuracy val 0.86\n",
      "0.05 sec | epoch 751 loss train: 0.33 accuracy train: 0.88 loss val 0.40 accuracy val 0.86\n",
      "0.05 sec | epoch 752 loss train: 0.31 accuracy train: 0.90 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 753 loss train: 0.48 accuracy train: 0.82 loss val 0.32 accuracy val 0.88\n",
      "0.05 sec | epoch 754 loss train: 0.30 accuracy train: 0.90 loss val 0.30 accuracy val 0.90\n",
      "0.05 sec | epoch 755 loss train: 0.38 accuracy train: 0.86 loss val 0.36 accuracy val 0.86\n",
      "0.05 sec | epoch 756 loss train: 0.36 accuracy train: 0.88 loss val 0.38 accuracy val 0.86\n",
      "0.05 sec | epoch 757 loss train: 0.42 accuracy train: 0.84 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 758 loss train: 0.29 accuracy train: 0.90 loss val 0.41 accuracy val 0.86\n",
      "0.05 sec | epoch 759 loss train: 0.38 accuracy train: 0.88 loss val 0.38 accuracy val 0.84\n",
      "0.05 sec | epoch 760 loss train: 0.39 accuracy train: 0.86 loss val 0.37 accuracy val 0.88\n",
      "0.05 sec | epoch 761 loss train: 0.37 accuracy train: 0.84 loss val 0.33 accuracy val 0.88\n",
      "0.05 sec | epoch 762 loss train: 0.39 accuracy train: 0.84 loss val 0.40 accuracy val 0.84\n",
      "0.05 sec | epoch 763 loss train: 0.37 accuracy train: 0.86 loss val 0.43 accuracy val 0.84\n",
      "0.05 sec | epoch 764 loss train: 0.37 accuracy train: 0.86 loss val 0.41 accuracy val 0.86\n",
      "0.05 sec | epoch 765 loss train: 0.37 accuracy train: 0.86 loss val 0.33 accuracy val 0.88\n",
      "0.05 sec | epoch 766 loss train: 0.44 accuracy train: 0.84 loss val 0.41 accuracy val 0.84\n",
      "0.05 sec | epoch 767 loss train: 0.37 accuracy train: 0.86 loss val 0.37 accuracy val 0.88\n",
      "0.05 sec | epoch 768 loss train: 0.46 accuracy train: 0.84 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 769 loss train: 0.37 accuracy train: 0.88 loss val 0.40 accuracy val 0.84\n",
      "0.05 sec | epoch 770 loss train: 0.47 accuracy train: 0.84 loss val 0.39 accuracy val 0.86\n",
      "0.05 sec | epoch 771 loss train: 0.35 accuracy train: 0.86 loss val 0.30 accuracy val 0.90\n",
      "0.05 sec | epoch 772 loss train: 0.34 accuracy train: 0.88 loss val 0.43 accuracy val 0.84\n",
      "0.05 sec | epoch 773 loss train: 0.36 accuracy train: 0.86 loss val 0.42 accuracy val 0.84\n",
      "0.05 sec | epoch 774 loss train: 0.35 accuracy train: 0.88 loss val 0.34 accuracy val 0.88\n",
      "0.05 sec | epoch 775 loss train: 0.44 accuracy train: 0.86 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 776 loss train: 0.39 accuracy train: 0.86 loss val 0.34 accuracy val 0.88\n",
      "0.05 sec | epoch 777 loss train: 0.40 accuracy train: 0.84 loss val 0.31 accuracy val 0.88\n",
      "0.05 sec | epoch 778 loss train: 0.38 accuracy train: 0.88 loss val 0.32 accuracy val 0.88\n",
      "0.05 sec | epoch 779 loss train: 0.30 accuracy train: 0.90 loss val 0.44 accuracy val 0.84\n",
      "0.05 sec | epoch 780 loss train: 0.35 accuracy train: 0.90 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 781 loss train: 0.32 accuracy train: 0.88 loss val 0.32 accuracy val 0.90\n",
      "0.05 sec | epoch 782 loss train: 0.43 accuracy train: 0.84 loss val 0.33 accuracy val 0.88\n",
      "0.05 sec | epoch 783 loss train: 0.33 accuracy train: 0.90 loss val 0.38 accuracy val 0.86\n",
      "0.05 sec | epoch 784 loss train: 0.47 accuracy train: 0.84 loss val 0.41 accuracy val 0.84\n",
      "0.05 sec | epoch 785 loss train: 0.44 accuracy train: 0.84 loss val 0.40 accuracy val 0.86\n",
      "0.05 sec | epoch 786 loss train: 0.43 accuracy train: 0.84 loss val 0.34 accuracy val 0.88\n",
      "0.05 sec | epoch 787 loss train: 0.35 accuracy train: 0.88 loss val 0.35 accuracy val 0.88\n",
      "0.04 sec | epoch 788 loss train: 0.43 accuracy train: 0.84 loss val 0.26 accuracy val 0.92\n",
      "0.05 sec | epoch 789 loss train: 0.41 accuracy train: 0.86 loss val 0.39 accuracy val 0.84\n",
      "0.05 sec | epoch 790 loss train: 0.42 accuracy train: 0.86 loss val 0.39 accuracy val 0.86\n",
      "0.05 sec | epoch 791 loss train: 0.40 accuracy train: 0.86 loss val 0.39 accuracy val 0.88\n",
      "0.05 sec | epoch 792 loss train: 0.40 accuracy train: 0.86 loss val 0.40 accuracy val 0.86\n",
      "0.05 sec | epoch 793 loss train: 0.36 accuracy train: 0.88 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 794 loss train: 0.37 accuracy train: 0.88 loss val 0.37 accuracy val 0.88\n",
      "0.05 sec | epoch 795 loss train: 0.39 accuracy train: 0.86 loss val 0.39 accuracy val 0.84\n",
      "0.06 sec | epoch 796 loss train: 0.34 accuracy train: 0.88 loss val 0.44 accuracy val 0.84\n",
      "0.05 sec | epoch 797 loss train: 0.39 accuracy train: 0.88 loss val 0.42 accuracy val 0.84\n",
      "0.06 sec | epoch 798 loss train: 0.42 accuracy train: 0.84 loss val 0.40 accuracy val 0.86\n",
      "0.05 sec | epoch 799 loss train: 0.36 accuracy train: 0.88 loss val 0.41 accuracy val 0.84\n",
      "0.06 sec | epoch 800 loss train: 0.31 accuracy train: 0.90 loss val 0.34 accuracy val 0.88\n",
      "0.05 sec | epoch 801 loss train: 0.36 accuracy train: 0.88 loss val 0.40 accuracy val 0.86\n",
      "0.05 sec | epoch 802 loss train: 0.31 accuracy train: 0.90 loss val 0.38 accuracy val 0.86\n",
      "0.05 sec | epoch 803 loss train: 0.38 accuracy train: 0.86 loss val 0.44 accuracy val 0.84\n",
      "0.05 sec | epoch 804 loss train: 0.35 accuracy train: 0.88 loss val 0.33 accuracy val 0.88\n",
      "0.05 sec | epoch 805 loss train: 0.34 accuracy train: 0.88 loss val 0.49 accuracy val 0.82\n",
      "0.05 sec | epoch 806 loss train: 0.49 accuracy train: 0.82 loss val 0.26 accuracy val 0.92\n",
      "0.05 sec | epoch 807 loss train: 0.46 accuracy train: 0.84 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 808 loss train: 0.42 accuracy train: 0.84 loss val 0.38 accuracy val 0.86\n",
      "0.05 sec | epoch 809 loss train: 0.36 accuracy train: 0.88 loss val 0.33 accuracy val 0.88\n",
      "0.05 sec | epoch 810 loss train: 0.34 accuracy train: 0.88 loss val 0.38 accuracy val 0.86\n",
      "0.05 sec | epoch 811 loss train: 0.34 accuracy train: 0.88 loss val 0.38 accuracy val 0.86\n",
      "0.05 sec | epoch 812 loss train: 0.36 accuracy train: 0.88 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 813 loss train: 0.30 accuracy train: 0.90 loss val 0.32 accuracy val 0.90\n",
      "0.05 sec | epoch 814 loss train: 0.36 accuracy train: 0.88 loss val 0.41 accuracy val 0.86\n",
      "0.05 sec | epoch 815 loss train: 0.45 accuracy train: 0.82 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 816 loss train: 0.36 accuracy train: 0.88 loss val 0.41 accuracy val 0.86\n",
      "0.05 sec | epoch 817 loss train: 0.35 accuracy train: 0.88 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 818 loss train: 0.27 accuracy train: 0.92 loss val 0.46 accuracy val 0.84\n",
      "0.05 sec | epoch 819 loss train: 0.32 accuracy train: 0.90 loss val 0.29 accuracy val 0.90\n",
      "0.05 sec | epoch 820 loss train: 0.33 accuracy train: 0.90 loss val 0.41 accuracy val 0.86\n",
      "0.05 sec | epoch 821 loss train: 0.44 accuracy train: 0.84 loss val 0.42 accuracy val 0.84\n",
      "0.05 sec | epoch 822 loss train: 0.28 accuracy train: 0.90 loss val 0.40 accuracy val 0.86\n",
      "0.05 sec | epoch 823 loss train: 0.34 accuracy train: 0.88 loss val 0.44 accuracy val 0.84\n",
      "0.05 sec | epoch 824 loss train: 0.37 accuracy train: 0.86 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 825 loss train: 0.43 accuracy train: 0.86 loss val 0.29 accuracy val 0.90\n",
      "0.05 sec | epoch 826 loss train: 0.40 accuracy train: 0.86 loss val 0.32 accuracy val 0.88\n",
      "0.05 sec | epoch 827 loss train: 0.42 accuracy train: 0.84 loss val 0.30 accuracy val 0.90\n",
      "0.05 sec | epoch 828 loss train: 0.34 accuracy train: 0.88 loss val 0.40 accuracy val 0.86\n",
      "0.05 sec | epoch 829 loss train: 0.39 accuracy train: 0.86 loss val 0.37 accuracy val 0.86\n",
      "0.05 sec | epoch 830 loss train: 0.48 accuracy train: 0.82 loss val 0.38 accuracy val 0.86\n",
      "0.05 sec | epoch 831 loss train: 0.29 accuracy train: 0.90 loss val 0.45 accuracy val 0.84\n",
      "0.05 sec | epoch 832 loss train: 0.45 accuracy train: 0.84 loss val 0.39 accuracy val 0.86\n",
      "0.05 sec | epoch 833 loss train: 0.42 accuracy train: 0.84 loss val 0.42 accuracy val 0.82\n",
      "0.05 sec | epoch 834 loss train: 0.34 accuracy train: 0.88 loss val 0.37 accuracy val 0.86\n",
      "0.05 sec | epoch 835 loss train: 0.45 accuracy train: 0.84 loss val 0.31 accuracy val 0.90\n",
      "0.05 sec | epoch 836 loss train: 0.35 accuracy train: 0.88 loss val 0.38 accuracy val 0.84\n",
      "0.05 sec | epoch 837 loss train: 0.38 accuracy train: 0.88 loss val 0.39 accuracy val 0.86\n",
      "0.05 sec | epoch 838 loss train: 0.39 accuracy train: 0.86 loss val 0.39 accuracy val 0.86\n",
      "0.05 sec | epoch 839 loss train: 0.34 accuracy train: 0.88 loss val 0.29 accuracy val 0.90\n",
      "0.05 sec | epoch 840 loss train: 0.37 accuracy train: 0.88 loss val 0.32 accuracy val 0.90\n",
      "0.05 sec | epoch 841 loss train: 0.32 accuracy train: 0.90 loss val 0.42 accuracy val 0.86\n",
      "0.05 sec | epoch 842 loss train: 0.38 accuracy train: 0.86 loss val 0.30 accuracy val 0.90\n",
      "0.05 sec | epoch 843 loss train: 0.37 accuracy train: 0.88 loss val 0.38 accuracy val 0.86\n",
      "0.05 sec | epoch 844 loss train: 0.35 accuracy train: 0.88 loss val 0.33 accuracy val 0.90\n",
      "0.05 sec | epoch 845 loss train: 0.40 accuracy train: 0.84 loss val 0.31 accuracy val 0.90\n",
      "0.06 sec | epoch 846 loss train: 0.31 accuracy train: 0.88 loss val 0.38 accuracy val 0.86\n",
      "0.09 sec | epoch 847 loss train: 0.33 accuracy train: 0.88 loss val 0.40 accuracy val 0.86\n",
      "0.07 sec | epoch 848 loss train: 0.34 accuracy train: 0.88 loss val 0.46 accuracy val 0.84\n",
      "0.06 sec | epoch 849 loss train: 0.37 accuracy train: 0.86 loss val 0.39 accuracy val 0.88\n",
      "0.05 sec | epoch 850 loss train: 0.35 accuracy train: 0.88 loss val 0.46 accuracy val 0.82\n",
      "0.05 sec | epoch 851 loss train: 0.39 accuracy train: 0.86 loss val 0.35 accuracy val 0.86\n",
      "0.07 sec | epoch 852 loss train: 0.29 accuracy train: 0.90 loss val 0.49 accuracy val 0.82\n",
      "0.08 sec | epoch 853 loss train: 0.41 accuracy train: 0.84 loss val 0.41 accuracy val 0.86\n",
      "0.09 sec | epoch 854 loss train: 0.36 accuracy train: 0.88 loss val 0.35 accuracy val 0.88\n",
      "0.08 sec | epoch 855 loss train: 0.37 accuracy train: 0.86 loss val 0.29 accuracy val 0.92\n",
      "0.08 sec | epoch 856 loss train: 0.37 accuracy train: 0.86 loss val 0.42 accuracy val 0.84\n",
      "0.08 sec | epoch 857 loss train: 0.37 accuracy train: 0.84 loss val 0.28 accuracy val 0.92\n",
      "0.06 sec | epoch 858 loss train: 0.41 accuracy train: 0.86 loss val 0.32 accuracy val 0.90\n",
      "0.08 sec | epoch 859 loss train: 0.34 accuracy train: 0.88 loss val 0.38 accuracy val 0.88\n",
      "0.07 sec | epoch 860 loss train: 0.31 accuracy train: 0.88 loss val 0.30 accuracy val 0.90\n",
      "0.08 sec | epoch 861 loss train: 0.36 accuracy train: 0.88 loss val 0.29 accuracy val 0.88\n",
      "0.08 sec | epoch 862 loss train: 0.38 accuracy train: 0.88 loss val 0.37 accuracy val 0.88\n",
      "0.06 sec | epoch 863 loss train: 0.35 accuracy train: 0.88 loss val 0.35 accuracy val 0.88\n",
      "0.06 sec | epoch 864 loss train: 0.29 accuracy train: 0.90 loss val 0.43 accuracy val 0.82\n",
      "0.06 sec | epoch 865 loss train: 0.29 accuracy train: 0.90 loss val 0.39 accuracy val 0.84\n",
      "0.07 sec | epoch 866 loss train: 0.37 accuracy train: 0.88 loss val 0.40 accuracy val 0.88\n",
      "0.07 sec | epoch 867 loss train: 0.37 accuracy train: 0.88 loss val 0.29 accuracy val 0.88\n",
      "0.06 sec | epoch 868 loss train: 0.34 accuracy train: 0.88 loss val 0.40 accuracy val 0.82\n",
      "0.07 sec | epoch 869 loss train: 0.44 accuracy train: 0.86 loss val 0.44 accuracy val 0.84\n",
      "0.08 sec | epoch 870 loss train: 0.29 accuracy train: 0.90 loss val 0.40 accuracy val 0.86\n",
      "0.08 sec | epoch 871 loss train: 0.46 accuracy train: 0.84 loss val 0.37 accuracy val 0.88\n",
      "0.07 sec | epoch 872 loss train: 0.38 accuracy train: 0.86 loss val 0.35 accuracy val 0.86\n",
      "0.07 sec | epoch 873 loss train: 0.41 accuracy train: 0.84 loss val 0.35 accuracy val 0.88\n",
      "0.08 sec | epoch 874 loss train: 0.37 accuracy train: 0.86 loss val 0.39 accuracy val 0.84\n",
      "0.08 sec | epoch 875 loss train: 0.37 accuracy train: 0.88 loss val 0.34 accuracy val 0.88\n",
      "0.09 sec | epoch 876 loss train: 0.44 accuracy train: 0.84 loss val 0.39 accuracy val 0.86\n",
      "0.07 sec | epoch 877 loss train: 0.32 accuracy train: 0.90 loss val 0.43 accuracy val 0.86\n",
      "0.06 sec | epoch 878 loss train: 0.35 accuracy train: 0.88 loss val 0.29 accuracy val 0.90\n",
      "0.08 sec | epoch 879 loss train: 0.29 accuracy train: 0.90 loss val 0.31 accuracy val 0.88\n",
      "0.08 sec | epoch 880 loss train: 0.33 accuracy train: 0.88 loss val 0.31 accuracy val 0.90\n",
      "0.07 sec | epoch 881 loss train: 0.32 accuracy train: 0.88 loss val 0.42 accuracy val 0.84\n",
      "0.07 sec | epoch 882 loss train: 0.42 accuracy train: 0.86 loss val 0.36 accuracy val 0.88\n",
      "0.08 sec | epoch 883 loss train: 0.41 accuracy train: 0.86 loss val 0.36 accuracy val 0.88\n",
      "0.07 sec | epoch 884 loss train: 0.41 accuracy train: 0.86 loss val 0.42 accuracy val 0.86\n",
      "0.06 sec | epoch 885 loss train: 0.35 accuracy train: 0.88 loss val 0.31 accuracy val 0.90\n",
      "0.08 sec | epoch 886 loss train: 0.37 accuracy train: 0.86 loss val 0.45 accuracy val 0.84\n",
      "0.08 sec | epoch 887 loss train: 0.31 accuracy train: 0.90 loss val 0.31 accuracy val 0.90\n",
      "0.08 sec | epoch 888 loss train: 0.33 accuracy train: 0.90 loss val 0.39 accuracy val 0.86\n",
      "0.07 sec | epoch 889 loss train: 0.38 accuracy train: 0.88 loss val 0.32 accuracy val 0.90\n",
      "0.07 sec | epoch 890 loss train: 0.34 accuracy train: 0.88 loss val 0.43 accuracy val 0.84\n",
      "0.05 sec | epoch 891 loss train: 0.45 accuracy train: 0.84 loss val 0.32 accuracy val 0.90\n",
      "0.05 sec | epoch 892 loss train: 0.38 accuracy train: 0.88 loss val 0.40 accuracy val 0.86\n",
      "0.07 sec | epoch 893 loss train: 0.36 accuracy train: 0.88 loss val 0.31 accuracy val 0.90\n",
      "0.08 sec | epoch 894 loss train: 0.46 accuracy train: 0.82 loss val 0.44 accuracy val 0.84\n",
      "0.05 sec | epoch 895 loss train: 0.39 accuracy train: 0.86 loss val 0.40 accuracy val 0.84\n",
      "0.05 sec | epoch 896 loss train: 0.44 accuracy train: 0.84 loss val 0.39 accuracy val 0.86\n",
      "0.05 sec | epoch 897 loss train: 0.35 accuracy train: 0.88 loss val 0.33 accuracy val 0.90\n",
      "0.05 sec | epoch 898 loss train: 0.36 accuracy train: 0.88 loss val 0.40 accuracy val 0.86\n",
      "0.05 sec | epoch 899 loss train: 0.40 accuracy train: 0.86 loss val 0.34 accuracy val 0.90\n",
      "0.05 sec | epoch 900 loss train: 0.40 accuracy train: 0.86 loss val 0.34 accuracy val 0.88\n",
      "0.06 sec | epoch 901 loss train: 0.44 accuracy train: 0.84 loss val 0.43 accuracy val 0.84\n",
      "0.05 sec | epoch 902 loss train: 0.36 accuracy train: 0.88 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 903 loss train: 0.46 accuracy train: 0.82 loss val 0.44 accuracy val 0.84\n",
      "0.05 sec | epoch 904 loss train: 0.36 accuracy train: 0.88 loss val 0.37 accuracy val 0.88\n",
      "0.05 sec | epoch 905 loss train: 0.39 accuracy train: 0.86 loss val 0.39 accuracy val 0.86\n",
      "0.05 sec | epoch 906 loss train: 0.39 accuracy train: 0.86 loss val 0.43 accuracy val 0.84\n",
      "0.05 sec | epoch 907 loss train: 0.30 accuracy train: 0.90 loss val 0.33 accuracy val 0.88\n",
      "0.05 sec | epoch 908 loss train: 0.35 accuracy train: 0.88 loss val 0.34 accuracy val 0.88\n",
      "0.05 sec | epoch 909 loss train: 0.38 accuracy train: 0.86 loss val 0.39 accuracy val 0.86\n",
      "0.05 sec | epoch 910 loss train: 0.40 accuracy train: 0.84 loss val 0.40 accuracy val 0.86\n",
      "0.05 sec | epoch 911 loss train: 0.35 accuracy train: 0.88 loss val 0.57 accuracy val 0.78\n",
      "0.05 sec | epoch 912 loss train: 0.34 accuracy train: 0.88 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 913 loss train: 0.36 accuracy train: 0.88 loss val 0.37 accuracy val 0.88\n",
      "0.05 sec | epoch 914 loss train: 0.31 accuracy train: 0.88 loss val 0.34 accuracy val 0.88\n",
      "0.05 sec | epoch 915 loss train: 0.44 accuracy train: 0.84 loss val 0.40 accuracy val 0.84\n",
      "0.05 sec | epoch 916 loss train: 0.33 accuracy train: 0.88 loss val 0.34 accuracy val 0.90\n",
      "0.05 sec | epoch 917 loss train: 0.38 accuracy train: 0.84 loss val 0.42 accuracy val 0.86\n",
      "0.05 sec | epoch 918 loss train: 0.39 accuracy train: 0.86 loss val 0.34 accuracy val 0.88\n",
      "0.05 sec | epoch 919 loss train: 0.38 accuracy train: 0.86 loss val 0.33 accuracy val 0.88\n",
      "0.05 sec | epoch 920 loss train: 0.36 accuracy train: 0.88 loss val 0.36 accuracy val 0.86\n",
      "0.05 sec | epoch 921 loss train: 0.37 accuracy train: 0.88 loss val 0.31 accuracy val 0.90\n",
      "0.05 sec | epoch 922 loss train: 0.33 accuracy train: 0.88 loss val 0.38 accuracy val 0.86\n",
      "0.05 sec | epoch 923 loss train: 0.32 accuracy train: 0.90 loss val 0.41 accuracy val 0.88\n",
      "0.05 sec | epoch 924 loss train: 0.38 accuracy train: 0.86 loss val 0.30 accuracy val 0.88\n",
      "0.05 sec | epoch 925 loss train: 0.34 accuracy train: 0.88 loss val 0.36 accuracy val 0.84\n",
      "0.05 sec | epoch 926 loss train: 0.35 accuracy train: 0.88 loss val 0.26 accuracy val 0.92\n",
      "0.05 sec | epoch 927 loss train: 0.49 accuracy train: 0.80 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 928 loss train: 0.30 accuracy train: 0.88 loss val 0.29 accuracy val 0.90\n",
      "0.05 sec | epoch 929 loss train: 0.40 accuracy train: 0.86 loss val 0.33 accuracy val 0.88\n",
      "0.05 sec | epoch 930 loss train: 0.35 accuracy train: 0.86 loss val 0.37 accuracy val 0.88\n",
      "0.05 sec | epoch 931 loss train: 0.38 accuracy train: 0.88 loss val 0.49 accuracy val 0.80\n",
      "0.05 sec | epoch 932 loss train: 0.53 accuracy train: 0.78 loss val 0.27 accuracy val 0.92\n",
      "0.05 sec | epoch 933 loss train: 0.37 accuracy train: 0.86 loss val 0.36 accuracy val 0.86\n",
      "0.05 sec | epoch 934 loss train: 0.40 accuracy train: 0.84 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 935 loss train: 0.47 accuracy train: 0.84 loss val 0.35 accuracy val 0.90\n",
      "0.05 sec | epoch 936 loss train: 0.35 accuracy train: 0.86 loss val 0.34 accuracy val 0.86\n",
      "0.05 sec | epoch 937 loss train: 0.32 accuracy train: 0.90 loss val 0.48 accuracy val 0.82\n",
      "0.04 sec | epoch 938 loss train: 0.36 accuracy train: 0.86 loss val 0.39 accuracy val 0.86\n",
      "0.05 sec | epoch 939 loss train: 0.33 accuracy train: 0.90 loss val 0.39 accuracy val 0.86\n",
      "0.05 sec | epoch 940 loss train: 0.36 accuracy train: 0.90 loss val 0.39 accuracy val 0.84\n",
      "0.05 sec | epoch 941 loss train: 0.39 accuracy train: 0.86 loss val 0.34 accuracy val 0.88\n",
      "0.05 sec | epoch 942 loss train: 0.34 accuracy train: 0.88 loss val 0.45 accuracy val 0.82\n",
      "0.05 sec | epoch 943 loss train: 0.37 accuracy train: 0.86 loss val 0.41 accuracy val 0.84\n",
      "0.06 sec | epoch 944 loss train: 0.41 accuracy train: 0.86 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 945 loss train: 0.31 accuracy train: 0.92 loss val 0.31 accuracy val 0.88\n",
      "0.06 sec | epoch 946 loss train: 0.33 accuracy train: 0.90 loss val 0.37 accuracy val 0.88\n",
      "0.05 sec | epoch 947 loss train: 0.40 accuracy train: 0.86 loss val 0.40 accuracy val 0.84\n",
      "0.05 sec | epoch 948 loss train: 0.42 accuracy train: 0.84 loss val 0.41 accuracy val 0.84\n",
      "0.05 sec | epoch 949 loss train: 0.44 accuracy train: 0.84 loss val 0.38 accuracy val 0.88\n",
      "0.05 sec | epoch 950 loss train: 0.42 accuracy train: 0.86 loss val 0.31 accuracy val 0.90\n",
      "0.05 sec | epoch 951 loss train: 0.40 accuracy train: 0.86 loss val 0.45 accuracy val 0.84\n",
      "0.05 sec | epoch 952 loss train: 0.35 accuracy train: 0.86 loss val 0.37 accuracy val 0.88\n",
      "0.05 sec | epoch 953 loss train: 0.38 accuracy train: 0.86 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 954 loss train: 0.34 accuracy train: 0.88 loss val 0.41 accuracy val 0.86\n",
      "0.06 sec | epoch 955 loss train: 0.42 accuracy train: 0.84 loss val 0.46 accuracy val 0.82\n",
      "0.05 sec | epoch 956 loss train: 0.37 accuracy train: 0.88 loss val 0.31 accuracy val 0.90\n",
      "0.05 sec | epoch 957 loss train: 0.34 accuracy train: 0.90 loss val 0.31 accuracy val 0.90\n",
      "0.05 sec | epoch 958 loss train: 0.39 accuracy train: 0.86 loss val 0.38 accuracy val 0.88\n",
      "0.05 sec | epoch 959 loss train: 0.42 accuracy train: 0.84 loss val 0.40 accuracy val 0.84\n",
      "0.05 sec | epoch 960 loss train: 0.41 accuracy train: 0.86 loss val 0.40 accuracy val 0.86\n",
      "0.05 sec | epoch 961 loss train: 0.43 accuracy train: 0.84 loss val 0.40 accuracy val 0.86\n",
      "0.05 sec | epoch 962 loss train: 0.35 accuracy train: 0.88 loss val 0.46 accuracy val 0.84\n",
      "0.06 sec | epoch 963 loss train: 0.42 accuracy train: 0.84 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 964 loss train: 0.44 accuracy train: 0.84 loss val 0.41 accuracy val 0.84\n",
      "0.05 sec | epoch 965 loss train: 0.37 accuracy train: 0.88 loss val 0.36 accuracy val 0.88\n",
      "0.05 sec | epoch 966 loss train: 0.26 accuracy train: 0.94 loss val 0.46 accuracy val 0.82\n",
      "0.05 sec | epoch 967 loss train: 0.30 accuracy train: 0.90 loss val 0.43 accuracy val 0.84\n",
      "0.05 sec | epoch 968 loss train: 0.37 accuracy train: 0.86 loss val 0.32 accuracy val 0.88\n",
      "0.05 sec | epoch 969 loss train: 0.39 accuracy train: 0.86 loss val 0.41 accuracy val 0.86\n",
      "0.05 sec | epoch 970 loss train: 0.38 accuracy train: 0.86 loss val 0.28 accuracy val 0.90\n",
      "0.05 sec | epoch 971 loss train: 0.38 accuracy train: 0.88 loss val 0.32 accuracy val 0.90\n",
      "0.05 sec | epoch 972 loss train: 0.41 accuracy train: 0.84 loss val 0.38 accuracy val 0.86\n",
      "0.05 sec | epoch 973 loss train: 0.46 accuracy train: 0.84 loss val 0.31 accuracy val 0.90\n",
      "0.05 sec | epoch 974 loss train: 0.36 accuracy train: 0.88 loss val 0.35 accuracy val 0.88\n",
      "0.06 sec | epoch 975 loss train: 0.31 accuracy train: 0.90 loss val 0.42 accuracy val 0.84\n",
      "0.05 sec | epoch 976 loss train: 0.41 accuracy train: 0.86 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 977 loss train: 0.33 accuracy train: 0.90 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 978 loss train: 0.33 accuracy train: 0.88 loss val 0.37 accuracy val 0.86\n",
      "0.05 sec | epoch 979 loss train: 0.40 accuracy train: 0.86 loss val 0.43 accuracy val 0.84\n",
      "0.06 sec | epoch 980 loss train: 0.50 accuracy train: 0.80 loss val 0.31 accuracy val 0.90\n",
      "0.05 sec | epoch 981 loss train: 0.36 accuracy train: 0.86 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 982 loss train: 0.35 accuracy train: 0.88 loss val 0.39 accuracy val 0.86\n",
      "0.05 sec | epoch 983 loss train: 0.39 accuracy train: 0.86 loss val 0.40 accuracy val 0.86\n",
      "0.05 sec | epoch 984 loss train: 0.36 accuracy train: 0.88 loss val 0.44 accuracy val 0.84\n",
      "0.05 sec | epoch 985 loss train: 0.39 accuracy train: 0.84 loss val 0.38 accuracy val 0.86\n",
      "0.05 sec | epoch 986 loss train: 0.40 accuracy train: 0.86 loss val 0.30 accuracy val 0.90\n",
      "0.05 sec | epoch 987 loss train: 0.44 accuracy train: 0.86 loss val 0.40 accuracy val 0.86\n",
      "0.05 sec | epoch 988 loss train: 0.36 accuracy train: 0.88 loss val 0.38 accuracy val 0.86\n",
      "0.05 sec | epoch 989 loss train: 0.38 accuracy train: 0.86 loss val 0.32 accuracy val 0.90\n",
      "0.06 sec | epoch 990 loss train: 0.37 accuracy train: 0.86 loss val 0.31 accuracy val 0.92\n",
      "0.05 sec | epoch 991 loss train: 0.36 accuracy train: 0.88 loss val 0.31 accuracy val 0.90\n",
      "0.05 sec | epoch 992 loss train: 0.36 accuracy train: 0.88 loss val 0.28 accuracy val 0.92\n",
      "0.06 sec | epoch 993 loss train: 0.40 accuracy train: 0.86 loss val 0.30 accuracy val 0.90\n",
      "0.05 sec | epoch 994 loss train: 0.40 accuracy train: 0.86 loss val 0.39 accuracy val 0.86\n",
      "0.05 sec | epoch 995 loss train: 0.39 accuracy train: 0.86 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 996 loss train: 0.45 accuracy train: 0.82 loss val 0.35 accuracy val 0.90\n",
      "0.06 sec | epoch 997 loss train: 0.37 accuracy train: 0.88 loss val 0.35 accuracy val 0.88\n",
      "0.05 sec | epoch 998 loss train: 0.36 accuracy train: 0.86 loss val 0.48 accuracy val 0.80\n",
      "0.05 sec | epoch 999 loss train: 0.35 accuracy train: 0.88 loss val 0.49 accuracy val 0.82\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    \n",
    "    running_loss = 0\n",
    "    running_acc = 0\n",
    "    running_loss_val = 0\n",
    "    running_acc_val = 0\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    classifier.train()\n",
    "    dataset.set_split('train')\n",
    "    data_generator = DataLoader(dataset=dataset, batch_size=2, shuffle=True)\n",
    "    for batch_index, batch_dict in enumerate(data_generator, 1):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = classifier(batch_dict['x'])\n",
    "        \n",
    "        loss_train = loss_func(y_pred, batch_dict['y'])\n",
    "        loss_item = loss_train.item()\n",
    "        running_loss += (loss_item - running_loss) / batch_index\n",
    "        \n",
    "        loss_train.backward()\n",
    "        \n",
    "        accuracy_score = compute_accuracy(batch_dict['y'], y_pred)\n",
    "        running_acc += (accuracy_score - running_acc) / batch_index\n",
    "        \n",
    "        optimizer.step()\n",
    "        break\n",
    "        \n",
    "    classifier.eval()\n",
    "    dataset.set_split('test')\n",
    "    data_generator = DataLoader(dataset=dataset, batch_size=2, shuffle=True)\n",
    "    for batch_index, batch_dict in enumerate(data_generator, 1):\n",
    "        \n",
    "        y_pred = classifier(batch_dict['x'])\n",
    "        \n",
    "        loss_train_val = loss_func(y_pred, batch_dict['y'])\n",
    "        loss_item_val = loss_train_val.item()\n",
    "        running_loss_val += (loss_item_val - running_loss_val) / batch_index\n",
    "        \n",
    "        accuracy_score_val = compute_accuracy(batch_dict['y'], y_pred)\n",
    "        running_acc_val += (accuracy_score_val - running_acc_val) / batch_index\n",
    "        break\n",
    "        \n",
    "    history_dict['acc_train'].append(running_acc)\n",
    "    history_dict['acc_test'].append(running_acc_val)\n",
    "    history_dict['loss_train'].append(running_loss)\n",
    "    history_dict['loss_test'].append(running_loss_val)\n",
    "    \n",
    "    print(\"{:.2f} sec | epoch {} loss train: {:.2f} accuracy train: {:.2f} loss val {:.2f} accuracy val {:.2f}\".format(\n",
    "        time.time() - start, epoch, running_loss, running_acc, running_loss_val, running_acc_val\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_dict['loss_train'])\n",
    "plt.plot(history_dict['loss_test'])\n",
    "plt.ylim(0.0, 1.0)\n",
    "plt.savefig('../reports/20190916.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = classifier(data['x'].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
